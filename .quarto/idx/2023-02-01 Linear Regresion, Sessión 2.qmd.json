{"title":"2023-02-01. Session 2","markdown":{"yaml":{"title":"2023-02-01. Session 2","format":{"html":{"self-contained":true,"code-line-numbers":true}},"custom_title_page":false,"filters":["lightbox"],"lightbox":"auto","number-sections":false,"fig-cap-location":"top"},"headingText":"abstract: The exercise asks to review again the concepts of intercept, slope and coefficient of determination. However this time in a multivariate linear regression (for 2 independent variables). But first, to know if we can use linear regression or not, we have to test its assumptions (linearity, variance homogeneity, normality and independence of observations). Likewise to use linear regression correctly we need to check for exceptional values (outliers), influential observations or if we need to do any transformation of the variable.","containsRefs":false,"markdown":"\n\n---\nsubtitle: \"Linear Regression - Session 2\"\ndate: 2023-02-01\n\nauthor:\n  - name: Javier Silva-Valencia\n    orcid: 0000-0002-5982-2821\n    email: javier.silva@unmsm.edu.pe\n    affiliations:\n      - name: Instituut Voor Tropische Geneeskunde. Antwerp-Belgium\n\nlanguage: \n  title-block-author-single: \"Writer\"\n  \n\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\n\n### Starting the Exercise\n\n**Instructions:**\n\nUse database evans_county.csv. Explore the data. There is a variable QTI,' Quetelet Index' which is equivalent to the BMI, weight in kg divided by the squared height in meters.\n\nIs the Queteled Index(QTI) associated with systolic blood pressure(SBP)?\n\n-   Independent variable: QTI\n-   Dependent variable: SBP\n\n#### Import data\n\nImporting a CSV database under the name of \"evans\", with \",\" as separator and \".\" as decimal:\n\n```{r}\nevans <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2/Linear Regresion Exercise Database/Datasets/evans_county.csv\", sep=\",\", dec= \".\")\n```\n\nWe assume that all variables ok to start (we dont need to transform or create variables)\n\n#### Explore the data\n\nIt is a good practice to explore the data (Doing bivariate analysis). In this case we can do it quicky with a scatterplot\n\n```{r}\n#| label: fig-plot\n#Code in R:          \n  # Make a scatterplot\n  plot(evans$QTI, evans$SBP, main=\"Scatterplot\")\n  # add a regression line\n  abline(lm(SBP~QTI, data = evans), col = \"blue\")\n```\n\n::: callout-note\nWe can see that there could be a correlation, although it doesn't seem very strong.\n:::\n\n#### Question 1\n\nWhat is the regression equation?\n\nFirst we are going to do the regression analysis for only SBP and QTI (bivariate)\n\n```{r}\n#Code for linear regresion:\n  lmQTI = lm(SBP ~ QTI, data = evans)\n  summary(lmQTI)\n```\n\n::: callout-note\n-As a result: we can create the equation with the data we obtained\n\n    * Formula:  y = a+b(x)\n    * a = 129.420\n    * b = 4.439\n        (b is the slope, \n        it means that for every increase of 1 in QTI the SBP increase in 4.43)\n\n    So, the equation would be:\n    * Y= 129.420 + 4.439(X)\n:::\n\n#### Question 2\n\nHow much is the determination coefficient? What does it mean?\n\n::: callout-note\n-The determination coefficient is R2 = 0.009\n\n    Interpretation: \n    \" __%  of the variability of the outcome could be explained by the model \"\n    \"0.9% of the variability of the SBP(blood preasure) could be explained by the model\"\n:::\n\n#### Question 3\n\nIs the slope for QTI statistically significant?\n\n::: callout-note\n-The slope for QTI is 4.439, and its p value is 0.0183 (less than 0.05)\n\n    Interpretation: \n    *The p-value in this case says that there is a statistical association between QTI and SBP (ie, the same as saying that \"the slope of the regression line is significantly different from zero)\"\n:::\n\n### Testing assumptions\n\n::: {.callout-tip collapse=\"true\"}\n## What assumptions?\n\nIn order to say whether it is correct to use linear regression, we must first know if certain conditions are met. These conditions are called assumptions.\n\nWhat are the assumptions to decide whether or not to use linear regression? In addition that our dependent variables need to be a continuous numerical variable, we seek to comply with:\n\n1.  Linearity\n2.  Homogeneity of variance\n3.  Normality\n4.  Independence of observations\n\nFor the first 3 we have to check the residuals. The last one is a theoretical concept of what our data is like.\n:::\n\nTo test for the assumptions first we need to calculate the residuals.\n\nThe residuals can be put as another variable in the data set and also with them the estimated outcome(fitted) can be calculated. Both as new variables\n\n```{r}\n#Creating the residuals and fitted values as new variables\nevans$mod_resid <- residuals(lmQTI)\nevans$mod_fitted <- fitted(lmQTI)\n```\n\n#### Question 4\n\nChecking for Linearity: Is the association between SBP and QTI a linear association?\n\nFor this we scatterplot the residuals(new variable) against the exposure(the independent variable)\n\n```{r}\n#| label: fig-plot2\n#Code in R:          \n  # Make a scatterplot\n  plot(evans$QTI, evans$mod_resid, main=\"Scatterplot\")\n  # add a regression line\n  abline(lm(mod_resid~QTI, data = evans), col = \"blue\")\n```\n\n::: callout-tip\n## Interpretation\n\nFor Linearity we scatterplot the **residuals against the exposure(VI)**\n\nIn this case we see all the dots as a cloud, this suggests that we can assume linearity\n:::\n\n#### Question 5\n\nChecking for Homogeneity of variance: Is the variance of the residuals homogeneous?\n\nWe scatterplot the residuals against the estimated outcome(fitted)\n\n```{r}\n#| label: fig-plot3\n#Code in R:          \n  # Make a scatterplot\n  plot(evans$mod_fitted, evans$mod_resid, main=\"Scatterplot\")\n  # add a regression line\n  abline(lm(mod_resid ~ mod_fitted, data = evans), col = \"blue\")\n```\n\n::: callout-tip\n## Interpretation\n\nFor Homogeneity of variance we scatterplot the **residuals against estimated outcome(fitted)**\n\nIn this case we see all the dots as a cloud, then we assume homogeneity\n:::\n\n#### Question 6\n\nChecking for Normality: Are the residuals normally distributed?\n\n```{r}\n#| label: fig-plot4\n#Doing an histogram of the residuals\n  hist(evans$mod_resid,main=\"Age distribution of study participants\", \n     xlab=\"Age (years)\", ylab=\"nb\", col=\"green\", border=\"dark green\")\n```\n\n::: callout-tip\n## Interpretation\n\nFor checking normality we do an histogram of the **residuals**\n\nIn this case it seems not, but it is debatable\n:::\n\n#### Question 7\n\nChecking for Independence: Are the observations independent?\n\n::: callout-tip\n## Interpretation\n\nWe don't need to do any calculation for this.\n\nBecause we are not working with sequential measures (in time or in space): The observations are independent\n:::\n\n### Rare values\n\n#### Question 8\n\nAre there any extreme values?\n\n::: callout-tip\n## Reply\n\nFor answer this we need to made a scatter plot of the **residuals against the estimated outcome (fitted)** (we already did this in @fig-plot3 )\n\nFor discussion. It does seem to have some extreme values.\n:::\n\n#### Question 9\n\nAre there any influential observation?\n\n::: callout-tip\n## Reply\n\nFor answer this we need to made a scatter plot of the **residuals against the exposure** (we already did this in @fig-plot2 )\n\nFor discussion. It does seem to have some influential observations.\n:::\n\n#### Question 10\n\nDoes the model significantly improve when the variable AGE is added?\n\nThe exercise is asking to doing an multivariate linear regression\n\n```{r}\n#Code for linear regresion:\n  lmQTI_AGE = lm(SBP ~ QTI + AGE, data = evans)\n  summary(lmQTI_AGE)\n```\n\n::: callout-note\n-A. As a result: we can create the new formula with the data we obtained\n\n    * y = a + b1(x1) + b2(x2)\n    * a= 73.4912\n    * b1 = 5.6031\n    * b2 = 0.9630\n    So, the formula would be:\n    * Y= 73.4912 + 5.6031(QTI) + 0.9630(AGE)\n\n-B. We also find the R2\n\n    * R2 is the \"Determination coefficient\". \n    * R2 =  0.1136\n    Interpretation: \n    \"11% of the variability of the SBP could be explained by the model\"\n\n-C. Does the model significantly improve when the variable AGE is added?\n\n    * It improves, but I dont know if it is a significantly improvement. \n:::\n\nTo know if it is a significant improvement, we can do an anova table comparing the 2 models\n\n```{r}\n#Code for ANOVA\n    anova (lmQTI,lmQTI_AGE)\n```\n\n::: callout-tip\n## Reply\n\np = 2.2e-16\n\nThis means that the second model has a significant difference to the first model, so including AGE has increased significantly the model.\n:::\n\n#### Question 11\n\nWhich proportion of the variability in SBP is explained by this model?\n\n::: callout-tip\n## Reply\n\nThey are asking for the R2 (\"Determination coefficient\")\n\nWe already did it in question 10\n\nR2 = 0.1136\n\nInterpretation: \"11% of the variability of the SBP could be explained by the model\"\n:::\n\n#### Question 12\n\nPlease write down the equation of the model\n\n::: callout-tip\n## Reply\n\nWe already did it in question 10\n\ny = a + b1(x1) + b2(x2)\n\n-   a= 73.4912\n-   b1 = 5.6031\n-   b2 = 0.9630\n\nSo, the formula would be:\n\nY= 73.4912 + 5.6031(QTI) + 0.9630(AGE)\n:::\n\nFinish =)\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":true,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":4,"reference-location":"margin","filters":["lightbox"],"number-sections":false,"self-contained":true,"output-file":"2023-02-01 Linear Regresion, Sessión 2.html"},"language":{"title-block-author-single":"Writer"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","editor":"visual","knitr":{"opts_chunk":{"cache":true,"cache.lazy":false,"R.options":{"knitr.graphics.auto_pdf":true},"attr.source":".numberLines"}},"theme":{"light":"flatly"},"fontsize":"16px","linestretch":1.6,"smooth-scroll":true,"title":"2023-02-01. Session 2","custom_title_page":false,"lightbox":"auto","fig-cap-location":"top","subtitle":"Linear Regression - Session 2","date":"2023-02-01","author":[{"name":"Javier Silva-Valencia","orcid":"0000-0002-5982-2821","email":"javier.silva@unmsm.edu.pe","affiliations":[{"name":"Instituut Voor Tropische Geneeskunde. Antwerp-Belgium"}]}],"abstract":"The exercise asks to review again the concepts of intercept, slope and coefficient of determination. However this time in a multivariate linear regression (for 2 independent variables). But first, to know if we can use linear regression or not, we have to test its assumptions (linearity, variance homogeneity, normality and independence of observations). Likewise to use linear regression correctly we need to check for exceptional values (outliers), influential observations or if we need to do any transformation of the variable."},"extensions":{"book":{"multiFile":true}}}}}