{"title":"Data Analysis Wk2","markdown":{"yaml":{"title":"Data Analysis Wk2","format":{"html":{"self-contained":true,"code-line-numbers":true},"pdf":{"documentclass":"article"}},"custom_title_page":false,"filters":["lightbox"],"lightbox":"auto"},"headingText":"abstract: Today we are going to create an index/score. For this we have a lot of variables of socioeconomical aspects and we are going to clean and select the ones we are going to use to create the index/score","containsRefs":false,"markdown":"\n\n---\nsubtitle: \"Data Analysis Week - Session 2\"\ndate: 2023-02-28\n\nauthor:\n  - name: Javier Silva-Valencia\n    orcid: 0000-0002-5982-2821\n    email: javier.silva@unmsm.edu.pe\n    affiliations:\n      - name: Instituut Voor Tropische Geneeskunde. Antwerp-Belgium\n\nlanguage: \n  title-block-author-single: \"Writer\"\n  \n\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\n\n\n### Exercise 1\n\n#### 0. Import CSV\n\n0.1 Set working directory: We are not going to do it now, but this is useful to say to R that all the files we are going to work is that one directory.\n\n0.2 Importing the CSV database under the name of Q1_B_106, with \",\" as separator, and with \".\" as decimal:\n\n```{r}\nQ1_B_106 <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2_DataAnalysis_ThWk/Material/Q1_B_106.csv\", sep=\",\", dec= \".\")\n```\n\n\n#### 1. Cleaning the dataset\n\n1.1 Seeing the structure of the dataset\n```{r}\nstr(Q1_B_106)\n```\n\n::: callout-tip\nAccording to diccionary\n\n-1 : Missing or not available\n\n0, 1, 2, 3 : Number of items they have\n::: \n\n\n```{r}\nsummary(Q1_B_106)\n```\n::: callout-tip\nExample of what we can see: The maximum number of radios in a household is 6\n::: \n\n#### 2. Replace values\n\n2.1 We need that all ‘-1’  be converting to ‘0’ \n\nand all value more than ‘≥ 1’ be converting to ‘1’\n\n```{r}\n#We can do it by using \"if else\":\nQ1_B_106$own_Radio <- ifelse(Q1_B_106$Radio>0,1,0)\n\n\n#But other way is: \n#Q1_B_106$own_Radio <- as.numeric(Q1_B_106$Radio > 0)\n#Ask to create a variable called \"own_Radio\" only TRUE when \"Radio\" is more than 0 and converting that into a number (as.numeric) (1:true,0:false)\n\n\n#Checking if it works\ntable(Q1_B_106$own_Radio, Q1_B_106$Radio, useNA = \"always\")\nsummary(Q1_B_106$own_Radio)\n\n```\n::: callout-tip\n12.14% of households have at least one radio.\nWhen we only have 0 and 1, The mean is the proportion of individuals having the exposure.\n::: \n\nWe need to do that for every variable\n\n```{r}\nQ1_B_106$own_Radio <- ifelse(Q1_B_106$Radio>0,1,0)\nQ1_B_106$own_CD_Player <- ifelse(Q1_B_106$CD_Player>0,1,0)\nQ1_B_106$own_BW_Television <- ifelse(Q1_B_106$BW_Television>0,1,0)\nQ1_B_106$own_Color_Television <- ifelse(Q1_B_106$Color_Television>0,1,0)\nQ1_B_106$own_Video_DVD_Player <- ifelse(Q1_B_106$Video_DVD_Player>0,1,0)\nQ1_B_106$own_Mobile <- ifelse(Q1_B_106$Mobile>0,1,0)\nQ1_B_106$own_Non_Mobile_Phone <- ifelse(Q1_B_106$Non_Mobile_Phone>0,1,0)\nQ1_B_106$own_Refrigerator <- ifelse(Q1_B_106$Refrigerator>0,1,0)\nQ1_B_106$own_Iron <- ifelse(Q1_B_106$Iron>0,1,0)\nQ1_B_106$own_Sewing_Machine <- ifelse(Q1_B_106$Sewing_Machine>0,1,0)\nQ1_B_106$own_Watch <- ifelse(Q1_B_106$Watch>0,1,0)\nQ1_B_106$own_Pressure_Cooker <- ifelse(Q1_B_106$Pressure_Cooker>0,1,0)\nQ1_B_106$own_Chairs <- ifelse(Q1_B_106$Chairs>0,1,0)\nQ1_B_106$own_Sofas <- ifelse(Q1_B_106$Sofas>0,1,0)\nQ1_B_106$own_Tables <- ifelse(Q1_B_106$Tables>0,1,0)\nQ1_B_106$own_Cot_Bed <- ifelse(Q1_B_106$Cot_Bed>0,1,0)\nQ1_B_106$own_Cupboards <- ifelse(Q1_B_106$Cupboards>0,1,0)\nQ1_B_106$own_Bicycle <- ifelse(Q1_B_106$Bicycle>0,1,0)\nQ1_B_106$own_Motor_Cycle <- ifelse(Q1_B_106$Motor_Cycle>0,1,0)\nQ1_B_106$own_Animal_Draw_Cart <- ifelse(Q1_B_106$Animal_Draw_Cart>0,1,0)\nQ1_B_106$own_Car <- ifelse(Q1_B_106$Car>0,1,0)\nQ1_B_106$own_Tractor <- ifelse(Q1_B_106$Tractor>0,1,0)\nQ1_B_106$own_Computer <- ifelse(Q1_B_106$Computer>0,1,0)\nQ1_B_106$own_Electric_Fan <- ifelse(Q1_B_106$Electric_Fan>0,1,0)\n```\n\n\n2.2 Now we will make a subset containing only the ‘own’ variables and  FSN\n```{r}\nassets <- subset(Q1_B_106, select = grepl(\"own|FSN\", names(Q1_B_106)))\nstr(assets)  \n```\n\n2.3 Now we will focus only in those variables whose mean have a value between 5-95% (0.05-0.95)\n\nwhy?:\nBecause the mean is the proportion of individuals having the exposure, we are going to exclude the variables that nobody has (less than 5%) and the variables that all people has (more than 95%)\n\n```{r}\n#summary(assets)\nround(sapply(assets, FUN=mean),3)   #To display the mean of each variable with 3 decimals\n```\n::: callout-tip\nBesides FSN, 10 variables have a value between 5-95% (0.05-0.95) \n::: \n\n\n2.3 We are going to create a new subset (assets2) with only in those variables whose mean have a value between 5-95% (0.05-0.95)\n\n```{r}\nassets2 <- subset(assets, select = c(FSN, own_Radio,own_Mobile, own_Sewing_Machine, own_Watch, own_Pressure_Cooker, own_Chairs, own_Tables, own_Bicycle, own_Motor_Cycle, own_Electric_Fan))\nstr(assets2)\n```\n\n#### 3. Adding animals variable\n\nThe researchers noticed that having a \"bovines animals\" variable is important, so we need to incorporate it. The only problem is that the animals information is in another dataset.\n\n’own_bov’ for each household = whether or not it owns cows or buffaloes\n\n```{r}\nanimals = readRDS(\"animals.RDS\")\nhlp1 <- subset(animals, select=c(FSN, count_Cow, count_Buf))\nhlp1$own_bov <- NA\nhlp1$own_bov[hlp1$count_Cow== 0 & hlp1$count_Buf==0] <- 0\nhlp1$own_bov[hlp1$count_Cow> 0 | hlp1$count_Buf>0] <- 1 \nstr(hlp1)\n```\n\n#### 4. Adding brick wall variable\n\nThe researchers noticed that having a \"brick_wall\" variable is important, so we need to incorporate it. The only problem is that the brick_wall information is in another dataset.\n\n\n4.1 Opening Q1_B dataset\n```{r}\nQ1_B <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2_DataAnalysis_ThWk/Material/Q1_B.csv\", sep=\",\", dec= \".\")\n```\n\n4.2 Checking the variable Wall_Material in the Q1_B dataset\n```{r}\ntable(Q1_B$Wall_Material)\n```\n::: callout-tip\nAccording the code list:\n\n    6= Other\n    163= Grass\n    163= Bamboo\n    164, 165, 166= Brick\n\nSo we only need those who had the value 164 or 165 in the Wall_Material variable\n::: \n\n4.3. I only need \"FSN\" and \"WallMaterial\" variables\n```{r}\nhlp2 <- subset(Q1_B, select = c(FSN, Wall_Material))\n```\n\n4.4  Creating a new variable called brickwall according to what I need\n```{r}\nhlp2$brick_wall <- NA\nhlp2$brick_wall[hlp2$Wall_Material %in% c(6,162,163)] <- 0\nhlp2$brick_wall[hlp2$Wall_Material %in% c(164:166)] <- 1\n\ntable(hlp2$brick_wall, Q1_B$Wall_Material)\n```\n\n#### 5. Merging datasets\n\n![Merging planning](mergingdatsets.png)\n\n\n5.1 Merging hlp1 and hlp2\n```{r}\nstr(hlp1)\nstr(hlp2)\nhlp  <-  merge(hlp2, hlp1, all=TRUE, by = \"FSN\")\nstr(hlp)\n#View(hlp)\n```\nwe Dont need countCow, count_Buf or Wall_Material\n```{r}\nhlp <- subset(hlp, select=-c(count_Cow,count_Buf,Wall_Material))\nstr(hlp)\n```\n\n5.2 Merging hlp2 to assets2\n```{r}\nstr(hlp)\nstr(assets2)\nassets3  <-  merge(assets2, hlp, all=TRUE, by = \"FSN\")\nstr(assets3)\n#View(assets3)\n```\n5.3 Check NA values\n\nThe merging creates NA values (ex: in own_bov), but that values are because that household doesnt have a bovine animal, so it should be 0\n\nChecking NA\n```{r}\ntable (assets3$own_bov)\ntable (assets3$own_bov, useNA = \"ifany\")\ntable (assets3$own_bov, useNA = \"always\")\nstr(assets3)\n```\n\n5.4 Replacing NA\n```{r}\nassets3$own_bov[is.na(assets3$own_bov)]<- 0\n#View(assets3)\ntable (assets3$own_bov, useNA = \"always\")\n```\n\n\n#### 6. Principle component analysis\n\n::: {.callout-tip collapse=\"true\"}\n## What is a Principle component analysis (PCA)?\n\n*Principal Component Analysis (PCA)* is a statistical technique that is used to transform a large number of variables into a smaller number (or just 1) new variable. Is often used for making scores or index.\n\nWhen we do a score/index we tend to put equal weight to every variable because we think that every variable is equal important. But is that true? Usually no. So in *Principle component analysis* we try to put a weight to every variable depending the variance. It is useful to also put in in order to know which first component we need to work. (Which variables are representatives and in what measure)\n\nThe idea behind PCA is to find the underlying patterns in the data using its variances. The analysis will create a first (principal) component, then a second, third, and so on. Each component captures a different aspect of the variation in the data, with the first  component capturing the most variation, and subsequent components capturing progressively less. \n\nUsually we use the first component and with that then create a weighted variable for each individual.\n\n::: \n\n```{r}\nnames(assets3)\n```\n6.1 PCA code\n```{r}\npcamod <- princomp(~own_Radio+own_Mobile+own_Sewing_Machine++own_Watch+own_Pressure_Cooker+own_Chairs+own_Tables+own_Bicycle+own_Motor_Cycle+own_Electric_Fan+brick_wall+ own_bov, cor=TRUE, data= assets3)\n```\n\n6.2 Inspect the component loadings of Comp.1\n```{r}\npcamod$loadings\n```\n::: callout-tip\nWe have to choose one model (one component) to select their scores\n::: \n\n\n6.3 Extract the component scores\n\nCreate a variable named PC1 in assets3 from the scores un pcamod\n```{r}\nassets3$PC1 <- pcamod$scores[ ,1]\n#View(assets3)\n```\n\n\n6.4 Check the quintiles\n```{r}\nquantile(assets3$PC1, probs = seq(0,1, 1/5))\n```\n\n6.5 Create a new categorical variable ‘asset_index’ with values 1-5 by quintile\n```{r}\nassets3$asset_index <- NA\nassets3$asset_index[assets3$PC1 >= -2.11118368   & assets3$PC1 <=-1.66100172  ] <- \"1\"\nassets3$asset_index[assets3$PC1 >-1.66100172    & assets3$PC1 <=-0.98271146   ] <- \"2\"\nassets3$asset_index[assets3$PC1 >-0.98271146    & assets3$PC1 <=-0.06987735    ] <- \"3\"\nassets3$asset_index[assets3$PC1 >-0.06987735     & assets3$PC1 <=1.45281527    ] <- \"4\"\nassets3$asset_index[assets3$PC1 >1.45281527     & assets3$PC1 <=7.18120558  ] <- \"5\"\n\n\n```\n\n\n6.6 Drop unnecessary variables by making a subset\n\nOr final dataset (with the Asset index) only need to have FSN and asset_index\n```{r}\nassets4 <- subset(assets3, select= c(FSN,asset_index))\nstr(assets4)\ntable(assets4$asset_index)\n```\n\n\nOpening Quest 1\n```{r}\nQuestionnaire_1 <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2_DataAnalysis_ThWk/Material/Questionnaire_1.csv\", sep=\",\", dec= \".\")\n```\n\n```{r}\nstr(Questionnaire_1)\n```\n\n\n```{r}\nQ1_Screening <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2_DataAnalysis_ThWk/Material/Q1_Screening.csv\", sep=\",\", dec= \".\")\nstr(Q1_Screening)\nhead(Q1_Screening,10)\n```\n```{r}\nhlp  <-  merge(hlp2, hlp1, all=TRUE, by = \"FSN\")\n```\n\n\n\n\n\n\n\n\n\n\n\n\nanimals assets \n+q1screenin\n\n\n\n\n\n\n\n\n\n\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":true,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":4,"reference-location":"margin","filters":["lightbox"],"self-contained":true,"output-file":"Data Analysis Wk2.html"},"language":{"title-block-author-single":"Writer"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.269","editor":"visual","knitr":{"opts_chunk":{"cache":true,"cache.lazy":false,"R.options":{"knitr.graphics.auto_pdf":true},"attr.source":".numberLines"}},"theme":{"light":"flatly"},"fontsize":"16px","linestretch":1.6,"smooth-scroll":true,"title":"Data Analysis Wk2","custom_title_page":false,"lightbox":"auto","subtitle":"Data Analysis Week - Session 2","date":"2023-02-28","author":[{"name":"Javier Silva-Valencia","orcid":"0000-0002-5982-2821","email":"javier.silva@unmsm.edu.pe","affiliations":[{"name":"Instituut Voor Tropische Geneeskunde. Antwerp-Belgium"}]}],"abstract":"Today we are going to create an index/score. For this we have a lot of variables of socioeconomical aspects and we are going to clean and select the ones we are going to use to create the index/score"},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","filters":["lightbox"],"output-file":"Data Analysis Wk2.pdf"},"language":{"title-block-author-single":"Writer"},"metadata":{"block-headings":true,"editor":"visual","knitr":{"opts_chunk":{"cache":true,"cache.lazy":false,"R.options":{"knitr.graphics.auto_pdf":true},"attr.source":".numberLines"}},"title":"Data Analysis Wk2","custom_title_page":false,"lightbox":"auto","subtitle":"Data Analysis Week - Session 2","date":"2023-02-28","author":[{"name":"Javier Silva-Valencia","orcid":"0000-0002-5982-2821","email":"javier.silva@unmsm.edu.pe","affiliations":[{"name":"Instituut Voor Tropische Geneeskunde. Antwerp-Belgium"}]}],"abstract":"Today we are going to create an index/score. For this we have a lot of variables of socioeconomical aspects and we are going to clean and select the ones we are going to use to create the index/score","documentclass":"article"},"extensions":{"book":{}}}}}