{
  "hash": "dfbd5814539163dfa2f54a0244052caf",
  "result": {
    "markdown": "---\ntitle: \"1st Feb. Session 2\"\nformat: \n  html:\n    self-contained: true\n---\n\n\n-   Instituut Voor Tropische Geneeskunde - Antwerp, Belgium\n-   Javier Silva-Valencia\n\n## Step by Step\n\n##### Import data\n\nImporting a CSV database under the name of \"evans\", with \",\" as separator and \".\" as decimal:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevans <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2/Linear Regresion Exercise Database/Datasets/evans_county.csv\", sep=\",\", dec= \".\")\n```\n:::\n\n\nWe assume that all variables ok to start (we dont need to transform or create variables)\n\n------------------------------------------------------------------------\n\n------------------------------------------------------------------------\n\n### Starting the Exercise:\n\nIs the Queteled Index(QTI) associated with systolic blood pressure(SBP)?\n\nIndependent variable: QTI\n\nDependent variable: SBP\n\n##### 0. It is a good practice to explore the data. In this case with a scatterplot\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Code in R:          \n  # Make a scatterplot\n  plot(evans$QTI, evans$SBP, main=\"Scatterplot\")\n  # add a regression line\n  abline(lm(SBP~QTI, data = evans), col = \"blue\")\n```\n\n::: {.cell-output-display}\n![](2023-02-01-Linear-Regresion,-Sessión-2_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n::: callout-note\n-We can see that there could be a correlation, although it seen not very strong\n:::\n\n##### 1. What is the regressión equation?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Code for linear regresion:\n  lmQTI = lm(SBP ~ QTI, data = evans)\n  summary(lmQTI)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = SBP ~ QTI, data = evans)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-54.855 -19.634  -5.213  14.743 155.497 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  129.420      6.875  18.824   <2e-16 ***\nQTI            4.439      1.876   2.366   0.0183 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 27.4 on 607 degrees of freedom\nMultiple R-squared:  0.00914,\tAdjusted R-squared:  0.007508 \nF-statistic: 5.599 on 1 and 607 DF,  p-value: 0.01828\n```\n:::\n:::\n\n\n::: callout-note\n-As a result: we can create the equation with the data we obtained\n\n    * Formula:  y = a+b(x)\n    * a = 129.420\n    * b = 4.439\n        (b is the slope, \n        it means that for every increase of 1 in QTI the SBP increase in 4.43)\n\n    So, the equation would be:\n    * Y= 129.420 + 4.439(X)\n:::\n\n##### 2. How much is the determination coefficient? What does it mean?\n\n::: callout-note\n-The determination coefficient is R2 = 0.009\n\n    Interpretation: \n    \" __%  of the variability of the outcome could be explained by the model \"\n    \"0.9% of the variability of the SBP(blood preasure) could be explained by the model\"\n:::\n\n##### 3. Is the slope for QTI statiscally significant?\n\n::: callout-note\n-The slope for QTI is 4.439 -And its p value is 0.0183 (less than 0.05)\n\n    Interpretation: \n    *P value in this case says that there is a statisticas association (that is the same that       says that \"the slope of the regresion line is significanly different from zero)\n:::\n\n### Testing the assumptions (linearity, homogeneity of variance, normality...)\n\nFirst we need to calculate the residuals an calculate the estimated outcome(fitted) as new variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\nevans$mod_resid <- residuals(lmQTI)\nevans$mod_fitted <- fitted(lmQTI)\n```\n:::\n\n\n##### 4. Is the association betwenn SBP and QTI a linear association?\n\nWe scatterplot the residuals against the exposure(VI)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Code in R:          \n  # Make a scatterplot\n  plot(evans$QTI, evans$mod_resid, main=\"Scatterplot\")\n  # add a regression line\n  abline(lm(mod_resid~QTI, data = evans), col = \"blue\")\n```\n\n::: {.cell-output-display}\n![](2023-02-01-Linear-Regresion,-Sessión-2_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n::: callout-note\n    We scatterplot the residuals against the exposure(VI) \n    In this case because we see it as a cloud, then we assume linearity\n:::\n\n##### 5. Is the variance of the residuals homogeneous?\n\nWe scatterplot the residuals against the estimated outcome(fitted)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Code in R:          \n  # Make a scatterplot\n  plot(evans$mod_fitted, evans$mod_resid, main=\"Scatterplot\")\n  # add a regression line\n  abline(lm(mod_resid ~ mod_fitted, data = evans), col = \"blue\")\n```\n\n::: {.cell-output-display}\n![](2023-02-01-Linear-Regresion,-Sessión-2_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n::: callout-note\n    We residuals against the estimated outcome(fitted)\n    In this case because we see it as a cloud, then we assume homogeneity\n:::\n\n##### 6. Are the residuals normally distributted?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Doing an histogram of the residuals\n  hist(evans$mod_resid,main=\"Age distribution of study participants\", \n     xlab=\"Age (years)\", ylab=\"nb\", col=\"green\", border=\"dark green\")\n```\n\n::: {.cell-output-display}\n![](2023-02-01-Linear-Regresion,-Sessión-2_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n::: callout-note\n    Seems not\n:::\n\n##### 7. Are the observations independent?\n\n::: callout-note\n    We dont need any calculation for this.\n    Because we are not working with sequential measures (in time or in space):\n      The observations  are  independent\n:::\n\n##### 8. Are there any extreme values?\n\n::: callout-note\n    For this we need to made a scatter plot of the residuals against the estimated outcome (fitted) (we already did this in step 5 )\n\n    For discussion. It seems to have some extreme values.\n:::\n\n##### 9. Are there any influential observation?\n\n::: callout-note\n    For this we need to made a scatter plot of the residuals against the exposure (we already did this in step 4 )\n\n    For discussion. It seems to have some influential observations.\n:::\n\n##### 10. Does the model significantly improve when the variable AGE is added?\n\nWe do this doing an multivariate linear regresion\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Code for linear regresion:\n  lmQTI_AGE = lm(SBP ~ QTI+AGE, data = evans)\n  summary(lmQTI_AGE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = SBP ~ QTI + AGE, data = evans)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-57.645 -15.916  -3.985  11.393 160.285 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  73.4912     9.2816   7.918 1.16e-14 ***\nQTI           5.6031     1.7809   3.146  0.00173 ** \nAGE           0.9630     0.1139   8.452  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 25.93 on 606 degrees of freedom\nMultiple R-squared:  0.1136,\tAdjusted R-squared:  0.1107 \nF-statistic: 38.84 on 2 and 606 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n::: callout-note\n-A. As a result: we can create the new formula with the data we obtained\n\n    * y = a + b1(x1) + b2(x2)\n    * a= 73.4912\n    * b1 = 5.6031\n    * b2 = 0.9630\n    So, the formula would be:\n    * Y= 73.4912 + 5.6031(QTI) + 0.9630(AGE)\n\n-B. We also find the R2\n\n    * R2 is the \"Determination coefficient\". \n    * R2 =  0.1136\n    Interpretation: \n    \"11% of the variability of the SBP could be explained by the model\"\n\n-C. Does the model significantly improve when the variable AGE is added?\n\n    * It improves, but I dont know if it is a significantly improvement. \n:::\n\nTo know if it is a significantly improvement, we can do an anova table comparing the 2 models\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Code for ANOVA\n    anova (lmQTI,lmQTI_AGE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: SBP ~ QTI\nModel 2: SBP ~ QTI + AGE\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1    607 455567                                  \n2    606 407530  1     48037 71.432 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n::: callout-note\np = 2.2e-16 The second model has a significant difference to the first model, so including AGE has increased significantly the model.\n:::\n\n##### 11. Which proportion of the variability in SBP is explained by this model?\n\n::: callout-note\nWe already did it at step 10 \\* R2 is the \"Determination coefficient\". \\* R2 = 0.1136 Interpretation: \"11% of the variability of the SBP could be explained by the model\"\n:::\n\n##### 12. Please write down the equation of the model\n\n::: callout-note\nWe already did it at step 10 \\* y = a + b1(x1) + b2(x2) \\* a= 73.4912 \\* b1 = 5.6031 \\* b2 = 0.9630 So, the formula would be: \\* Y= 73.4912 + 5.6031(QTI) + 0.9630(AGE)\n:::\n\nFinish =)\n",
    "supporting": [
      "2023-02-01-Linear-Regresion,-Sessión-2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}