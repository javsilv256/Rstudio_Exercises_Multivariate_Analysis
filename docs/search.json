[
  {
    "objectID": "2023-01-30 Session_VitA.html",
    "href": "2023-01-30 Session_VitA.html",
    "title": "30-01-2023 Exercise",
    "section": "",
    "text": "Field trial in rural northern Ghana on the effect of Vitamin A given in large doses to children under 5 . The data in this exercise were taken from the baseline survey. They include interview data provided by the mother or her substitute, clinical and laboratory data. You will find the da-ta in VASTCHS.csv . Please note that in this csv file semi colons (;) have been used as field separators and comma’s as decimal-point characters. Take this into account when you import the dataset in R!"
  },
  {
    "objectID": "2023-01-30 Session_VitA.html#descriptive-statistics",
    "href": "2023-01-30 Session_VitA.html#descriptive-statistics",
    "title": "30-01-2023 Exercise",
    "section": "2. Descriptive Statistics",
    "text": "2. Descriptive Statistics\n\nSummary\n\nNumeric Variable\n\nsummary(vastchs$AGE)                      #summary\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00   10.00   21.00   22.49   34.00   55.00 \n\nvar(vastchs$AGE)                          #variance\n\n[1] 200.287\n\nsd(vastchs$AGE)                           #standart desviation\n\n[1] 14.15228\n\n\n\n\nCategoric Variable\nFrecuency and Percentage\n\ntable(vastchs$SEX)                        #Counting\n\n\n  1   2 \n560 577 \n\nprop.table(table(vastchs$SEX))            #Percentages\n\n\n        1         2 \n0.4925242 0.5074758 \n\n\nRecode to a factor - From number to string\n\nvastchs$SEX2<-factor(vastchs$SEX, levels=c(1,2))\nsummary(vastchs$SEX2)\n\n  1   2 \n560 577 \n\n\n\n\n\nCreating variables- Recoding: Yes/No = 1/0\n\nvastchs$wasted<- ifelse(vastchs$WHZ< -2, 1,0)     #wasted si es menos a -2 poner 1 sino 0\nvastchs$stunded<- ifelse(vastchs$HAZ< -2, 1,0)     #stunded si es menos a -2 poner 1 sino 0\nvastchs$underweight<- ifelse(vastchs$WAZ< -2, 1,0)     #undweig si es menos a -2 poner 1 sino 0\nvastchs$anemia<- ifelse(vastchs$HB< 8, 1,0)     #anemia si es menos que 8 poner 1 sino 0\nvastchs$vitadef<- ifelse(vastchs$RETINOL< 0.7, 1,0)     #Def of VitA si es menos de 0.7 poner 1 sino 0\n\nvastchs$HANDPUMP2<- ifelse(vastchs$HANDPUMP== 1, 1,0) \n\n\ntable(vastchs$vitadef)                        #Counting\n\n\n  0   1 \n302 835 \n\nprop.table(table(vastchs$vitadef))            #Percentages\n\n\n        0         1 \n0.2656113 0.7343887 \n\ntable(vastchs$HANDPUMP, vastchs$HANDPUMP2)\n\n   \n      0   1\n  1   0 903\n  2  65   0\n  3 169   0\n\n\n\n\nBreast feeding as a potential protective factor agains vit A deficiency\n\ntable (vastchs$CURRBF)            #To see what values have CURRBF\n\n\n  1   2 \n793 344 \n\nvastchs$CURRBF2<- ifelse(vastchs$CURRBF==1, 1,0)    #To change values to 0 to 1\ntable (vastchs$CURRBF, vastchs$CURRBF2)     #To see if has already changed\n\n   \n      0   1\n  1   0 793\n  2 344   0\n\n\nCalculate de OR\n\ntable (vastchs$vitadef, vastchs$CURRBF2)\n\n   \n      0   1\n  0  74 228\n  1 270 565\n\nprop.table(table(vastchs$vitadef, vastchs$CURRBF2))       #Proportion above total sum\n\n   \n             0          1\n  0 0.06508355 0.20052770\n  1 0.23746702 0.49692172\n\nprop.table(table(vastchs$vitadef, vastchs$CURRBF2), margin = 1) #Proportion above ROW\n\n   \n            0         1\n  0 0.2450331 0.7549669\n  1 0.3233533 0.6766467\n\ncc(vastchs,vitadef,CURRBF2)\n\n$df1\n                   Cases Controls Total\nExposed              565      228   793\nUnexposed            270       74   344\nTotal                835      302  1137\nProportion exposed  0.68     0.75  0.70\n\n$df2\n                Point estimate 95%CI-ll 95%CI-ul\nOdds ratio                0.68     0.50     0.92\nPrev. frac. ex.           0.32     0.08     0.50\nPrev. frac. pop           0.24       NA       NA\nchi2(1)                   6.45       NA       NA\nPr>chi2                  0.011       NA       NA\n\n\nAgruping Variable\n\n# Regrouping (e.g. age in months to agegroup)\n          vastchs$agegrp <- NA\n          vastchs$agegrp[vastchs$AGE<12] <- \"1\"\n          vastchs$agegrp[vastchs$AGE>11 & vastchs$AGE<24] <- \"2\"\n          vastchs$agegrp[vastchs$AGE>23 & vastchs$AGE<36] <- \"3\"\n          vastchs$agegrp[vastchs$AGE>35 & vastchs$AGE<48] <- \"4\"\n          vastchs$agegrp[vastchs$AGE>47 & vastchs$AGE<60] <- \"5\"\n          # don't forget to convert agegrp to a factor variable\n          vastchs$agegrp <- factor(vastchs$agegrp)\n\nBeing under2 is a coufunder?\n\nvastchs$under2 <- \"0\"\nvastchs$under2[vastchs$AGE<2] <- \"1\"\nvastchs$agegrp <- factor(vastchs$agegrp)\n\n\nhist(vastchs$AGE)\n\n\n\nsummary(vastchs$AGE)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00   10.00   21.00   22.49   34.00   55.00 \n\n\nWith more options\n\nhist(vastchs$AGE,main=\"Age distribution of study participants\", \n     xlab=\"Age (years)\", ylab=\"nb\", col=\"green\", border=\"dark green\",\n     breaks=5)\n\n\n\n\nWith Tidyverse\n\nggplot(vastchs, aes(x=AGE)) +\n  geom_histogram( color=\"darkblue\", fill=\"lightblue\",  alpha=0.5, origin = 0, binwidth=10)\n\nWarning: `origin` is deprecated. Please use `boundary` instead.\n\n\n\n\n\n\n\nSummary of a categorical variable"
  },
  {
    "objectID": "2023-01-31 Linear Regresion 1.html",
    "href": "2023-01-31 Linear Regresion 1.html",
    "title": "2023-01-31. Session 1",
    "section": "",
    "text": "Instituut Voor Tropische Geneeskunde - Antwerp, Belgium\nJavier Silva-Valencia"
  },
  {
    "objectID": "2023-01-31 Linear Regresion 1.html#step-by-step",
    "href": "2023-01-31 Linear Regresion 1.html#step-by-step",
    "title": "2023-01-31. Session 1",
    "section": "Step by Step",
    "text": "Step by Step\n\nImport data\nImporting a CSV database under the name of lbwpmor, with “,” as separator, and with “.” as decimal:\n\nlbwpmor <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2/Linear Regresion Exercise Database/Datasets/lbwpmor.csv\", sep=\",\", dec= \".\")\n\nWe assume that all variables ok to start (we dont need to transform or create variables)\n\n\n\n\nStarting the Exercise: Low birth and perinatal mortality\nAn ecological study has looked into the relationship between the incidence of low birth weight (“low birth weight per 100 births”) and perinatal mortality (“perinatal mortality per 100 births”) in health districts of a certain region.\n\n1. Finding Correlation (To assume linearity)\n\n#Code in R:\n  cor(lbwpmor$inclbw, lbwpmor$permor)\n\n[1] 0.6861169\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs a result: we have an r of 0.68. It is a moderate strong positive correlation\n\n\n\n\n\n2. Doing the Scatterplot\n\n#Code in R:          \n  # Make a scatterplot\n  plot(lbwpmor$inclbw, lbwpmor$permor, main=\"Title\")\n  # add a regression line\n  abline(lm(permor~inclbw, data = lbwpmor), col = \"blue\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAs a result: we can see a linear positive correlation\n\n\n\n\n\n3. Doing the Linear regresion\n\n#Code in R:\nlmHeight = lm(permor ~ inclbw, data = lbwpmor)\nsummary(lmHeight)\n\n\nCall:\nlm(formula = permor ~ inclbw, data = lbwpmor)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.30030 -0.17013 -0.03691  0.21897  0.34469 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  0.42139    0.31880   1.322 0.202786    \ninclbw       0.14676    0.03668   4.001 0.000837 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.218 on 18 degrees of freedom\nMultiple R-squared:  0.4708,    Adjusted R-squared:  0.4414 \nF-statistic: 16.01 on 1 and 18 DF,  p-value: 0.0008373\n\n\n\n\n\n\n\n\nNote\n\n\n\n-A. As a result: we can recreate the formula with the data we obtained\n* y = a+b(x)\n* a= 0.42139\n* b = 0.14677\nSo, the formula would be:\n* Y= 0.42 +0.147(X)\n  \n-B. We also find the R2\n* R2 is the \"Determination coefficient\". \n* R2 =  0.4708\nInterpretation: \n\"47% of the variability of the mortality could be explained by the model\"\n    \n-C. We also find the p value = 0.000837\nInterpretation:\n*P value in this case says that there is a statisticas association between mortality\nand low birth weight (that is the same that says that \"the slope of the regresion line \nis significanly different from zero)\n    \n-D. As another result we have the “correlation coefficient”\nRemember that we calculate the correlation coefficiente before in part 1 (\"1. Finding\nCorrelation\"). But we can also calculate here because: \n      Correlation coefficient = Square root of R2\nSo:\n      Correlation coefficient (r) = Sqrt(0.4708)\n      Correlation coefficient (r) = 0.6861\nInterpretation: \n    \"The value of 0.68 suggest a strong positive association\"\n\n\n\n\n4. Predict “y” where X=8\nBefore we have already calculated the formula: “Y= 0.42 +0.147(X)” So we just need to replace the “X”\n\n#Calculate:\n0.42 +(0.147*8)\n\n[1] 1.596\n\n\n\n\n\n\n\n\nNote\n\n\n\nClarification: Using the Linear regression formula above we can say that\nwhen \"low birth weight per 100 births\" is 8 \nthe \"perinatal mortality per 100 births\" may be 1.596"
  },
  {
    "objectID": "2023-02-01 Linear Regresion, Sessión 2.html",
    "href": "2023-02-01 Linear Regresion, Sessión 2.html",
    "title": "2023-02-01. Session 2",
    "section": "",
    "text": "Instituut Voor Tropische Geneeskunde - Antwerp, Belgium\nJavier Silva-Valencia"
  },
  {
    "objectID": "2023-02-01 Linear Regresion, Sessión 2.html#step-by-step",
    "href": "2023-02-01 Linear Regresion, Sessión 2.html#step-by-step",
    "title": "2023-02-01. Session 2",
    "section": "Step by Step",
    "text": "Step by Step\n\nImport data\nImporting a CSV database under the name of “evans”, with “,” as separator and “.” as decimal:\n\nevans <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2/Linear Regresion Exercise Database/Datasets/evans_county.csv\", sep=\",\", dec= \".\")\n\nWe assume that all variables ok to start (we dont need to transform or create variables)\n\n\n\n\nStarting the Exercise:\nIs the Queteled Index(QTI) associated with systolic blood pressure(SBP)?\nIndependent variable: QTI\nDependent variable: SBP\n\n0. It is a good practice to explore the data. In this case with a scatterplot\n\n#Code in R:          \n  # Make a scatterplot\n  plot(evans$QTI, evans$SBP, main=\"Scatterplot\")\n  # add a regression line\n  abline(lm(SBP~QTI, data = evans), col = \"blue\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n-We can see that there could be a correlation, although it seen not very strong\n\n\n\n\n1. What is the regressión equation?\n\n#Code for linear regresion:\n  lmQTI = lm(SBP ~ QTI, data = evans)\n  summary(lmQTI)\n\n\nCall:\nlm(formula = SBP ~ QTI, data = evans)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-54.855 -19.634  -5.213  14.743 155.497 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  129.420      6.875  18.824   <2e-16 ***\nQTI            4.439      1.876   2.366   0.0183 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 27.4 on 607 degrees of freedom\nMultiple R-squared:  0.00914,   Adjusted R-squared:  0.007508 \nF-statistic: 5.599 on 1 and 607 DF,  p-value: 0.01828\n\n\n\n\n\n\n\n\nNote\n\n\n\n-As a result: we can create the equation with the data we obtained\n* Formula:  y = a+b(x)\n* a = 129.420\n* b = 4.439\n    (b is the slope, \n    it means that for every increase of 1 in QTI the SBP increase in 4.43)\n\nSo, the equation would be:\n* Y= 129.420 + 4.439(X)\n\n\n\n\n2. How much is the determination coefficient? What does it mean?\n\n\n\n\n\n\nNote\n\n\n\n-The determination coefficient is R2 = 0.009\nInterpretation: \n\" __%  of the variability of the outcome could be explained by the model \"\n\"0.9% of the variability of the SBP(blood preasure) could be explained by the model\"\n\n\n\n\n3. Is the slope for QTI statiscally significant?\n\n\n\n\n\n\nNote\n\n\n\n-The slope for QTI is 4.439 -And its p value is 0.0183 (less than 0.05)\nInterpretation: \n*P value in this case says that there is a statisticas association (that is the same that       says that \"the slope of the regresion line is significanly different from zero)\n\n\n\n\n\nTesting the assumptions (linearity, homogeneity of variance, normality…)\nFirst we need to calculate the residuals an calculate the estimated outcome(fitted) as new variables\n\nevans$mod_resid <- residuals(lmQTI)\nevans$mod_fitted <- fitted(lmQTI)\n\n\n4. Is the association betwenn SBP and QTI a linear association?\nWe scatterplot the residuals against the exposure(VI)\n\n#Code in R:          \n  # Make a scatterplot\n  plot(evans$QTI, evans$mod_resid, main=\"Scatterplot\")\n  # add a regression line\n  abline(lm(mod_resid~QTI, data = evans), col = \"blue\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe scatterplot the residuals against the exposure(VI) \nIn this case because we see it as a cloud, then we assume linearity\n\n\n\n\n5. Is the variance of the residuals homogeneous?\nWe scatterplot the residuals against the estimated outcome(fitted)\n\n#Code in R:          \n  # Make a scatterplot\n  plot(evans$mod_fitted, evans$mod_resid, main=\"Scatterplot\")\n  # add a regression line\n  abline(lm(mod_resid ~ mod_fitted, data = evans), col = \"blue\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe residuals against the estimated outcome(fitted)\nIn this case because we see it as a cloud, then we assume homogeneity\n\n\n\n\n6. Are the residuals normally distributted?\n\n#Doing an histogram of the residuals\n  hist(evans$mod_resid,main=\"Age distribution of study participants\", \n     xlab=\"Age (years)\", ylab=\"nb\", col=\"green\", border=\"dark green\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSeems not\n\n\n\n\n7. Are the observations independent?\n\n\n\n\n\n\nNote\n\n\n\nWe dont need any calculation for this.\nBecause we are not working with sequential measures (in time or in space):\n  The observations  are  independent\n\n\n\n\n8. Are there any extreme values?\n\n\n\n\n\n\nNote\n\n\n\nFor this we need to made a scatter plot of the residuals against the estimated outcome (fitted) (we already did this in step 5 )\n\nFor discussion. It seems to have some extreme values.\n\n\n\n\n9. Are there any influential observation?\n\n\n\n\n\n\nNote\n\n\n\nFor this we need to made a scatter plot of the residuals against the exposure (we already did this in step 4 )\n\nFor discussion. It seems to have some influential observations.\n\n\n\n\n10. Does the model significantly improve when the variable AGE is added?\nWe do this doing an multivariate linear regresion\n\n#Code for linear regresion:\n  lmQTI_AGE = lm(SBP ~ QTI+AGE, data = evans)\n  summary(lmQTI_AGE)\n\n\nCall:\nlm(formula = SBP ~ QTI + AGE, data = evans)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-57.645 -15.916  -3.985  11.393 160.285 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  73.4912     9.2816   7.918 1.16e-14 ***\nQTI           5.6031     1.7809   3.146  0.00173 ** \nAGE           0.9630     0.1139   8.452  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 25.93 on 606 degrees of freedom\nMultiple R-squared:  0.1136,    Adjusted R-squared:  0.1107 \nF-statistic: 38.84 on 2 and 606 DF,  p-value: < 2.2e-16\n\n\n\n\n\n\n\n\nNote\n\n\n\n-A. As a result: we can create the new formula with the data we obtained\n* y = a + b1(x1) + b2(x2)\n* a= 73.4912\n* b1 = 5.6031\n* b2 = 0.9630\nSo, the formula would be:\n* Y= 73.4912 + 5.6031(QTI) + 0.9630(AGE)\n-B. We also find the R2\n* R2 is the \"Determination coefficient\". \n* R2 =  0.1136\nInterpretation: \n\"11% of the variability of the SBP could be explained by the model\"\n-C. Does the model significantly improve when the variable AGE is added?\n* It improves, but I dont know if it is a significantly improvement. \n\n\nTo know if it is a significantly improvement, we can do an anova table comparing the 2 models\n\n#Code for ANOVA\n    anova (lmQTI,lmQTI_AGE)\n\nAnalysis of Variance Table\n\nModel 1: SBP ~ QTI\nModel 2: SBP ~ QTI + AGE\n  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    \n1    607 455567                                  \n2    606 407530  1     48037 71.432 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\np = 2.2e-16 The second model has a significant difference to the first model, so including AGE has increased significantly the model.\n\n\n\n\n11. Which proportion of the variability in SBP is explained by this model?\n\n\n\n\n\n\nNote\n\n\n\nWe already did it at step 10 * R2 is the “Determination coefficient”. * R2 = 0.1136 Interpretation: “11% of the variability of the SBP could be explained by the model”\n\n\n\n\n12. Please write down the equation of the model\n\n\n\n\n\n\nNote\n\n\n\nWe already did it at step 10 * y = a + b1(x1) + b2(x2) * a= 73.4912 * b1 = 5.6031 * b2 = 0.9630 So, the formula would be: * Y= 73.4912 + 5.6031(QTI) + 0.9630(AGE)\n\n\nFinish =)"
  },
  {
    "objectID": "2023-02-02 Linear Regresion, Sessión 3.html",
    "href": "2023-02-02 Linear Regresion, Sessión 3.html",
    "title": "2023-02-02 Linear Regresion, Sessión 3",
    "section": "",
    "text": "Instituut Voor Tropische Geneeskunde - Antwerp, Belgium\nJavier Silva-Valencia"
  },
  {
    "objectID": "2023-02-02 Linear Regresion, Sessión 3.html#step-by-step",
    "href": "2023-02-02 Linear Regresion, Sessión 3.html#step-by-step",
    "title": "2023-02-02 Linear Regresion, Sessión 3",
    "section": "Step by Step",
    "text": "Step by Step\n\nImport data\nImporting a CSV database under the name of “cholest”, with “,” as separator and “.” as decimal:\n\ncholest <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2/Linear Regresion Exercise Database/Datasets/Cholesterol.csv\", sep=\",\", dec= \".\")\n\n\n\n\n\nStarting the Exercise:\nWe want to respond to the question: How do we best explain the variability of cholesterol with the data we have?\n\n1. We explore the variables - Cleaning\n1.1 Cholesterol\n\nhist(cholest$cholesterol)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n-Cholesterol seems ok\n\n\n1.2 Activity\n\nhist(cholest$activity)\n\n\n\nsummary(cholest$activity)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    5.00    8.50   10.92   15.50   26.00 \n\n\n\n\n\n\n\n\nNote\n\n\n\n-Activity seems ok\n\n\n1.3 Occupation\n1.3.1 First we see the values of the variable if they make sense\n\ntable(cholest$occupation)\n\n\n1 2 3 4 \n4 7 6 7 \n\n\n\n\n\n\n\n\nNote\n\n\n\n-Seems ok, Occupation only have 4 categories, and there are 4 categories in my data\n\n\n1.3.2 Second we see if the variable is in a categorical or numerical way as I want. Ocupation is in a numerical way, need to change it to a factor\n\ncholest$occupation_f <- factor(cholest$occupation)\n\n1.3.2 Then, we have to be sure that the first category of the variable should be the reference category\n\n#\ncholest$occupation_f <- factor(cholest$occupation)\n\n\n\n\n\n\n\nNote\n\n\n\n-activity seems ok\n\n\n\n\nDoing the modeling - linear regresion - Method: Change-in-estimate model\nModel with inly the primary expouse variable\n\nmod1 <- lm(cholesterol ~ activity, data=cholest)\nsummary(mod1)\n\n\nCall:\nlm(formula = cholesterol ~ activity, data = cholest)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.85397 -0.49306 -0.06166  0.34349  1.25118 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  4.05397    0.22507  18.012 1.17e-14 ***\nactivity    -0.06410    0.01704  -3.762  0.00108 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6205 on 22 degrees of freedom\nMultiple R-squared:  0.3914,    Adjusted R-squared:  0.3638 \nF-statistic: 14.15 on 1 and 22 DF,  p-value: 0.001077\n\n\nModel with two independent variables\n\nmod2 <- lm(cholesterol ~ activity + age, data=cholest)\n#mod3 <- lm(cholesterol ~ activity + bmi_cat, data=cholest)\n#mod4 <- lm(cholesterol ~ activity + sex_f, data=cholest)\n#mod5 <- lm(cholesterol ~ activity + occupation_f, data=cholest)\n\nsummary(mod2) summary(mod3) summary(mod4) summary(mod5)\nAfter see the % of change we see that only “activity+age” and “activity+BMI” has a change % higher than 10\nMultivariate model\n\n#mod6 <- lm(cholesterol ~ activity + age + bmi_cat, data=cholest)\n#summary(mod6)\n\nThe adjusted effect of activity is: -0.016\nMultivatiate model without age\n\n#mod7 <- lm(cholesterol ~ activity + bmi_cat, data=cholest)\n#summary(mod7)\n\nThe adjusted effect of activity now is: -0.029\nIs that a substancial change? (-0.029 - -0.016)/-0.016 81% Yes, it is a substancial change, so we shoulnt take age of the equation\nMultivatiate model without bmi\n\nmod8 <- lm(cholesterol ~ activity + age, data=cholest)\nsummary(mod8)\n\n\nCall:\nlm(formula = cholesterol ~ activity + age, data = cholest)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.65374 -0.23438 -0.04463  0.20482  0.54035 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.67711    0.32871   5.102 4.71e-05 ***\nactivity    -0.01687    0.01078  -1.565    0.132    \nage          0.04722    0.00610   7.741 1.39e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3235 on 21 degrees of freedom\nMultiple R-squared:  0.8421,    Adjusted R-squared:  0.827 \nF-statistic: 55.99 on 2 and 21 DF,  p-value: 3.836e-09\n\n\nThe adjusted effect of activity now is: -0.017\nIs that a substancial change? (-0.017 - -0.016)/-0.016 6% No, it is not a substancial change, so we can take BMI of the equation\nSo the final model (the more simple) is cholesterol ~ activity + age Mod8"
  },
  {
    "objectID": "2023-02-02 Linear Regresion, Sessión 3_Aft.html",
    "href": "2023-02-02 Linear Regresion, Sessión 3_Aft.html",
    "title": "2023-02-02 Sessión 3",
    "section": "",
    "text": "Instituut Voor Tropische Geneeskunde - Antwerp, Belgium\nJavier Silva-Valencia"
  },
  {
    "objectID": "2023-02-02 Linear Regresion, Sessión 3_Aft.html#step-by-step",
    "href": "2023-02-02 Linear Regresion, Sessión 3_Aft.html#step-by-step",
    "title": "2023-02-02 Sessión 3",
    "section": "Step by Step",
    "text": "Step by Step\n\nImport data\nImporting a CSV database under the name of “usamod”, with “,” as separator and “.” as decimal:\n\nusamod <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2/Linear Regresion Exercise Database/Datasets/usamod.csv\", sep=\",\", dec= \".\")\n\n\n\n\n\nStarting the Exercise:\nThe data represents a sample of 28 women. Those with ID 1 to 11 come from Pizzana, while those with ID 12 to 28 come from Steakosin\n\n1. Perform the regresion analysis on the association between cholesterol and age. Write down the equation of the model. What can you say this model.\nIndependant variable: Age (numeric) Dependant variable: Cholesterol (numeric)\n\n#Code in R:\nlmCholes_Age = lm(cholest ~ age, data = usamod)\nsummary(lmCholes_Age)\n\n\nCall:\nlm(formula = cholest ~ age, data = usamod)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-95.934 -13.378   0.277  24.525  67.230 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 119.5947    21.8781   5.466 9.86e-06 ***\nage           1.8612     0.4322   4.307 0.000209 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 36.55 on 26 degrees of freedom\nMultiple R-squared:  0.4164,    Adjusted R-squared:  0.3939 \nF-statistic: 18.55 on 1 and 26 DF,  p-value: 0.0002092\n\n\n\n\n\n\n\n\nNote\n\n\n\n-A. As a result: we can recreate the formula with the data we obtained\n* y = a+b(x)\n* a= 119.5947\n* b = 1.8612\n    \"For every increase of 1 in age, the cholesterol would increase in 1.86\"\nSo, the formula would be:\n* Y= 119.5947 +1.8612(X)\n  \n-B. We also find the R2\n* R2 is the \"Determination coefficient\". \n* R2 =  0.4164\nInterpretation: \n\"41% of the variability of the Cholesterol could be explained by the model\"\n    \n-C. We also find the p value = 0.0002092\nInterpretation:\n*P value in this case says that there is a statisticas association between Cholesterol\nand age (that is the same that says that \"the slope of the regresion line \nis significanly different from zero)\n    \n-D. As another result we have the “correlation coefficient”\n      Correlation coefficient = Square root of R2\nSo:\n      Correlation coefficient (r) = sqrt(0.4164)\n      Correlation coefficient (r) = 0.6452906\nInterpretation: \n    \"The value of 0.64 suggest a strong positive association\"\n\n\n\n\n2.Now generate a new variable called State (according tho the statement at the beggining). Add State to the model and write down the equation for each categorie. Does the addition of State improve the model significantly? Is this a parallell lines model or a separate lines model?\n2.1 Creating the variable\n\n#Creating the variable\n    usamod$state <-  \"steakosin\"                    #Creating a variable w/only \"steakosin\"\n    usamod$state[usamod$id<12] <- \"pizzana\"         #Replacing where id<12\n#When used the pizzana would be the reference (alphabetical order)\n\n2.2 Puting inside the model\n\n#Code in R:\nlmCholes_Age_Stat = lm(cholest ~ age + state, data = usamod)\nsummary(lmCholes_Age_Stat)\n\n\nCall:\nlm(formula = cholest ~ age + state, data = usamod)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-77.254 -17.669  -0.846  15.964  77.837 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     87.9993    24.7809   3.551  0.00155 ** \nage              2.1303     0.4199   5.074 3.08e-05 ***\nstatesteakosin  30.7509    13.7423   2.238  0.03439 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 34.03 on 25 degrees of freedom\nMultiple R-squared:  0.5138,    Adjusted R-squared:  0.4749 \nF-statistic: 13.21 on 2 and 25 DF,  p-value: 0.0001218\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe equations for each categorie are:\nWhen State is Pizzana (0): \n    y = 87.9993 + 2.1303(Age) + 30.7509(0)\nWhen State is Steakonsin (1): \n    y = 87.9993  + 2.1303(Age) + 30.7509(1)\n    y = 118.7502 + 2.1303(Age)\nThe “Determination coefficient” is:\n\nR2 = 0.5138 “51% of the variability of the Cholesterol could be explained by the model” (It is better that the previous model, but this improve is significant?)\n\n\n\n\n2.3 Seeing if it improves significantly\n\n#Code for ANOVA\n    anova (lmCholes_Age,lmCholes_Age_Stat)\n\nAnalysis of Variance Table\n\nModel 1: cholest ~ age\nModel 2: cholest ~ age + state\n  Res.Df   RSS Df Sum of Sq      F  Pr(>F)  \n1     26 34742                              \n2     25 28945  1    5797.3 5.0073 0.03439 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe p value is 0.03 (less than 0.05) so the difference it is significant So, this new model (lmCholes_Age_Stat) is better. This is a parallel lines model\nBut So far has prove that that in the model should be included Age and also State. But: Should the model stay like this putting state as an another variable (parallel lines) or should be put state as an interaction variable (separate lines)?\n\n\n\n\n3.As the next step please fit a separate lines model by using interaction. Please write down the equations for pizzana and steakconsin. Is this model significantly better than the parallel lines model?\n3.1 Creating the model with interaction\n\n#Code in R:\nlmCholes_Age_Stat_INTERAC = lm(cholest ~ age*state, data = usamod)\nsummary(lmCholes_Age_Stat_INTERAC)\n\n\nCall:\nlm(formula = cholest ~ age * state, data = usamod)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-67.655 -19.951  -6.884  24.689  59.409 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         -2.0506    40.2844  -0.051  0.95982    \nage                  3.8064     0.7300   5.214 2.42e-05 ***\nstatesteakosin     147.6374    45.3424   3.256  0.00335 ** \nage:statesteakosin  -2.2811     0.8517  -2.678  0.01314 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 30.47 on 24 degrees of freedom\nMultiple R-squared:  0.6257,    Adjusted R-squared:  0.5789 \nF-statistic: 13.37 on 3 and 24 DF,  p-value: 2.468e-05\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe new equations for each categorie are:\nWhen State is Pizzana (0): \n    y = -2.0506 + 3.8064(Age) + 0 + 0\nWhen State is Steakonsin (1): \n    y = -2.0506  + 3.8064(Age) + 147.6374(1) + -2.2811(Age)(1)\n    y = 145.5868 + 1.5253(Age)\nThe new “Determination coefficient” is:\n\nR2 = 0.6257 “62% of the variability of the Cholesterol could be explained by the model” (It is better that the previous model, but this improve is significant?)\n\n\n\n\n3.2 Seeing if it improves significantly\n\n#Code for ANOVA\n    anova (lmCholes_Age_Stat,lmCholes_Age_Stat_INTERAC)\n\nAnalysis of Variance Table\n\nModel 1: cholest ~ age + state\nModel 2: cholest ~ age * state\n  Res.Df   RSS Df Sum of Sq      F  Pr(>F)  \n1     25 28945                              \n2     24 22284  1    6660.9 7.1738 0.01314 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe p value is 0.01314 (less than 0.05) so the difference it is significant So, this new model (lmCholes_Age_Stat_INTERAC) is better.\nThis also means that the State acts as an interaction variable, and that the regression should be presented only between 1.cholesterol and 2.age but presented separately by each group of State\n(In the case of not having been significant, it would have meant that the “State” doesnt acts as an interaction variable, and that the regression should be presented between 1.cholesterol, 2.age and 3.state)\n\n\n\n\n4. Make an scatterplot with “Age” as X-variable, “cholesterol” as Y-variable and a regressión line for each category of “state”. At what age do the two regressions line cross? Can you calculate the age at which the lines cross from the equation in question 3?\n4.1 Creating the scatterplot and linear regression only for cholest ~ age\n\n#We will try it with ggplot\nlibrary(tidyverse)                          #Install the package\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n\n#creating the graph for a linear regression of \"lm(cholest ~ age, data = usamod)\"\nggplot(usamod, aes(x=age, y=cholest)) +     \n  geom_point(size=2) +\n  geom_smooth(method=lm, se=FALSE)\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\n4.2 Creating the scatterplot and linear regression for cholest ~ age for each category of state\n\n#creating the graph for a linear regression of \"lm(cholest ~ age*state, data = usamod)\"\nggplot(usamod, aes(x=age, y=cholest, color = state)) + \n  geom_point(size=2) +\n  geom_smooth(method=lm, se=FALSE)\n\n`geom_smooth()` using formula 'y ~ x'\n\n\n\n\n\n4.3 Calculate the age at witch the two lines cross ::: callout-note So before (in section 3.1) we have calculate the equations for the linear regression of cholesterol and age with state acting as a interaction variable:\n  When State is Pizzana (0): \n      y = -2.0506 + 3.8064(Age) + 0 + 0\n  When State is Steakonsin (1): \n      y = -2.0506  + 3.8064(Age) + 147.6374(1) + -2.2811(Age)(1)\n      y = 145.5868 + 1.5253(Age)\n      \n  So if there is a point that both equations have the same \"Cholesterol\" value, we can calculate the Age:\n      \n      -2.0506 + 3.8064(Age) = 145.5868 + 1.5253(Age)\n               2.2811 (Age) = 147.6374\n                      (Age) = 64.72202\n:::"
  },
  {
    "objectID": "2023-02-03 Linear Regresion, Sessión 4.html",
    "href": "2023-02-03 Linear Regresion, Sessión 4.html",
    "title": "2023-02-03 Sessión 4",
    "section": "",
    "text": "Instituut Voor Tropische Geneeskunde - Antwerp, Belgium\nJavier Silva-Valencia"
  },
  {
    "objectID": "2023-02-03 Linear Regresion, Sessión 4.html#step-by-step---selection-of-variables-for-modeling",
    "href": "2023-02-03 Linear Regresion, Sessión 4.html#step-by-step---selection-of-variables-for-modeling",
    "title": "2023-02-03 Sessión 4",
    "section": "Step by Step - Selection of variables for modeling",
    "text": "Step by Step - Selection of variables for modeling\n\nImport data\nImporting a CSV database under the name of “sandfly”, with “,” as separator:\n\nsandfly <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2/Linear Regresion Exercise Database/Datasets/sandfly.csv\", sep=\",\")\n\n\n\n\n\nSpoiler alert\n\n\n\n\n\n\nNote\n\n\n\nWhat we are going to do today is a multivariate linear regression and selecting the variables that will be included in this regression with the “Classical model selection”\nSo, so far we know that the steps to the “Classical model selection” are:\n\n\n\n\n\n\n\nSteps\nExample\n\n\n\n\n\nImagine that you have 6 independent variables and 1 dependent variable. And you want to create a linear regression.\n\n\n1. Do a simple linear regression (bivariate) which each independent variable\nSo we will have 6 models\n\n\n2. Note the models with a p-value less than 0.10. Those are the variables we are going to start working with. Exclude the others\nImagine that only 4 models had a p-value less than 0.10. So we keep those independent variables\n\n\n3. Now create a multivariate linear regression model with all the remaining variables\nSo we will create 01 model with the 4 remaining independent variables. (multivariate model 1)\n\n\n4. Check in the results if any on the variables have a p-value higher than 0.05. If yes, exclude the one with the highest value and create a new model with the remaining variables. Repeat until all variables has a significant p-value (less than 0.05)\nImagine that in the results we see that two variables had a p-value bigger than 0.05. We exclude the highest and create a (multivariate model 2). In the new results we still see that one variable had a p-value bigger than 0.05. So we exclude it and create a (multivariate model 3). In the new results all variables has a significant p value.\n\n\nNow you have the variables that, no matter what happens, they have to be in your model. But, are they ok in that way? or it would be better to put them as interaction?\nThe remaining model (multivariate model 3) only includes 2 independent variables: lm(DependVariabl~ IndepVariab1 + IndependVariable2\n\n\n5. Create another model(s) with the remaining variables but as an interaction\nSo, we create another model (multivariate model 4) but as an interaction lm(DependVariabl~ IndepVariab1 * IndependVariable2\n\n\n6. Check if the model(s) with interaction is significantly better than the one without interaction. For this perform an F test (anova table)\nWe will compare the (multivariate model 3) vs the (multivariate model 4) in an anova table.\n\n\n7. If the results show that no model is better than the other, we keep the model more simple (the one without interaction). Otherwise, we keep the model with interaction\nImagine that the p-value of the ANOVA table is not significant (less than 0.05). This means that no model is better than the other. So we keep the more simple model (the one without interaction)\n\n\n\nSo in this case the final model would be the (multivariate model 3)\n\n\n\n\n\n\n\n\n\nStarting the Exercise (Ex05-2023):\n In Bihar, India, visceral Leishmaniasis or Kala Azar is transmitted by the phlebotomine sand fly p.argentipes. The disease is known to disproportionally affect the poorest segments of society, this could be due to increased exposure to sand flies as a result of poor housing and environmental conditions. To assess the independent contributions of different factors, a study team conducted an entomological survey and collected information on housing and environmental conditions as well as on assets owned. Five hundred houses from a rural block were randomly sampled and light traps were installed simultaneously for a total of 6 nights in each house. Per house the total number of p. argentipes sand flies captured was determined. The data can be found in sandfly.csv. \n\n1. The outcome variable is tot_parg (total numbers of p.argentipes sandflyes captured per house) Is tot_parg normally distributed?\n\nhist(sandfly$tot_parg,main=\"Total number of p.argentipes sandflies captured in a house distribution\", \n     xlab=\"Total number of p.argentipes sandflies captured\", ylab=\"nb\", col=\"green\", border=\"dark green\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is not normally distributed\n\n\n\n\n2. Generate a new variable “log_parg” which is the natural logarithm of tot_parg. Is normally distributed?\n\nsandfly$log_parg <- log(sandfly$tot_parg)    #Creating the natural logarith variable\n\n\nhist(sandfly$log_parg,main=\"Log of p.argentipes sandflies captured in a house distribution\", \n     xlab=\"Log of p.argentipes sandflies captured\", ylab=\"nb\", col=\"green\", border=\"dark green\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt seems normally distributed\n\n\n\n\n3. Explored in simple linear regression whether each of the independent variables is associated with log_parg. Make a table listing each factor, the number and proportion of households in which it is present\n This is the Classical model selection. So, we need bivariate regressions for each independent variable with log_parg \n3.1 Animals\n\n  sandfly$animals <- factor(sandfly$animals)      #Factor because is a categorical variable\n  #table (sandfly$animals, useNA=\"always\")         #To explore the frequency and missing values\n  lm1 = lm(log_parg ~ animals, data = sandfly)    #Simple linear regression (bivariate)\n  summary(lm1)\n\n\nCall:\nlm(formula = log_parg ~ animals, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1944 -0.7965 -0.0164  0.7226  3.3292 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.19440    0.05053  63.218  < 2e-16 ***\nanimals1     0.81025    0.25265   3.207  0.00143 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.107 on 498 degrees of freedom\nMultiple R-squared:  0.02023,   Adjusted R-squared:  0.01827 \nF-statistic: 10.29 on 1 and 498 DF,  p-value: 0.001427\n\n\n3.2 Stove\n\n  sandfly$stove <- factor(sandfly$stove)        #Factor because is a categorical variable\n  #table (sandfly$stove, useNA=\"always\")         #To explore the frequency and missing values\n  lm2 = lm(log_parg ~ stove, data = sandfly)    #Simple linear regression (bivariate)\n  summary(lm2)\n\n\nCall:\nlm(formula = log_parg ~ stove, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.4602 -0.8197 -0.0395  0.7336  3.3060 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.21760    0.05095  63.150   <2e-16 ***\nstove1       0.24261    0.26138   0.928    0.354    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.117 on 498 degrees of freedom\nMultiple R-squared:  0.001727,  Adjusted R-squared:  -0.0002775 \nF-statistic: 0.8615 on 1 and 498 DF,  p-value: 0.3538\n\n\n3.3 Ventilation\n\n  sandfly$ventilation <- factor(sandfly$ventilation)    #Factor because is a categorical variable\n  #table (sandfly$ventilation, useNA=\"always\")           #To explore the frequency and missing values\n  lm3 = lm(log_parg ~ ventilation, data = sandfly)      #Simple linear regression (bivariate)\n  summary(lm3)\n\n\nCall:\nlm(formula = log_parg ~ ventilation, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.3918 -0.6837 -0.0740  0.7756  3.1318 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   3.39179    0.06271  54.084  < 2e-16 ***\nventilation1 -0.42741    0.10094  -4.234 2.73e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.099 on 498 degrees of freedom\nMultiple R-squared:  0.03475,   Adjusted R-squared:  0.03281 \nF-statistic: 17.93 on 1 and 498 DF,  p-value: 2.731e-05\n\n\n3.4 Light\n\n  sandfly$light <- factor(sandfly$light)          #Factor because is a categorical variable\n  #table (sandfly$light, useNA=\"always\")           #To explore the frequency and missing values\n  lm4 = lm(log_parg ~ light, data = sandfly)      #Simple linear regression (bivariate)\n  summary(lm4)\n\n\nCall:\nlm(formula = log_parg ~ light, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.2306 -0.8216 -0.0118  0.7425  3.2929 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.23063    0.06166  52.394   <2e-16 ***\nlight1      -0.01115    0.10544  -0.106    0.916    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.118 on 498 degrees of freedom\nMultiple R-squared:  2.244e-05, Adjusted R-squared:  -0.001986 \nF-statistic: 0.01118 on 1 and 498 DF,  p-value: 0.9158\n\n\n3.5 Cowdung\n\n  sandfly$cowdung <- factor(sandfly$cowdung)        #Factor because is a categorical variable\n  #table (sandfly$cowdung, useNA=\"always\")           #To explore the frequency and missing values\n  lm5 = lm(log_parg ~ cowdung, data = sandfly)      #Simple linear regression (bivariate)\n  summary(lm5)\n\n\nCall:\nlm(formula = log_parg ~ cowdung, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.2419 -0.7570 -0.0230  0.7284  3.2817 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   2.7388     0.2879   9.512   <2e-16 ***\ncowdung1      0.5031     0.2923   1.721   0.0859 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.115 on 498 degrees of freedom\nMultiple R-squared:  0.005912,  Adjusted R-squared:  0.003916 \nF-statistic: 2.962 on 1 and 498 DF,  p-value: 0.08588\n\n\n3.6 Water\n\n  sandfly$water <- factor(sandfly$water)         #Factor because is a categorical variable\n  #table (sandfly$water, useNA=\"always\")          #To explore the frequency and missing values\n  lm6 = lm(log_parg ~ water, data = sandfly)     #Simple linear regression (bivariate)\n  summary(lm6)\n\n\nCall:\nlm(formula = log_parg ~ water, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.3342 -0.8027 -0.0305  0.7452  3.3229 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.20064    0.05572  57.443   <2e-16 ***\nwater1       0.13354    0.12586   1.061    0.289    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.117 on 498 degrees of freedom\nMultiple R-squared:  0.002256,  Adjusted R-squared:  0.0002522 \nF-statistic: 1.126 on 1 and 498 DF,  p-value: 0.2892\n\n\n3.7 Asset_index\n\n  sandfly$asset_index <- factor(sandfly$asset_index)   #Factor because is a categorical variable}\n  #we don't need to relevel\n  #table (sandfly$asset_index, useNA=\"always\")          #To explore the frequency and missing values\n  lm7 = lm(log_parg ~ asset_index, data = sandfly)     #Simple linear regression (bivariate)\n  summary(lm7)\n\n\nCall:\nlm(formula = log_parg ~ asset_index, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5065 -0.7242  0.0206  0.7371  3.2189 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   3.50646    0.10664  32.882  < 2e-16 ***\nasset_index2  0.03697    0.16667   0.222   0.8245    \nasset_index3 -0.33546    0.15196  -2.208   0.0278 *  \nasset_index4 -0.30015    0.15276  -1.965   0.0500 .  \nasset_index5 -0.70187    0.14556  -4.822 1.92e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.072 on 477 degrees of freedom\n  (18 observations deleted due to missingness)\nMultiple R-squared:  0.06171,   Adjusted R-squared:  0.05384 \nF-statistic: 7.843 on 4 and 477 DF,  p-value: 3.968e-06\n\n\n3.8 House_type\n\n  #Already a character (categorical) variable no need to factor\n  #table(sandfly$house_type, useNA=\"always\")             #To explore the frequency and missing values\n  lm8 = lm(log_parg ~ house_type, data = sandfly)       #Simple linear regression (bivariate)\n  summary(lm8)\n\n\nCall:\nlm(formula = log_parg ~ house_type, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1259 -0.6913 -0.0121  0.6752  3.2067 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              2.88012    0.12215  23.578  < 2e-16 ***\nhouse_typepbrick_efloor  0.02238    0.15798   0.142    0.887    \nhouse_typethatched       0.83198    0.14821   5.614  3.3e-08 ***\nhouse_typeupbrick        0.24579    0.14994   1.639    0.102    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.065 on 496 degrees of freedom\nMultiple R-squared:  0.09706,   Adjusted R-squared:  0.0916 \nF-statistic: 17.77 on 3 and 496 DF,  p-value: 5.686e-11\n\n\n3.9 Completing the requested table and checking witch models has a p value higher than 0.10\n We do this checking all the results above \n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\n\n\n\n\n\nFactor\nNumber (%)\nCoefficient\np-value\n\n\n\n\nAnimals in the house\n20 (4.0)\n0.81\n0.001\n\n\nTraditional stove\n19 (3.8)\n0.24\n0.35\n\n\nVentilation\n193 (38.6)\n-0.43\n<0.001\n\n\nAdequate light\n171 (34.2)\n-0.01\n0.92\n\n\nCow dung\n485 (97.0)\n0.50\n0.09\n\n\nWater body\n98 (19.6)\n0.13\n0.29\n\n\nAsset index*\n\n\n\n\n\n—–1 (poorest)\n101 (21.0)\nref\nref\n\n\n—–2\n70 (14.5)\n0.04\n0.82\n\n\n—–3\n98 (20.3)\n-0.34\n0.03\n\n\n—–4\n96 (19.9)\n-0.30\n0.05\n\n\n—–5 (wealthiest)\n117 (24.3)\n-0.70\n<0.001\n\n\n—–Missing\n18\n\n\n\n\nHouse type\n\n\n\n\n\n—–Plastered brick, cemented floor\n76 (15.2)\nref\nref\n\n\n—–Thatched\n161 (32.2)\n0.83\n<0.001\n\n\n—–Unplastered brick\n150 (30.0)\n0.25\n0.10\n\n\n—–Plastered brick, earth floor\n113 (22.6)\n0.02\n0.89\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThere are 3 models that have a p value higher than 0.10 (the ones in red) Those variables are not going to enter to the final model\n\n\n\n\n4. Construct a multiple linear regresion with all variables that were significant. Which variables will you include?\n We will incude those who obtained a p value less than 0.10: animals, ventilation, cowdung, asset index and house_type. The regresion model is: \n\nlm9 = lm(log_parg ~ animals + ventilation + cowdung + asset_index + house_type, data = sandfly)\nsummary(lm9)\n\n\nCall:\nlm(formula = log_parg ~ animals + ventilation + cowdung + asset_index + \n    house_type, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.2528 -0.6406 -0.0122  0.7067  3.2542 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              3.03255    0.31616   9.592  < 2e-16 ***\nanimals1                 0.54503    0.24444   2.230  0.02624 *  \nventilation1            -0.14492    0.10974  -1.321  0.18728    \ncowdung1                 0.17978    0.28358   0.634  0.52641    \nasset_index2             0.12385    0.16411   0.755  0.45082    \nasset_index3            -0.20495    0.14927  -1.373  0.17040    \nasset_index4            -0.13879    0.15207  -0.913  0.36187    \nasset_index5            -0.33856    0.16225  -2.087  0.03746 *  \nhouse_typepbrick_efloor -0.02115    0.16290  -0.130  0.89678    \nhouse_typethatched       0.51342    0.17465   2.940  0.00345 ** \nhouse_typeupbrick        0.04044    0.16383   0.247  0.80514    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.04 on 471 degrees of freedom\n  (18 observations deleted due to missingness)\nMultiple R-squared:  0.1274,    Adjusted R-squared:  0.1089 \nF-statistic: 6.876 on 10 and 471 DF,  p-value: 4.592e-10\n\n\n\n\n5. Which is the weaksest factor (highest p-value) and how high is its p-value?\n\n\n\n\n\n\nNote\n\n\n\nCowndown (has the higher pvalue 0.52641)\nClarification: If we see the previous results, In fact the one with the highest p-value is one category of house_type (brick_efloor: 0.89678). But because there are other categories of the same variable that are significant (has p value less than 0.05), we cannot eliminate that variable.\n\n\n\n\n6. Remove ‘cowdung’, which is now the weakest factor and what is its p-value?\n So the next model is: \n\nlm10 = lm(log_parg ~ animals + ventilation + asset_index + house_type, data = sandfly)\nsummary(lm10)\n\n\nCall:\nlm(formula = log_parg ~ animals + ventilation + asset_index + \n    house_type, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.2535 -0.6438 -0.0135  0.6956  3.2634 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              3.195702   0.183532  17.412  < 2e-16 ***\nanimals1                 0.539125   0.244108   2.209  0.02769 *  \nventilation1            -0.151368   0.109200  -1.386  0.16636    \nasset_index2             0.124507   0.163999   0.759  0.44812    \nasset_index3            -0.208963   0.149044  -1.402  0.16157    \nasset_index4            -0.135136   0.151862  -0.890  0.37399    \nasset_index5            -0.342134   0.162053  -2.111  0.03528 *  \nhouse_typepbrick_efloor -0.004478   0.160663  -0.028  0.97778    \nhouse_typethatched       0.530562   0.172439   3.077  0.00221 ** \nhouse_typeupbrick        0.057824   0.161416   0.358  0.72033    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.039 on 472 degrees of freedom\n  (18 observations deleted due to missingness)\nMultiple R-squared:  0.1266,    Adjusted R-squared:   0.11 \nF-statistic: 7.605 on 9 and 472 DF,  p-value: 1.904e-10\n\n\n\n\n\n\n\n\nNote\n\n\n\nVentilation (has now the higher pvalue 0.16636)\nClarification: If we see the previous results, in fact are others with a highest p-value (ej: asset_index2 or house_typepbrick_efloor). But because there are other categories of the same variable that are significant (has p value less than 0.05, we cannot eliminate that variable.\n\n\n\n\n7. Remove ‘ventilation’. Is there still another factor of which no category is significant at the 5% level ? Which factors do you keep in your final model?\n So the new model is: \n\nlm11 = lm(log_parg ~ animals + asset_index + house_type, data = sandfly)\nsummary(lm11)\n\n\nCall:\nlm(formula = log_parg ~ animals + asset_index + house_type, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.2045 -0.6371 -0.0027  0.6814  3.2001 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              3.129930   0.177465  17.637  < 2e-16 ***\nanimals1                 0.505096   0.243107   2.078 0.038279 *  \nasset_index2             0.114276   0.163992   0.697 0.486246    \nasset_index3            -0.215243   0.149120  -1.443 0.149563    \nasset_index4            -0.137779   0.151997  -0.906 0.365156    \nasset_index5            -0.381083   0.159754  -2.385 0.017451 *  \nhouse_typepbrick_efloor -0.006961   0.160810  -0.043 0.965490    \nhouse_typethatched       0.586305   0.167848   3.493 0.000522 ***\nhouse_typeupbrick        0.074528   0.161122   0.463 0.643897    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.04 on 473 degrees of freedom\n  (18 observations deleted due to missingness)\nMultiple R-squared:  0.1231,    Adjusted R-squared:  0.1083 \nF-statistic: 8.299 on 8 and 473 DF,  p-value: 1.493e-10\n\n\n\n\n\n\n\n\nNote\n\n\n\nAll have at least one category with a p-value < 0.05, So there is not another factor no significant and I dont have to exclude another variable\nSo, This factors are the ones who are going to stay in the final model: House_type, asset_index and animals.\n\n\n\n\n8. To test for interactions generate the following binary variables:\n - rich, ‘yes’ if asset_index = 5, ‘no’ if asset-index = 1-4 (beware of missing values!) \n - thatched, ‘yes’ if house_type = ‘thatched, else ’no’\n Run the model with ‘animals’, ‘rich’ and ‘thatched’ as predictors, note down the equation. Are all three factors statistically significant? \n8.1 Creating the variable Rich\n\n#Variable Rich\n      #table(sandfly$asset_index, useNA = \"always\")\n      sandfly$rich <- ifelse(sandfly$asset_index==5,1,0)\n        table(sandfly$rich, useNA = \"always\")\n\n\n   0    1 <NA> \n 365  117   18 \n\n\n8.2 Creating the variable thatched\n\n#Variable thatched\n      #table(sandfly$house_type, useNA = \"always\")\n      sandfly$thatched <- ifelse(sandfly$house_type==\"thatched\",1,0)\n        table(sandfly$thatched, useNA = \"always\")\n\n\n   0    1 <NA> \n 339  161    0 \n\n\n8.3 With this variables, the regresion model is:\n\n  mod12 <- lm(log_parg ~ animals+rich+thatched, data=sandfly)\n  summary(mod12)\n\n\nCall:\nlm(formula = log_parg ~ animals + rich + thatched, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1078 -0.6820  0.0068  0.6770  3.2620 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.08869    0.06985  44.217  < 2e-16 ***\nanimals1     0.55419    0.24126   2.297  0.02205 *  \nrich        -0.32729    0.11664  -2.806  0.00522 ** \nthatched     0.56358    0.10836   5.201 2.95e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.041 on 478 degrees of freedom\n  (18 observations deleted due to missingness)\nMultiple R-squared:  0.1128,    Adjusted R-squared:  0.1072 \nF-statistic: 20.25 on 3 and 478 DF,  p-value: 2.277e-12\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe can see that all variables are still significant The equation of this model is: log_parg = 3.09 + 0.55* animals – 0.33* rich + 0.56* thatched\n\n\n\n\n9. Theoretically there could be interactions between rich and thatched, rich and animals and animals and thatched. Is any of these interaction terms statistically significant?\n Check for Possible interactions (pairs)\nmod13 <- lm(log_parg ~ animals+rich*thatched, data=sandfly)\nmod14 <- lm(log_parg ~ rich+thatched*animals, data=sandfly)\nmod15 <- lm(log_parg ~ animals*rich+thatched, data=sandfly)\n\nmod13 <- lm(log_parg ~ animals+rich*thatched, data=sandfly)\nsummary(mod13)\n\n\nCall:\nlm(formula = log_parg ~ animals + rich * thatched, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1053 -0.6899 -0.0030  0.6862  3.2730 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    3.09408    0.07087  43.659  < 2e-16 ***\nanimals1       0.56026    0.24181   2.317  0.02093 *  \nrich          -0.34365    0.12195  -2.818  0.00503 ** \nthatched       0.54954    0.11259   4.881 1.44e-06 ***\nrich:thatched  0.19563    0.42168   0.464  0.64291    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.042 on 477 degrees of freedom\n  (18 observations deleted due to missingness)\nMultiple R-squared:  0.1132,    Adjusted R-squared:  0.1057 \nF-statistic: 15.22 on 4 and 477 DF,  p-value: 1.019e-11\n\nmod14 <- lm(log_parg ~ rich+thatched*animals, data=sandfly)\nsummary(mod14)\n\n\nCall:\nlm(formula = log_parg ~ rich + thatched * animals, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0775 -0.6796 -0.0034  0.6854  3.2755 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        3.07750    0.06994  43.999  < 2e-16 ***\nrich              -0.32953    0.11636  -2.832  0.00482 ** \nthatched           0.60208    0.11010   5.469 7.33e-08 ***\nanimals1           1.20517    0.42790   2.817  0.00506 ** \nthatched:animals1 -0.95217    0.51750  -1.840  0.06640 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.038 on 477 degrees of freedom\n  (18 observations deleted due to missingness)\nMultiple R-squared:  0.119, Adjusted R-squared:  0.1116 \nF-statistic: 16.11 on 4 and 477 DF,  p-value: 2.206e-12\n\nmod15 <- lm(log_parg ~ animals*rich+thatched, data=sandfly)\nsummary(mod15)\n\n\nCall:\nlm(formula = log_parg ~ animals * rich + thatched, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0898 -0.6869  0.0029  0.6843  3.2723 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    3.08981    0.06989  44.210  < 2e-16 ***\nanimals1       0.48546    0.25532   1.901  0.05785 .  \nrich          -0.33865    0.11749  -2.882  0.00413 ** \nthatched       0.56918    0.10861   5.241 2.41e-07 ***\nanimals1:rich  0.64829    0.78580   0.825  0.40978    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.041 on 477 degrees of freedom\n  (18 observations deleted due to missingness)\nMultiple R-squared:  0.114, Adjusted R-squared:  0.1066 \nF-statistic: 15.35 on 4 and 477 DF,  p-value: 8.137e-12\n\n\n\n\n\n\n\n\nNote\n\n\n\nNone of them are statistically significant. So this models are not good\n  - rich*thatched       p= 0.64\n  - thatched*animals    p = 0.07\n  - animals*rich        p = 0.41\nClarification: To see if some model is better than another, we should perform a F test (anova table), but it will not be done in this exercise\n\n\n\n\n10. As our final model we keep the model with type of house, asset-index and presence of animals. Please make a table presenting this final model.\n They are talking about lm11 = lm(log_parg ~ animals + asset_index + house_type, data = sandfly) \n\nlm11 = lm(log_parg ~ animals + asset_index + house_type, data = sandfly)\nsummary(lm11)\n\n\nCall:\nlm(formula = log_parg ~ animals + asset_index + house_type, data = sandfly)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.2045 -0.6371 -0.0027  0.6814  3.2001 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              3.129930   0.177465  17.637  < 2e-16 ***\nanimals1                 0.505096   0.243107   2.078 0.038279 *  \nasset_index2             0.114276   0.163992   0.697 0.486246    \nasset_index3            -0.215243   0.149120  -1.443 0.149563    \nasset_index4            -0.137779   0.151997  -0.906 0.365156    \nasset_index5            -0.381083   0.159754  -2.385 0.017451 *  \nhouse_typepbrick_efloor -0.006961   0.160810  -0.043 0.965490    \nhouse_typethatched       0.586305   0.167848   3.493 0.000522 ***\nhouse_typeupbrick        0.074528   0.161122   0.463 0.643897    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.04 on 473 degrees of freedom\n  (18 observations deleted due to missingness)\nMultiple R-squared:  0.1231,    Adjusted R-squared:  0.1083 \nF-statistic: 8.299 on 8 and 473 DF,  p-value: 1.493e-10\n\n\n\n\n\n\n\n\nNote\n\n\n\n  Intercept: 3.129930   \n  R2 : 0.1231\n  P-value of the model: 1.493e-10 (less than 0.05)\n\n\n10.1 The table should be like this:\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nFactor\nCoefficient\np-value\n\n\n\n\nAnimals in the house\n0.51\n0.04\n\n\nAsset index\n\n\n\n\n-1 (poorest)\nref\nref\n\n\n-2\n0.11\n0.49\n\n\n-3\n-0.22\n0.15\n\n\n-4\n-0.14\n0.37\n\n\n-5 (wealthiest)\n-0.38\n0.02\n\n\nHouse type\n\n\n\n\n-Thatched\n0.59\n0.0005\n\n\n-Unplastered brick\n0.07\n0.64\n\n\n-Plastered brick earth floor\n-0.007\n0.97\n\n\n-Plastered brick cemented floor\nref\nref\n\n\n\n\n\n\n\n11. How much of the variability in sand fly exposure is explained by the three factors retained? What would be your conclusion about exposure to sand flies in this rural area.\n\n\n\n\n\n\nNote\n\n\n\nR squared = 0.1231, so the model explains only 12% of the total variability.\n- Being rich and living in a good house (Plastered brick earth floor or cemented\n  floor) reduces outcome, but far from being factors that play an important role.\n- Could be other factors that play a role. \n\n\n\n\n12. What is the predicted total number of sandflies in a thatched house with animals inside of a family belonging to the poorest quintile? And in a plastered brick house with cemented floor without animals and belonging to the wealthiest quintile?\n12.1 For the first condition:\n\n\n\n\n\n\nNote\n\n\n\nSo the conditions are:\n- Animals in the hous: Yes\n- House type: thatched house\n- Assest index: 1 (poorest)\nSo the equation for lm11 should be\n  y = a + b1X1 + b2x2 + b3x3\n  y = a + b1(animals) + b2(assest_index) + b3 (house_type)\n  y = 3.129930 + 0.51(animals) + 0(assest_index:poorest) + 0.59(house_type:thatched)\n  y = 3.13     + 0.51(1)       + 0                       + 0.59(1)\nlog_parg = 4.23\n  #The \"log of parg\" is 4.23, but I need the value of parg\nexp(log_parg) = exp(4.23)\nparg = 69\n  #parg is 69 with this conditions\n\n\n12.2 For the second condition:\n\n\n\n\n\n\nNote\n\n\n\nSo the conditions are:\n- Animals in the house: No\n- House type: Plastered brick cemented floor\n- Assest index: 5 (wealthiest)\nSo the equation for lm11 should be\n  y = a + b1X1 + b2x2 + b3x3\n  y = a + b1(animals) + b2(assest_index) + b3 (house_type)\n  y = 3.129930 + 0.51(animals) -0.38(wealthiest) + 0(Plastered brick cemented floor)\n  y = 3.13     + 0.51(0)       -0.38(1)          + 0\nlog_parg = 2.75\n  #The \"log of parg\" is 2.75 , but I need the value of parg\nexp(log_parg) = exp(2.75)\nparg = 16\n  #parg is 16 with this conditions\n\n\n\n\n\n\nExtra\n\n\n\n\n\n\nNote\n\n\n\nIf we want to really check witch model is best than another (like in the step 9), we need to do a f test - anova function and see the p value:\nanova(lm11, mod13)\nBut an error may show. When one of the variables that are in one model have missing values, R eliminate those rows when doing the model. So then if we want to compare, the models might not have the same number of rows and the test will fail.\nFor this is better to work with a subset of the data with no missing data in all the variables:\nSo if I know that asset_index has missing value, then:\nsandfly_complete <- subset(sandfly, !is.na(sandfly$asset_index))\nor\nsandfly_complete <- subset(sandfly, complete.cases(sandfly))"
  },
  {
    "objectID": "2023-02-06 Logistic Regresion, Sessión 1.html",
    "href": "2023-02-06 Logistic Regresion, Sessión 1.html",
    "title": "2023-02-06 Sessión 1",
    "section": "",
    "text": "Instituut Voor Tropische Geneeskunde - Antwerp, Belgium\nJavier Silva-Valencia"
  },
  {
    "objectID": "2023-02-06 Logistic Regresion, Sessión 1.html#step-by-step---selection-of-variables-for-modeling",
    "href": "2023-02-06 Logistic Regresion, Sessión 1.html#step-by-step---selection-of-variables-for-modeling",
    "title": "2023-02-06 Sessión 1",
    "section": "Step by Step - Selection of variables for modeling",
    "text": "Step by Step - Selection of variables for modeling\n\nImport data\nImporting a CSV database under the name of “onch1302”, with “,” as separator:\n\nonch1302 <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2/Logistic Regresion Exercise Database/Datasets/onch1302.csv\", sep=\",\")\n\n\n\n\n\nStarting the Exercise (MVA_LogReg_Ex1-2023):\n Onchocerciasis (commonly known as River Blindness) is a chronic filarial disease found in sub-Saharan Africa and some parts of Central and South America. An onchocerciasis project was set up in 1982 in the Bo district of Sierra Leone. The aims of the project were to study epidemiological, clin-ical, immunological and entomological aspects of the disease. Prevalence surveys were undertaken in villages selected on the basis of potential high endemicity, being situated on or near rivers which are the breeding sites for the Simulium damnosum blackfly. Of the twelve villages included in the present dataset, five were situated in the south and east of the country in the forest' zone and the other seven were in thesavannah’ zone of the country. A census was taken of each village, and all villagers over the age of five years were asked to participate in the study. Coverage was over 90% in all but one of the selected villages. Diagnosis was made by taking a skin-snip, and clinical and an ocular examination were also performed. The file ONCH1302 contains data for all 1,302 subjects. \n\n1. To make the naming a bit more logical, copy the ‘sex’ variable into a new variable called ‘female’ and the ‘area’ variable into one called ‘forest’. For ‘mf’ and ‘lesions’ you may use the variables as is. Next, recode variables with more than 2 levels (‘agegrp’ and ‘mfload’) to binary variables. For ‘agegrp’ use ‘adult’ and code as ‘TRUE’ for those aged 20 and older, ‘FALSE’ for those under 20 years of age. For ‘mfload’ you can recode to ‘highload’ taking values 0 and 1 together as ‘FALSE’ and values 2 and 3 together as ’TRUE\nCreating the new variables (as a copy)\n\nonch1302$female <- onch1302$sex\nonch1302$forest <- onch1302$area\n\nRecoding the variables with more than 2 levels into binary variables\n\n#Adult variable (adult=1, non adult=0)\n  onch1302$adult <- ifelse(onch1302$agegrp>1,1,0)\n\n#Highload (False = 0, True=1)\n  #table(onch1302$mfload, useNA = \"always\")\n  onch1302$highload <- 0\n  onch1302$highload[onch1302$mfload==2] <- 1\n  onch1302$highload[onch1302$mfload==3] <- 1\n\n\n\n2. Get an overview of the data by univariable analysis. Construct a table showing numbers and frequencies of each of the variables\n\ntable(onch1302$lesions, useNA = \"always\")     #frecuency\n\n\n   0    1 <NA> \n1101  201    0 \n\nprop.table(table(onch1302$lesions))           #proportion\n\n\n        0         1 \n0.8456221 0.1543779 \n\ntable(onch1302$female, useNA = \"always\")     #frecuency\n\n\n   0    1 <NA> \n 616  686    0 \n\nprop.table(table(onch1302$female))           #proportion\n\n\n        0         1 \n0.4731183 0.5268817 \n\n#Forest\ntable(onch1302$forest, useNA = \"always\")     #frecuency\n\n\n   0    1 <NA> \n 548  754    0 \n\nprop.table(table(onch1302$forest))           #proportion\n\n\n        0         1 \n0.4208909 0.5791091 \n\n#Highload\ntable(onch1302$highload, useNA = \"always\")     #frecuency\n\n\n   0    1 <NA> \n 847  455    0 \n\nprop.table(table(onch1302$highload))           #proportion\n\n\n        0         1 \n0.6505376 0.3494624 \n\n#Adult\ntable(onch1302$adult, useNA = \"always\")     #frecuency\n\n\n   0    1 <NA> \n 420  882    0 \n\nprop.table(table(onch1302$adult))           #proportion\n\n\n        0         1 \n0.3225806 0.6774194 \n\n#Microfilaria\ntable(onch1302$mf, useNA = \"always\")     #frecuency\n\n\n   0    1 <NA> \n 480  822    0 \n\nprop.table(table(onch1302$mf))           #proportion\n\n\n        0         1 \n0.3686636 0.6313364 \n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nFactor\nN\n\n\n\n\nFemale gender\n686 (52.7)\n\n\nAdult age\n882 (67.7)\n\n\nLiving in Forest\n754 (57.9)\n\n\nMicro filaria infected\n822 (63.1)\n\n\nHigh micro-filarial load\n455 (34.9)\n\n\nEyes affected (lesions)\n201 (15.4)\n\n\n\n\n\n\n\n3. Make three 2x2 tables to explore the association between mf infection and the three exposures, ‘female’, ‘adult’ and ‘forest’ and manually compute the odds ratios between exposed and unex-posed\n We can do that directly with “cc” command from the EpiStat library. If EpiStat doesnt work you can do it manually with “table” command and a calculator \n\nlibrary(EpiStats)\n\n\ncc(onch1302, mf,female)\n\n$df1\n                   Cases Controls Total\nExposed              396      290   686\nUnexposed            426      190   616\nTotal                822      480  1302\nProportion exposed  0.48     0.60  0.53\n\n$df2\n                Point estimate 95%CI-ll 95%CI-ul\nOdds ratio                0.61     0.48     0.77\nPrev. frac. ex.           0.39     0.23     0.52\nPrev. frac. pop           0.24       NA       NA\nchi2(1)                  18.22       NA       NA\nPr>chi2                  0.000       NA       NA\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\nMicro filaria infected\n\n\n\n\n\nGender\nYes\nNo\n\n\nFemale\n396\n290\n\n\nMale\n426\n190\n\n\n\nOR (female) = 0.61 (0.48-0.77) p value = 0.0001\n\n\n\ncc(onch1302, mf,adult)\n\n$df1\n                   Cases Controls Total\nExposed              677      205   882\nUnexposed            145      275   420\nTotal                822      480  1302\nProportion exposed  0.82     0.43  0.68\n\n$df2\n                Point estimate 95%CI-ll 95%CI-ul\nOdds ratio                6.26     4.82     8.15\nAttr. frac. ex.           0.84     0.79     0.88\nAttr. frac. pop           0.69       NA       NA\nchi2(1)                 218.04       NA       NA\nPr>chi2                  0.000       NA       NA\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\nMicro filaria infected\n\n\n\n\n\nAge\nYes\nNo\n\n\n20+\n677\n205\n\n\n1-19\n145\n275\n\n\n\nOR (female) = 6.26 (4.82-8.15) p value = 0.0001\n\n\n\ncc(onch1302, mf,forest)\n\n$df1\n                   Cases Controls Total\nExposed              541      213   754\nUnexposed            281      267   548\nTotal                822      480  1302\nProportion exposed  0.66     0.44  0.58\n\n$df2\n                Point estimate 95%CI-ll 95%CI-ul\nOdds ratio                2.41     1.90     3.06\nAttr. frac. ex.           0.59     0.47     0.67\nAttr. frac. pop           0.39       NA       NA\nchi2(1)                  57.15       NA       NA\nPr>chi2                  0.000       NA       NA\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\nMicro filaria infected\n\n\n\n\n\nResidence\nYes\nNo\n\n\nForest\n541\n213\n\n\nSavanna\n281\n261\n\n\n\nOR (female) = 2.41 (1.90-3.06) p value = 0.0001\n\n\n\n\n4. As a next step, use the ‘cc’ command from the ‘Epistats’ package to confirmm the associations between ‘mf’ and exposures ‘female’, ‘adult’ and ‘forest’ and add the 95% confidence intervals. Are these associations statistically significant? Who are more at risk, men or women?\n\n\n\n\n\n\nNote\n\n\n\nWe did this in the previous step.\n\n\n\n\nNumber (%)\nOR (95% CI)\n\n\n\n\nFemale\n686 (52.7)\n0.6 (0.5-0.8)\n\n\nAdult age\n883 (67.7)\n6.3 (4.8-8.2)\n\n\nForest\n754 (57.9)\n2.4 (1.9-3.1)\n\n\n\nAll bivariate associations are significant\n\n\n\n\n5. Now compare results from table-based analyses with results from logistic regression. Are they consistent? For each of the three models note the OR and it’s 95% CI\n Now we are going to calculate the OR again but with the logistic regression \n5.1. mf and female\n\nGLM1 <- glm(mf ~ female, family=binomial, data=onch1302)\n  summary(GLM1)                   # To see the results of the logistic regression\n\n\nCall:\nglm(formula = mf ~ female, family = binomial, data = onch1302)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.5338  -1.3122   0.8589   1.0483   1.0483  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.80742    0.08724   9.255  < 2e-16 ***\nfemale      -0.49588    0.11655  -4.255 2.09e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1714.1  on 1301  degrees of freedom\nResidual deviance: 1695.7  on 1300  degrees of freedom\nAIC: 1699.7\n\nNumber of Fisher Scoring iterations: 4\n\n  exp(coef(GLM1))                 # To calculate the OR\n\n(Intercept)      female \n  2.2421053   0.6090335 \n\n  exp(confint(GLM1))              # To calculate the confidence intervarl of the OR\n\nWaiting for profiling to be done...\n\n\n                2.5 %    97.5 %\n(Intercept) 1.8930554 2.6654704\nfemale      0.4842344 0.7647899\n\n\n5.2. mf and adult\n\nGLM2 <- glm(mf ~ adult, family=binomial, data=onch1302)\n  summary(GLM2)                   # To see the results of the logistic regression\n\n\nCall:\nglm(formula = mf ~ adult, family = binomial, data = onch1302)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.7083  -0.9203   0.7274   0.7274   1.4584  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -0.6400     0.1026  -6.236 4.48e-10 ***\nadult         1.8347     0.1300  14.118  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1714.1  on 1301  degrees of freedom\nResidual deviance: 1497.8  on 1300  degrees of freedom\nAIC: 1501.8\n\nNumber of Fisher Scoring iterations: 4\n\n  exp(coef(GLM2))                 # To calculate the OR\n\n(Intercept)       adult \n  0.5272727   6.2632464 \n\n  exp(confint(GLM2))              # To calculate the confidence intervarl of the OR\n\nWaiting for profiling to be done...\n\n\n                2.5 %    97.5 %\n(Intercept) 0.4302207 0.6435193\nadult       4.8647343 8.0981555\n\n\n5.3. mf and forest\n\nGLM3 <- glm(mf ~ forest, family=binomial, data=onch1302)\n  summary(GLM3)                   # To see the results of the logistic regression\n\n\nCall:\nglm(formula = mf ~ forest, family = binomial, data = onch1302)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.5900  -1.1992   0.8148   0.8148   1.1558  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.05111    0.08546   0.598     0.55    \nforest       0.88102    0.11767   7.487 7.05e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1714.1  on 1301  degrees of freedom\nResidual deviance: 1657.0  on 1300  degrees of freedom\nAIC: 1661\n\nNumber of Fisher Scoring iterations: 4\n\n  exp(coef(GLM3))                 # To calculate the OR\n\n(Intercept)      forest \n   1.052434    2.413363 \n\n  exp(confint(GLM3))              # To calculate the confidence intervarl of the OR\n\nWaiting for profiling to be done...\n\n\n                2.5 %   97.5 %\n(Intercept) 0.8901384 1.244620\nforest      1.9176644 3.042055\n\n\n\n\n\n\n\n\nNote\n\n\n\nYes, the OR calculated with logistic regresion it is consistent with the OR calculated in step 4\n\n\n\n\nNumber (%)\nOR (95% CI)\n\n\n\n\nFemale\n686 (52.7)\n0.6 (0.5-0.8)\n\n\nAdult age\n883 (67.7)\n6.3 (4.8-8.2)\n\n\nForest\n754 (57.9)\n2.4 (1.9-3.1)\n\n\n\n\n\n\n\n6. The only exposure that we could do something about in an intervention is ‘living in the forest’, do you think age or gender could be confounders in the association between ‘living in the forest’ and being infected with micro filaria?\n\n\n\n\n\n\nNote\n\n\n\nYes it could be confounders.\nClarification:\nTo being counfunders has to fulfill 3 conditions:\n1. Has to be related to the VI, 2. TO be related to the VD, and 3. Not be in the causal pathway\n            \n            (Microfilaria Infection) ----- (living forest)\n                                 \\           /\n                                  Confounders\n                                 (Age or gender)\n                                 \nIf it is permant residence, then probably age or gender cannot affect the residence\nBut in this case it doesn't say anything.\n\nIf adult men spend part of the year in the forest for professional reasons, \nboth age and gender could be associated with living in forest and with having microfilaria infect.\n\nAlso age or gender do not seem to be in the causar pathway\n\n\n\n\n7. Use ‘CCInter’ from the ‘Epistats’ package to test for confounding. Is there confounding or inter-action in the association between ‘mf’ and ‘forest’ by either ‘female’ or ‘adult’?\n7.1 Confounding: being female\n\n\nCCInter(onch1302, \"mf\", \"forest\", \"female\") \n\n$df1\n   CCInter mf - forest by(female) Cases Controls          P.est. Stats 95%CI-ll\n1                      female = 1  <NA>     <NA>      Odds ratio  2.87     2.07\n2                         Exposed   265      120 Attrib.risk.exp  0.65     0.52\n3                       Unexposed   131      170 Attrib.risk.pop  0.44     <NA>\n4                           Total   396      290                  <NA>     <NA>\n5                       Exposed % 66.9%    41.4%                  <NA>     <NA>\n6                  ______________  <NA>     <NA>                  <NA>     <NA>\n7                      female = 0  <NA>     <NA>      Odds ratio  1.92     1.34\n8                         Exposed   276       93 Attrib.risk.exp  0.48     0.25\n9                       Unexposed   150       97 Attrib.risk.pop  0.31     <NA>\n10                          Total   426      190                  <NA>     <NA>\n11                      Exposed % 64.8%    48.9%                  <NA>     <NA>\n12                 ______________  <NA>     <NA>                  <NA>     <NA>\n13                  Number of obs  1302     <NA>            <NA>  <NA>     <NA>\n14                        Missing     0     <NA>            <NA>  <NA>     <NA>\n   95%CI-ul\n1      3.97\n2      0.75\n3      <NA>\n4      <NA>\n5      <NA>\n6      <NA>\n7      2.76\n8      0.64\n9      <NA>\n10     <NA>\n11     <NA>\n12     <NA>\n13     <NA>\n14     <NA>\n\n$df2\n                        P.estimate Stats 95%CI-ll 95%CI-ul\n1 MH test of Homogeneity (p-value)  0.09                  \n2              Crude OR for forest  2.41     1.90     3.06\n3 MH OR forest adjusted for female  2.40     1.90     3.02\n4   Adjusted/crude relative change -0.75        _        _\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSteps for check for confounding\n  1.Check for the wolf test (homogeneity test) if pvalue higher than 0.05,\n  means no interaction (no effect modifier) and that could be a confounding\n  \n  2. If is not interaction, then check for the change between OR crude and OR adjusted, \n  if that relative change is higher than 10%, it is a confounding\n  \nSo, with the results:\n  1. The Homogeneity test had a p value of 0.09 (higher than 0.05)\n  means no interaction and that could be a confounding\n  \n  2. Then, the OR crude is 2.41 and the OR adjusted 2.40. \n  Also the relative change is -0.75\n  So sex  is not a confounding\n\n\n7.2 Confounding: being adult\n\n\nCCInter(onch1302, \"mf\", \"forest\", \"adult\") \n\n$df1\n   CCInter mf - forest by(adult) Cases Controls          P.est. Stats 95%CI-ll\n1                      adult = 1  <NA>     <NA>      Odds ratio  3.85     2.72\n2                        Exposed   434       65 Attrib.risk.exp  0.74     0.63\n3                      Unexposed   243      140 Attrib.risk.pop  0.47     <NA>\n4                          Total   677      205                  <NA>     <NA>\n5                      Exposed % 64.1%    31.7%                  <NA>     <NA>\n6                 ______________  <NA>     <NA>                  <NA>     <NA>\n7                      adult = 0  <NA>     <NA>      Odds ratio  2.42     1.53\n8                        Exposed   107      148 Attrib.risk.exp  0.59     0.34\n9                      Unexposed    38      127 Attrib.risk.pop  0.43     <NA>\n10                         Total   145      275                  <NA>     <NA>\n11                     Exposed % 73.8%    53.8%                  <NA>     <NA>\n12                ______________  <NA>     <NA>                  <NA>     <NA>\n13                 Number of obs  1302     <NA>            <NA>  <NA>     <NA>\n14                       Missing     0     <NA>            <NA>  <NA>     <NA>\n   95%CI-ul\n1      5.46\n2      0.82\n3      <NA>\n4      <NA>\n5      <NA>\n6      <NA>\n7      3.86\n8      0.74\n9      <NA>\n10     <NA>\n11     <NA>\n12     <NA>\n13     <NA>\n14     <NA>\n\n$df2\n                        P.estimate Stats 95%CI-ll 95%CI-ul\n1 MH test of Homogeneity (p-value)  0.10                  \n2              Crude OR for forest  2.41     1.90     3.06\n3  MH OR forest adjusted for adult  3.23     2.48     4.22\n4   Adjusted/crude relative change 34.04        _        _\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSo, with the results:\n  1. The Homogeneity test had a p value of 0.10 (higher than 0.05)\n  means no interaction and that could be a confounding\n  \n  2. Then, the OR crude is 2.41 and the OR adjusted 3.23 \n  Also the relative change is 34.04 (more than 10%)\n  So being adult is a confounding\n\n\n\n\n8. Does logistic regression confirm your findings on “adult” and “female” as potential confounders?\n8.1 Logistic regresion only with: mf and forest (bivariate)\n\nGLM4 <- glm(mf ~ forest, family=binomial, data=onch1302)\nexp(coef(GLM4))\n\n(Intercept)      forest \n   1.052434    2.413363 \n\n\n8.2 Logistic regresion with: mf and forest and female (multivariate)\n\nGLM5 <- glm(mf ~ forest + female, family=binomial, data=onch1302)\nexp(coef(GLM5))\n\n(Intercept)      forest      female \n  1.3739477   2.3967425   0.6165796 \n\n\n8.3 Logistic regresion with: mf and forest and adult (multivariate)\n\nGLM6 <- glm(mf ~ forest + adult, family=binomial, data=onch1302)\nexp(coef(GLM6))\n\n(Intercept)      forest       adult \n  0.2427931   3.2653865   7.6328965 \n\n\n8.4 Logistic regresion with: mf and forest and female and adult (multivariate)\n\nGLM7 <- glm(mf ~ forest + female + adult, family=binomial, data=onch1302)\nexp(coef(GLM7))\n\n(Intercept)      forest      female       adult \n  0.3313785   3.2577809   0.5342773   8.0289468 \n\n\n\n\n\n\n\n\nNote\n\n\n\nThe OR of forest in model GLM4 (only with: mf and forest) is\n  OR (crude) = 2.413363\n\n  Interpretation: The odds of having a microfilarial infection are 2.41 times as high for those \n  who reside in the forest compared to those in the savanna.\nThe OR for forest in model GLM5 (with mf and forest and female) is 2.3967425 This ise quite the same with GLM4, so it confirms that adding female do not cause changes, so female it is not a confounder of (mf ~ forest association)\n  Interpretation: The odds of having a microfilarial infection are 2.39 times as high for those \n  who reside in the forest compared to those in the savanna, if sex are held constant.\nThe OR for forest in model GLM6 (with mf and forest and adult) is 3.2653865 This OR is different from the GLM4, so it confirms that adding adult do cause changes, so being adult it is a confounder of (mf ~ forest association)\n  Interpretation: The odds of having a microfilarial infection are 3.27 times as high for those \n  who reside in the forest compared to those in the savanna, if age(being adult) \n  are held constant.\nThe OR for forest in model GLM7 (with mf and forest and female and adult) is 3.2577809 This is different from the GLM4, so it still confirms that one of the variables added caused changes,\nInterpretation: The odds of having a microfilarial infection are 3.26 times as high for those \nwho reside in the forest compared to those in the savanna, if sex and age are held constant.\n\n\n\n\n9. What happens if you add an additional term in the ‘CCInter’ command, e.g. if you type: ‘CCInter(Onch1302, “mf”,“forest”,“adult”,“female”)’?\n\nCCInter(onch1302, \"mf\", \"forest\", \"female\", \"adult\") \n\n$df1\n   CCInter mf - forest by(female) Cases Controls          P.est. Stats 95%CI-ll\n1                      female = 1  <NA>     <NA>      Odds ratio  2.87     2.07\n2                         Exposed   265      120 Attrib.risk.exp  0.65     0.52\n3                       Unexposed   131      170 Attrib.risk.pop  0.44     <NA>\n4                           Total   396      290                  <NA>     <NA>\n5                       Exposed % 66.9%    41.4%                  <NA>     <NA>\n6                  ______________  <NA>     <NA>                  <NA>     <NA>\n7                      female = 0  <NA>     <NA>      Odds ratio  1.92     1.34\n8                         Exposed   276       93 Attrib.risk.exp  0.48     0.25\n9                       Unexposed   150       97 Attrib.risk.pop  0.31     <NA>\n10                          Total   426      190                  <NA>     <NA>\n11                      Exposed % 64.8%    48.9%                  <NA>     <NA>\n12                 ______________  <NA>     <NA>                  <NA>     <NA>\n13                  Number of obs  1302     <NA>            <NA>  <NA>     <NA>\n14                        Missing     0     <NA>            <NA>  <NA>     <NA>\n   95%CI-ul\n1      3.97\n2      0.75\n3      <NA>\n4      <NA>\n5      <NA>\n6      <NA>\n7      2.76\n8      0.64\n9      <NA>\n10     <NA>\n11     <NA>\n12     <NA>\n13     <NA>\n14     <NA>\n\n$df2\n                        P.estimate Stats 95%CI-ll 95%CI-ul\n1 MH test of Homogeneity (p-value)  0.09                  \n2              Crude OR for forest  2.41     1.90     3.06\n3 MH OR forest adjusted for female  2.40     1.90     3.02\n4   Adjusted/crude relative change -0.75        _        _\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhat happened? Nothing. Only worked with female, doesn’t show anything about adults This command does not work for more than 1 independent variable\n\n\n\n\n10.Now try to fit a logistic regression model with ‘mf’ as outcome variable and ‘forest’, ‘adult’ and ‘female’ as predictors. What happens now to the odds ratio of ‘forest’ in comparison to the model with only ‘forest’ and ‘adult’ as predictors?\n\n\n\n\n\n\nNote\n\n\n\nWe already did this in step 8. They are asking for compare GLM7 with GLM6:\nThe OR for forest in model GLM6 (with mf and forest and adult) is 3.2653865\n  Interpretation: The odds of having a microfilarial infection are 3.27 times as high for those \n  who reside in the forest compared to those in the savanna, if age(being adult) \n  are held constant.\nThe OR for forest in model GLM7 (with mf and forest and female and adult) is 3.2577809\n  Interpretation: The odds of having a microfilarial infection are 3.26 times as high for those \n  who reside in the forest compared to those in the savanna, if sex and age are held constant.\nThere is a minimal change from 3.2577809 to 3.2653865. This is no surprise because we already knew that adding “female”, that is not a counfounder, so it was not going to cause change in the OR of forest.\nYet, the question still remains: for the final model will it be better to have sex or not? for this we have to compare both models with the likelihood ratio test. we will do it later\n\n\n\n\n11. Please check that the null deviance (the -2LLR of the null model) is 1714.1 on 1301 degrees of freedom. For the model with ‘forest’ and ‘adult’ it is 1416.7 on 1299 degrees of freedom. For the model with ‘forest’, ‘adult’ and ‘female’ it is 1394.1 on 1298 degrees of freedom. So the differ-ence between the last two models is 1416.7-1394.1, which is equal to 22.6, on 1299-1298, i.e. 1 degree of freedom. Is this a significant difference, please check a chi square table or in Excel (formula CHIDIST(22.6,1)?\n\nModel ‘forest’ and ‘adult’ is GLM6 (Check step 8.3)\n\n\nsummary (GLM6)\n\n\nCall:\nglm(formula = mf ~ forest + adult, family = binomial, data = onch1302)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.9765  -1.0805   0.5531   0.9290   1.8072  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -1.4155     0.1432  -9.884   <2e-16 ***\nforest        1.1834     0.1359   8.709   <2e-16 ***\nadult         2.0325     0.1402  14.499   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1714.1  on 1301  degrees of freedom\nResidual deviance: 1416.7  on 1299  degrees of freedom\nAIC: 1422.7\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor Model ‘forest’ and ‘adult’ (GLM6)\n  null deviance: 1714.1\n  Residual deviance: 1416.7   df: 1299\n\n\n\nModel ‘forest’, ‘adult’ and ‘female’ is GLM7 (Check step 8.4)\n\n\nsummary (GLM7)\n\n\nCall:\nglm(formula = mf ~ forest + female + adult, family = binomial, \n    data = onch1302)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1302  -0.9543   0.4673   0.7988   1.9465  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -1.1045     0.1564  -7.060 1.66e-12 ***\nforest        1.1810     0.1370   8.619  < 2e-16 ***\nfemale       -0.6268     0.1335  -4.696 2.65e-06 ***\nadult         2.0831     0.1427  14.594  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1714.1  on 1301  degrees of freedom\nResidual deviance: 1394.1  on 1298  degrees of freedom\nAIC: 1402.1\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor Model ‘forest’, ‘adult’ and ‘female’ (GLM7)\n  null deviance: 1714.1\n  Residual deviance: 1394.1     df: 1298\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the null deviance is the same for all the models (because the null deviance refers to a model without any factor)\nSo the differ-ence between the two models is\nResidual deviance 1416.7-1394.1 = 22.6, \nDegrees of freedom 1299-1298 = 1 \nIs this a significant difference, please check a chi square table or in Excel (formula CHIDIST(22.6,1)?\nWith the Chi square in excel we will obtain p=0.00002\nSo the difference between both models is highly significant.\n\n\n\n\n12. So apparently the model with the three terms, ‘forest’, ‘adult’ and ‘female’ is significantly better than the model with only ‘forest’ and ‘adult’. The easier way to check this is to do a likelihood ra-tio test in R. First run the complex model with three terms, then run the simple model with two terms and next use the anova() function to make the comparison.\n12.1 Fist the model with ‘forest’, ‘adult’ and ‘female’ (GLM7)\n\n#We will run again the Model ‘forest’, ‘adult’ and ‘female’ (GLM7)\nGLM7 <- glm(mf ~ forest + female + adult, family=binomial, data=onch1302)\nsummary (GLM7)\n\n\nCall:\nglm(formula = mf ~ forest + female + adult, family = binomial, \n    data = onch1302)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1302  -0.9543   0.4673   0.7988   1.9465  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -1.1045     0.1564  -7.060 1.66e-12 ***\nforest        1.1810     0.1370   8.619  < 2e-16 ***\nfemale       -0.6268     0.1335  -4.696 2.65e-06 ***\nadult         2.0831     0.1427  14.594  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1714.1  on 1301  degrees of freedom\nResidual deviance: 1394.1  on 1298  degrees of freedom\nAIC: 1402.1\n\nNumber of Fisher Scoring iterations: 4\n\n\n12.2 Then the model with ‘forest’ and ‘adult’ (GLM6)\n\n#Model ‘forest’ and ‘adult’\nGLM6 <- glm(mf ~ forest + adult, family=binomial, data=onch1302)\nsummary (GLM7)\n\n\nCall:\nglm(formula = mf ~ forest + female + adult, family = binomial, \n    data = onch1302)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1302  -0.9543   0.4673   0.7988   1.9465  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -1.1045     0.1564  -7.060 1.66e-12 ***\nforest        1.1810     0.1370   8.619  < 2e-16 ***\nfemale       -0.6268     0.1335  -4.696 2.65e-06 ***\nadult         2.0831     0.1427  14.594  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1714.1  on 1301  degrees of freedom\nResidual deviance: 1394.1  on 1298  degrees of freedom\nAIC: 1402.1\n\nNumber of Fisher Scoring iterations: 4\n\n\n12.3 Likelyhood ratio test: To check if adding female change the model significantly\n\nanova(GLM6, GLM7, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: mf ~ forest + adult\nModel 2: mf ~ forest + female + adult\n  Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    \n1      1299     1416.7                          \n2      1298     1394.1  1   22.562 2.035e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\nSo, according to the likelihood ratio test (anova) the p value is 2.035e-06 (less of 0.05) So adding sex(female) does generate a change in the model. Because of that we keep the more complex model.\nThe final model would be:\nGLM7 <- glm(mf ~ forest + female + adult, family=binomial, data=onch1302)"
  },
  {
    "objectID": "2023-02-07 Logistic Regresion, Sessión 2.html",
    "href": "2023-02-07 Logistic Regresion, Sessión 2.html",
    "title": "2023-02-07 Sessión 2",
    "section": "",
    "text": "Instituut Voor Tropische Geneeskunde - Antwerp, Belgium\nJavier Silva-Valencia"
  },
  {
    "objectID": "2023-02-07 Logistic Regresion, Sessión 2.html#step-by-step---selection-of-variables-for-modeling",
    "href": "2023-02-07 Logistic Regresion, Sessión 2.html#step-by-step---selection-of-variables-for-modeling",
    "title": "2023-02-07 Sessión 2",
    "section": "Step by Step - Selection of variables for modeling",
    "text": "Step by Step - Selection of variables for modeling\n\nImport data\nImporting a CSV database under the name of “mwanza”, with “,” as separator:\n\nmwanza <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2/Logistic Regresion Exercise Database/Datasets/mwanza.csv\", sep=\",\")\n\n\n\n\n\nStarting the Exercise (MVA_LogReg_Ex2-2023):\n Case control study of risk factors for HIV in women, Mwanza Tanzania: As part of a prospective study of the impact of STD control on the incidence of HIV infection in Mwanza, Tanzania, a baseline survey of HIV prevalence was carried out in 12 communities. All se-ropositive women (15 years and above) were revisited and, where possible) interviewed about poten-tial risk factors for HIV infection using a standard questionnaire. In addition to interviewing HIV +ve women, a random sample of HIV -ve women were selected from the population lists prepared during the baseline survey and these women were also revisited and, where possible, interviewed. No matching of controls with cases was performed \n The question which interests us most in this part of the exercise is whether and how education is associated with HIV infection\nSo the dependant variable is: HIV infection and main independent variable: education \n\n1. Explore how education and age are associated with HIV infection; the list of variables is present-ed overleaf. Transform ‘case’ into a factor variable with levels TRUE and FALSE, similarly cre-ate two factor variables, ‘age1_f’ and ‘ed_f’, based on ‘age1’ and ‘ed’ respectively.\n1.1 Creating the variables\n\n#Case variable (case TRUE=1, non Case FALSE=0)\n  #table(mwanza$case, useNA=\"always\")\n  mwanza$case <- factor(mwanza$case)\n\n#Age1 variable \n  #table(mwanza$age1, useNA=\"always\")\n  mwanza$age1_f <- factor(mwanza$age1, labels = c(\"15-19\",\"20-24\",\"25-29\",\"30-34\",\"35-44\",\"45-54\"))\n  #table(mwanza$age1_f, useNA=\"always\")\n#Ed1 variable \n  #table(mwanza$ed, useNA=\"always\")\n  mwanza$ed_f <- factor(mwanza$ed)\n\n1.2 Before doing anything, first is better to do bi-variates tables with the OR calculation for each independent variable\nBivariate table: VIH - Age group\n\ntable (mwanza$age1_f, mwanza$case)\n\n       \n          0   1\n  15-19  96  13\n  20-24 108  57\n  25-29  84  39\n  30-34  85  33\n  35-44 107  30\n  45-54  94  17\n\nprop.table(table (mwanza$age1_f, mwanza$case), margin=1)  #Porcentajes por fila\n\n       \n                0         1\n  15-19 0.8807339 0.1192661\n  20-24 0.6545455 0.3454545\n  25-29 0.6829268 0.3170732\n  30-34 0.7203390 0.2796610\n  35-44 0.7810219 0.2189781\n  45-54 0.8468468 0.1531532\n\n\n\n\n\n\n\n\nNote\n\n\n\nTable of Age group (with manual calculation of OR)\n\n\n\nAge group\nCase\nControl\nOR (95% CI)\n\n\n\n\n15-19\n13 (11.9)\n96(88.1)\nRef\n\n\n20-24\n57(34.5)\n108(65.5)\n3.9 (2.1-7.8)\n\n\n25-29\n39(31.7)\n84(68.3)\n3.4 (1.8-7.1)\n\n\n30-34\n33(28.0)\n85(72.0)\n2.9 (1.4-6.0)\n\n\n35-44\n30(21.9)\n107(78.1)\n2.1 (1.0-4.3)\n\n\n45-54\n17(15.3)\n94(84.7)\n1.3 (0.6-3.0)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSo far regarding to age, We can see that all age groups have higher odds to be infected than age group ‘15-19’ (reference) (even though not all are significant)\n\n\nBivariate table: VIH - Education\n\ntable (mwanza$ed_f, mwanza$case)\n\n   \n      0   1\n  1 263  49\n  2  51  24\n  3 255 110\n  4   5   6\n\nprop.table(table (mwanza$ed_f, mwanza$case), margin=1)  #Porcentajes por fila\n\n   \n            0         1\n  1 0.8429487 0.1570513\n  2 0.6800000 0.3200000\n  3 0.6986301 0.3013699\n  4 0.4545455 0.5454545\n\n\n\n\n\n\n\n\nNote\n\n\n\nTable of education (with manual calculation of OR)\n\n\n\nYears of education\nCase\nControl\nOR (95% CI)\n\n\n\n\n0\n49 (15.7)\n263 (84.3)\nRef.\n\n\n1-3\n24 (32.0)\n51 (68.0)\n2.5 (1.4-4.5)\n\n\n4-6\n110 (30.1)\n255 (69.9)\n2.3 (1.6-3.4)\n\n\n7+\n6 (54.5)\n5 (45.5)\n6.4 (1.9-23.1)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSo far regarding to education, we can see that educated women have all significantly higher odds to be infected than uneducated women (reference)\n\n\n\n\n2. Now we are interested in a possible interaction between these two variables. First we should reduce the number of categories for both of them. Transform “ed” into a binary variable called “ed2”, with should take value 1 for “having been at school for at least 1 year” and the value 0 otherwise. Check whether recoding has worked. The new variable “age2” should be coded as fol-lows: 1=15 19, 2=20 29, 3=30 44, 4=45 and more. In your own interest: always check that your recoding has worked\n2.1 Reducing the categories\n\n#Education at least 1 year\n  mwanza$ed2_f <- ifelse(mwanza$ed>1,1,0)\n  mwanza$ed2_f <- factor(mwanza$ed2_f)\n  table(mwanza$ed, mwanza$ed2_f)\n\n   \n      0   1\n  1 312   0\n  2   0  75\n  3   0 365\n  4   0  11\n\n#Age reducing categories\n  mwanza$age2_f <- mwanza$age1\n  mwanza$age2_f[mwanza$age1==3] <- 2\n  mwanza$age2_f[mwanza$age1==4] <- 3\n  mwanza$age2_f[mwanza$age1==5] <- 3\n  mwanza$age2_f[mwanza$age1==6] <- 4\n  mwanza$age2_f <- factor(mwanza$age2_f)\n  table(mwanza$age1, mwanza$age2_f)\n\n   \n      1   2   3   4\n  1 109   0   0   0\n  2   0 165   0   0\n  3   0 123   0   0\n  4   0   0 118   0\n  5   0   0 137   0\n  6   0   0   0 111\n\n\n\n\n3. Use logistic regression to look for interaction between education and age.\n3.1 First the model without interaction\n\nGLM1 <- glm(case ~ ed2_f + age2_f, family=binomial, data=mwanza)\nsummary(GLM1)\n\n\nCall:\nglm(formula = case ~ ed2_f + age2_f, family = binomial, data = mwanza)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.9623  -0.8965  -0.6131  -0.3542   2.3665  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -2.7375     0.3498  -7.827 5.02e-15 ***\ned2_f1        0.8719     0.2082   4.188 2.81e-05 ***\nage2_f2       1.3359     0.3227   4.140 3.48e-05 ***\nage2_f3       1.1615     0.3375   3.441 0.000579 ***\nage2_f4       0.8583     0.4211   2.038 0.041542 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 854.26  on 762  degrees of freedom\nResidual deviance: 807.90  on 758  degrees of freedom\nAIC: 817.9\n\nNumber of Fisher Scoring iterations: 4\n\nexp(coef(GLM1))\n\n(Intercept)      ed2_f1     age2_f2     age2_f3     age2_f4 \n 0.06473065  2.39150115  3.80333613  3.19461007  2.35904293 \n\nexp(confint(GLM1))\n\nWaiting for profiling to be done...\n\n\n                 2.5 %    97.5 %\n(Intercept) 0.03137867 0.1244741\ned2_f1      1.59983748 3.6230547\nage2_f2     2.08418557 7.4537561\nage2_f3     1.69527973 6.4225579\nage2_f4     1.03890649 5.4731892\n\n\n3.2 Then the model with interaction\n\nGLM2 <- glm(case ~ ed2_f*age2_f, family=binomial, data=mwanza)\nsummary(GLM2)\n\n\nCall:\nglm(formula = case ~ ed2_f * age2_f, family = binomial, data = mwanza)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.9508  -0.9494  -0.5530  -0.4673   2.1301  \n\nCoefficients:\n               Estimate Std. Error z value Pr(>|z|)   \n(Intercept)     -1.5041     0.5528  -2.721  0.00651 **\ned2_f1          -0.6554     0.6553  -1.000  0.31726   \nage2_f2          0.2719     0.6307   0.431  0.66636   \nage2_f3         -0.2964     0.6057  -0.489  0.62458   \nage2_f4         -0.4177     0.6333  -0.660  0.50951   \ned2_f1:age2_f2   1.3245     0.7354   1.801  0.07172 . \ned2_f1:age2_f3   1.8963     0.7256   2.613  0.00897 **\ned2_f1:age2_f4   1.7018     0.8991   1.893  0.05839 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 854.26  on 762  degrees of freedom\nResidual deviance: 801.46  on 755  degrees of freedom\nAIC: 817.46\n\nNumber of Fisher Scoring iterations: 4\n\nexp(coef(GLM2))\n\n   (Intercept)         ed2_f1        age2_f2        age2_f3        age2_f4 \n     0.2222222      0.5192308      1.3125000      0.7434783      0.6585366 \ned2_f1:age2_f2 ed2_f1:age2_f3 ed2_f1:age2_f4 \n     3.7601411      6.6610971      5.4835390 \n\nexp(confint(GLM2))\n\nWaiting for profiling to be done...\n\n\n                    2.5 %     97.5 %\n(Intercept)    0.06419365  0.5954641\ned2_f1         0.15008794  2.0850593\nage2_f2        0.40648790  5.0991675\nage2_f3        0.24434285  2.7814891\nage2_f4        0.20183699  2.5638698\ned2_f1:age2_f2 0.82155509 15.4284190\ned2_f1:age2_f3 1.47745296 26.7051999\ned2_f1:age2_f4 0.86959967 30.6574966\n\n\n3.3 Likelihood interaction test to compare both models\n\nanova(GLM1, GLM2, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: case ~ ed2_f + age2_f\nModel 2: case ~ ed2_f * age2_f\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)  \n1       758     807.90                       \n2       755     801.46  3   6.4335  0.09232 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe p value of the likelihood ratio test (the one with the anova command) is 0.09232 So adding age as interaction has not a significant improve in the model.that also means that we don’t have evidence to said that age is an interaction factor (because doesnt cause a significant change)\nLikewise, because of the principle of parsimony and because adding the interaction has not a significant improve in the model, we will keep the simplest model (without interaction)\n\n\n\n\n\n\n\n\nNote\n\n\n\nStill we have some doubt about if there is an interaction or not. Since the Age group variable had many categories, the interaction might not display that way. That is the reason for the next step\n\n\n\n\n4. Combining levels of exposure often increases the power of the likelihood ratio test to show inter-action. Therefore:\n a) dichotomise age in a new variable “young”, where 15-19 years is coded as ‘TRUE’ and 20 years is coded as ‘FALSE’. Compare to ‘age2’ to check that it worked well. b) test for interaction, using logistic regression c) estimate appropriate odds ratios for the association between education and HIV infection d) interpret these OR \n\nReducing the categories of age\n\n\n#Reducing Age to Young\n  mwanza$young <- ifelse(mwanza$age1==1,1,0)\n  #table(mwanza$young, mwanza$age1)\n\n\nTest for interaction, using logistic regression\n\nb.1 First the model without interaction\n\nGLM3 <- glm(case ~ ed2_f + young, family=binomial, data=mwanza)\nsummary(GLM3)\n\n\nCall:\nglm(formula = case ~ ed2_f + young, family = binomial, data = mwanza)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.9318  -0.9318  -0.6003  -0.3331   2.4163  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -1.6224     0.1563 -10.380  < 2e-16 ***\ned2_f1        1.0129     0.1891   5.357 8.44e-08 ***\nyoung        -1.2413     0.3134  -3.961 7.46e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 854.26  on 762  degrees of freedom\nResidual deviance: 810.31  on 760  degrees of freedom\nAIC: 816.31\n\nNumber of Fisher Scoring iterations: 4\n\nexp(coef(GLM3))\n\n(Intercept)      ed2_f1       young \n  0.1974194   2.7535251   0.2890131 \n\nexp(confint(GLM3))\n\nWaiting for profiling to be done...\n\n\n                2.5 %    97.5 %\n(Intercept) 0.1437040 0.2655621\ned2_f1      1.9125028 4.0177352\nyoung       0.1498001 0.5164487\n\n\nb.2 Then the model with interaction\n\nGLM4 <- glm(case ~ ed2_f*young, family=binomial, data=mwanza)\nsummary(GLM4)\n\n\nCall:\nglm(formula = case ~ ed2_f * young, family = binomial, data = mwanza)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.9446  -0.9446  -0.5807  -0.4673   2.1301  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -1.6946     0.1622 -10.449  < 2e-16 ***\ned2_f1         1.1188     0.1955   5.722 1.05e-08 ***\nyoung          0.1905     0.5761   0.331  0.74086    \ned2_f1:young  -1.7742     0.6839  -2.594  0.00948 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 854.26  on 762  degrees of freedom\nResidual deviance: 804.69  on 759  degrees of freedom\nAIC: 812.69\n\nNumber of Fisher Scoring iterations: 4\n\nexp(coef(GLM4))\n\n (Intercept)       ed2_f1        young ed2_f1:young \n   0.1836735    3.0610396    1.2098765    0.1696256 \n\nexp(confint(GLM4))\n\nWaiting for profiling to be done...\n\n\n                  2.5 %    97.5 %\n(Intercept)  0.13200733 0.2496751\ned2_f1       2.10056832 4.5268821\nyoung        0.33774768 3.4251394\ned2_f1:young 0.04620559 0.7138024\n\n\nb.3 With Likelihood interaction test we compare both models\n\nanova(GLM3, GLM4, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: case ~ ed2_f + young\nModel 2: case ~ ed2_f * young\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)  \n1       760     810.31                       \n2       759     804.69  1   5.6194  0.01776 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe p value of the likelihood ratio test (the one with the anova command) is 0.01776 So adding age (young) as interaction has a significant improve of the model.\n  But before we had not said that age group was not an interaction?\n      This is because before age group had 4 categories, not has only 2\n      Testing for interaction is more sensitive if we dichotomize, i.e. use two groups only\n  \n  Likewise, because the model with interaction (GLM4) had a significant improve, this is the model \n  we are going to take.\n\n\n\nestimate appropriate odds ratios for the association between education and HIV infection\ninterpret these OR\n\n\n\n\n\n\n\nNote\n\n\n\nSo the equation for model GLM4 (the one with interaction) is:\n                      (Intercept)     ed2_f1                young           ed2_f1:young\nOdds(HIV infection) = 0.1836735 * 3.0610396^Educat * 1.2098765^young * 0.1696256^(Educat*young)\nWhen we are talking about the OR (odds ratio) we only work with the coefficients (no te intercept)\n\n\n\n\n\n\n\nCategory\nOR\n\n\n\n\nYoung\n\n\n\nOR for not educated young\n=3.0610396^Educat * 1.2098765^young * 0.1696256^(Educat*young)\n\n\n\n=3.0610396^0 * 1.2098765^1 * 0.1696256^(0*1)\n\n\n\n= 1 * 1.2098765 * 1\n\n\n\n= 1.2098\n\n\nOR for educated young\n=3.0610396^Educat * 1.2098765^young * 0.1696256^(Educat*young)\n\n\n\n=3.0610396^1 * 1.2098765^1 * 0.1696256^(1*1)\n\n\n\n=3.0610396 * 1.2098765 * 0.1696256\n\n\n\n=0.628205\n\n\nOlder\n\n\n\nOR for not educated older\n=3.0610396^Educat * 1.2098765^young * 0.1696256^(Educat*young)\n\n\n\n=3.0610396^0 * 1.2098765^0 * 0.1696256^(0*0)\n\n\n\n= 1 * 1 * 1\n\n\n\n= 1 (Is one because is the reference)\n\n\nOR for educated older\n=3.0610396^Educat * 1.2098765^young * 0.1696256^(Educat*young)\n\n\n\n=3.0610396^1 * 1.2098765^0 * 0.1696256^(1*0)\n\n\n\n=3.0610396 * 1 * 1\n\n\n\n=3.0610396\n\n\n\nInterpretation: \n\n    1.Among old people, the odds of having VIH are 3.06 times as high for those \n    who have education compared to those without instruction. (=3.06/1) \n    So education is a risk factor\n    \n    2.Among young people, the odds of having VIH are 0.519 times as high for those \n    who have education compared to those without instruction. (=0.628205/1.2098)\n    So education is a protective factor\n\n\n\nExtra: Another way (maybe better) to doing this last part is to create subsets and doing the regression separate:\n\n\nyoung  <-  subset(mwanza, young==1)  #Creating a database for only young\nold  <-  subset(mwanza, young==0)    #Creating a database for only older\n\ne.1 Regressión in the database of youngs:\n\nGLM5 <- glm(case ~ ed2_f, family=binomial, data=young)\nsummary(GLM5)\n\n\nCall:\nglm(formula = case ~ ed2_f, family = binomial, data = young)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.6335  -0.4673  -0.4673  -0.4673   2.1301  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)   \n(Intercept)  -1.5041     0.5528  -2.721  0.00651 **\ned2_f1       -0.6554     0.6553  -1.000  0.31726   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 79.670  on 108  degrees of freedom\nResidual deviance: 78.734  on 107  degrees of freedom\nAIC: 82.734\n\nNumber of Fisher Scoring iterations: 4\n\nexp(coef(GLM5))\n\n(Intercept)      ed2_f1 \n  0.2222222   0.5192308 \n\nexp(confint(GLM5))\n\nWaiting for profiling to be done...\n\n\n                 2.5 %    97.5 %\n(Intercept) 0.06419365 0.5954641\ned2_f1      0.15008794 2.0850593\n\n\ne.2 Regressión in the database of olders:\n\nGLM6 <- glm(case ~ ed2_f, family=binomial, data=old)\nsummary(GLM6)\n\n\nCall:\nglm(formula = case ~ ed2_f, family = binomial, data = old)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.9446  -0.9446  -0.5807   1.4297   1.9304  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -1.6946     0.1622 -10.449  < 2e-16 ***\ned2_f1        1.1188     0.1955   5.722 1.05e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 761.75  on 653  degrees of freedom\nResidual deviance: 725.96  on 652  degrees of freedom\nAIC: 729.96\n\nNumber of Fisher Scoring iterations: 4\n\nexp(coef(GLM6))\n\n(Intercept)      ed2_f1 \n  0.1836735   3.0610396 \n\nexp(confint(GLM6))\n\nWaiting for profiling to be done...\n\n\n                2.5 %    97.5 %\n(Intercept) 0.1320073 0.2496751\ned2_f1      2.1005683 4.5268821\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn GLM5 (regresión in database of youngs), the OR for having VIH among young is:\n    OR: 0.5192308 \n    IC 95% (0.15008794 - 2.0850593)\n    \n    So, when we search for the association between (VIH and education) among youngs, \n    we can see that education is a protective factor OR= 0.5192, \n    but it is not significant (IC takes 1)\n    \nIn GLM6 (regresión in database of older), the OR for having VIH among older is:\n    OR: 3.0610396  \n    IC 95% (2.1005683 4.5268821)\n    \n    So, when we search for the association between (VIH and education) among older, \n    we can see that education is a risk factor OR= 3.06 and it is significant (IC doesnt takes 1)"
  },
  {
    "objectID": "2023-02-08 Logistic Regresion, Sessión 3.html",
    "href": "2023-02-08 Logistic Regresion, Sessión 3.html",
    "title": "2023-02-08 Sessión 3",
    "section": "",
    "text": "Instituut Voor Tropische Geneeskunde - Antwerp, Belgium\nJavier Silva-Valencia"
  },
  {
    "objectID": "2023-02-08 Logistic Regresion, Sessión 3.html#step-by-step---selection-of-variables-for-modeling",
    "href": "2023-02-08 Logistic Regresion, Sessión 3.html#step-by-step---selection-of-variables-for-modeling",
    "title": "2023-02-08 Sessión 3",
    "section": "Step by Step - Selection of variables for modeling",
    "text": "Step by Step - Selection of variables for modeling\n\nImport data\nImporting a CSV database under the name of “onch1302”, with “,” as separator:\n\nonch1302 <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2/Logistic Regresion Exercise Database/Datasets/onch1302.csv\", sep=\",\")\n\n\n\n\n\nStarting the Exercise (MVA_LogReg_Ex1-2023):\n Onchocerciasis (commonly known as River Blindness) is a chronic filarial disease found in sub-Saharan Africa and some parts of Central and South America. An onchocerciasis project was set up in 1982 in the Bo district of Sierra Leone. The aims of the project were to study epidemiological, clin-ical, immunological and entomological aspects of the disease. Prevalence surveys were undertaken in villages selected on the basis of potential high endemicity, being situated on or near rivers which are the breeding sites for the Simulium damnosum blackfly. Of the twelve villages included in the present dataset, five were situated in the south and east of the country in the forest' zone and the other seven were in thesavannah’ zone of the country. A census was taken of each village, and all villagers over the age of five years were asked to participate in the study. Coverage was over 90% in all but one of the selected villages. Diagnosis was made by taking a skin-snip, and clinical and an ocular examination were also performed. The file ONCH1302 contains data for all 1,302 subjects. \n This time you are asked to make two logistic regression models, first using classical model selection, then change-in-estimate model selection for the effect of area of residence (forest or savannah). Please answer the questions below. \n\nPart 1\n\n1. Which are the steps you will go through for classical model selection?\n\n\n2. Please start by making a table describing the study population. Remember that to get tables with percentages you can use the “proportions” or “prop.table” function around a table (both functions are the same)\n2.1 Modifing variables to work correctly\n\nonch1302$female <- factor(onch1302$sex, labels = c(\"male\", \"female\"))\nonch1302$forest <- factor(onch1302$area, labels = c(\"savanna\", \"forest\"))\n\nonch1302$agegrp <- factor(onch1302$agegrp, labels = c(\"(5-9)\", \"(10-19)\", \"(20-29)\", \"(40+)\"))\nonch1302$mf <- factor(onch1302$mf, labels = c(\"non-cases\", \"cases\"))\nonch1302$mfload <- factor(onch1302$mfload, labels = c(\"(none)\", \"(1-9)\", \"(10-49)\", \"(50+)\"))\nonch1302$lesions <- factor(onch1302$lesions, labels = c(\"no\", \"yes\"))\n\n\n#Lesions\ntable(onch1302$lesions, useNA = \"always\")     #frecuency\n\n\n  no  yes <NA> \n1101  201    0 \n\nprop.table(table(onch1302$lesions))           #proportion\n\n\n       no       yes \n0.8456221 0.1543779 \n\n#female\ntable(onch1302$female, useNA = \"always\")     #frecuency\n\n\n  male female   <NA> \n   616    686      0 \n\nprop.table(table(onch1302$female))           #proportion\n\n\n     male    female \n0.4731183 0.5268817 \n\n#Forest\ntable(onch1302$forest, useNA = \"always\")     #frecuency\n\n\nsavanna  forest    <NA> \n    548     754       0 \n\nprop.table(table(onch1302$forest))           #proportion\n\n\n  savanna    forest \n0.4208909 0.5791091 \n\n#Agegr\ntable(onch1302$agegrp, useNA = \"always\")     #frecuency\n\n\n  (5-9) (10-19) (20-29)   (40+)    <NA> \n    202     218     424     458       0 \n\nprop.table(table(onch1302$agegrp))           #proportion\n\n\n    (5-9)   (10-19)   (20-29)     (40+) \n0.1551459 0.1674347 0.3256528 0.3517665 \n\n#Microfilaria\ntable(onch1302$mf, useNA = \"always\")     #frecuency\n\n\nnon-cases     cases      <NA> \n      480       822         0 \n\nprop.table(table(onch1302$mf))           #proportion\n\n\nnon-cases     cases \n0.3686636 0.6313364 \n\n#Microfilaria Load\ntable(onch1302$mfload, useNA = \"always\")     #frecuency\n\n\n (none)   (1-9) (10-49)   (50+)    <NA> \n    480     367     277     178       0 \n\nprop.table(table(onch1302$mfload))           #proportion\n\n\n   (none)     (1-9)   (10-49)     (50+) \n0.3686636 0.2818740 0.2127496 0.1367127 \n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nFactor\nN (%)\n\n\n\n\nTotal\n1302 (100)\n\n\nFemale gender\n686 (52.7)\n\n\nAge group\n\n\n\n5-9\n202 (15.5)\n\n\n10-19\n218 (16.7)\n\n\n20-39\n424 (32.6)\n\n\n40+\n458 (35.2)\n\n\nLiving in Forest\n754 (57.9)\n\n\nMicro filaria infected\n822 (63.1)\n\n\nMicro-filarial load\n\n\n\nNone\n480 (36.8)\n\n\n1-9\n367 (28.1)\n\n\n10-49\n277 (21.2)\n\n\n50+\n178 (13.6)\n\n\nEyes affected (lesions)\n201 (15.4)\n\n\n\n\n\n\n\n3. Next step is to explore the bivariate associations with the outcome variable, microfilarial infection. Please explore these associations using bivariate logistic regression models and construct an appropriate table. Though odds ratios with 95% confidence intervals show which coefficients are significant, please add a column with p-values from the likelihood ratio test so we can decide which factors to test in our multivariate mode\n\nlibrary(EpiStats)\n\n3.1 Frecuency tables\n\n#Total\n#table (onch1302$mf)\nprop.table(table (onch1302$mf))  #Porcentajes totales\n\n\nnon-cases     cases \n0.3686636 0.6313364 \n\n#Female\n#table (onch1302$female, onch1302$mf)\nprop.table(table (onch1302$female, onch1302$mf), margin=2)  #Porcentajes por column\n\n        \n         non-cases     cases\n  male   0.3958333 0.5182482\n  female 0.6041667 0.4817518\n\n#Age group\n#table (onch1302$agegrp, onch1302$mf)\nprop.table(table (onch1302$agegrp, onch1302$mf), margin=2)  #Porcentajes por fila\n\n         \n           non-cases      cases\n  (5-9)   0.32500000 0.05596107\n  (10-19) 0.24791667 0.12043796\n  (20-29) 0.26041667 0.36374696\n  (40+)   0.16666667 0.45985401\n\n#forest\n#table (onch1302$forest, onch1302$mf)\nprop.table(table (onch1302$forest, onch1302$mf), margin=2)  #Porcentajes por fila\n\n         \n          non-cases     cases\n  savanna 0.5562500 0.3418491\n  forest  0.4437500 0.6581509\n\n#lesions\n#table (onch1302$lesions, onch1302$mf)\nprop.table(table (onch1302$lesions, onch1302$mf), margin=2)  #Porcentajes por fila\n\n     \n       non-cases      cases\n  no  0.96041667 0.77858881\n  yes 0.03958333 0.22141119\n\n\n3.2 For calculatin the OR and the p-value of the likelihood ratio test\nLogistic model: mf ~ female\n\nlm1 <- glm(mf ~ female, family=binomial, data=onch1302)\n#summary(lm1)\nexp(coef(lm1))\n\n (Intercept) femalefemale \n   2.2421053    0.6090335 \n\nexp(confint(lm1))\n\nWaiting for profiling to be done...\n\n\n                 2.5 %    97.5 %\n(Intercept)  1.8930554 2.6654704\nfemalefemale 0.4842344 0.7647899\n\nanova(lm1, test=\"Chisq\")  #To check for the p value of the likelihood ratio test\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: mf\n\nTerms added sequentially (first to last)\n\n       Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    \nNULL                    1301     1714.1              \nfemale  1   18.317      1300     1695.7 1.871e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLogistic model: mf ~ agegrp\n\nlm2 <- glm(mf ~ agegrp, family=binomial, data=onch1302)\n#summary(lm2)\nexp(coef(lm2))\n\n  (Intercept) agegrp(10-19) agegrp(20-29)   agegrp(40+) \n    0.2948718     2.8213372     8.1120000    16.0239130 \n\nexp(confint(lm2))\n\nWaiting for profiling to be done...\n\n\n                   2.5 %     97.5 %\n(Intercept)    0.2099851  0.4059964\nagegrp(10-19)  1.8566452  4.3348741\nagegrp(20-29)  5.5353487 12.0770820\nagegrp(40+)   10.7442422 24.3134387\n\nanova(lm2, test=\"Chisq\")  #To check for the p value of the likelihood ratio test\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: mf\n\nTerms added sequentially (first to last)\n\n       Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    \nNULL                    1301     1714.1              \nagegrp  3    258.4      1298     1455.7 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLogistic model: mf ~ forest\n\nlm3 <- glm(mf ~ forest, family=binomial, data=onch1302)\nsummary(lm3)\n\n\nCall:\nglm(formula = mf ~ forest, family = binomial, data = onch1302)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.5900  -1.1992   0.8148   0.8148   1.1558  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   0.05111    0.08546   0.598     0.55    \nforestforest  0.88102    0.11767   7.487 7.05e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1714.1  on 1301  degrees of freedom\nResidual deviance: 1657.0  on 1300  degrees of freedom\nAIC: 1661\n\nNumber of Fisher Scoring iterations: 4\n\nexp(coef(lm3))\n\n (Intercept) forestforest \n    1.052434     2.413363 \n\nexp(confint(lm3))\n\nWaiting for profiling to be done...\n\n\n                 2.5 %   97.5 %\n(Intercept)  0.8901384 1.244620\nforestforest 1.9176644 3.042055\n\nanova(lm3, test=\"Chisq\")  #To check for the p value of the likelihood ratio test\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: mf\n\nTerms added sequentially (first to last)\n\n       Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    \nNULL                    1301     1714.1              \nforest  1   57.025      1300     1657.0 4.302e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLogistic model: mf ~ lesions\n\nlm4 <- glm(mf ~ lesions, family=binomial, data=onch1302)\nsummary(lm4)\n\n\nCall:\nglm(formula = mf ~ lesions, family = binomial, data = onch1302)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1720  -1.3195   0.4456   1.0416   1.0416  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.32807    0.06109   5.370 7.85e-08 ***\nlesionsyes   1.93150    0.24868   7.767 8.03e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1714.1  on 1301  degrees of freedom\nResidual deviance: 1622.9  on 1300  degrees of freedom\nAIC: 1626.9\n\nNumber of Fisher Scoring iterations: 4\n\nexp(coef(lm4))\n\n(Intercept)  lesionsyes \n   1.388286    6.899835 \n\nexp(confint(lm4))\n\nWaiting for profiling to be done...\n\n\n               2.5 %    97.5 %\n(Intercept) 1.232067  1.565531\nlesionsyes  4.348729 11.590217\n\nanova(lm4, test=\"Chisq\")  #To check for the p value of the likelihood ratio test\n\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: mf\n\nTerms added sequentially (first to last)\n\n        Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    \nNULL                     1301     1714.1              \nlesions  1   91.198      1300     1622.9 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\n\n\nFactor\nCases (% col)\nNon-cases (% col)\nOR (95% CI)\np-value of LRTest\n\n\n\n\nTotal\n480 (36.9)\n822 (63.1)\n\n\n\n\nFemale gender (yes)\n396 (48.1)\n290 (60.4)\n0.6090335 (0.4842344 0.7647899)\n1.871e-05 *** (<0.001)\n\n\nFemale gender (no)\n426 (51.8)\n190 (39.5)\nRef\n\n\n\nAge group\n\n\n\n\n\n\n5-9\n46 (5.5)\n156 (32.5)\nRef\n2.2e-16 *** (<0.001)\n\n\n10-19\n99 (12.0)\n119 (24.7)\n2.8213372 (1.8566452 4.3348741)\n\n\n\n20-39\n299 (36.3)\n125 (26.0)\n8.1120000 (5.5353487 12.0770820)\n\n\n\n40+\n378 (45.9)\n80 (16.6)\n16.0239130 (10.7442422 24.3134387)\n\n\n\nLiving in Forest (yes)\n541 (65.8)\n213 (44.3)\n2.413363 (1.9176644 3.042055)\n4.302e-14 *** (<0.001)\n\n\nLiving in Forest (no)\n281 (34.1)\n267 (55.6)\nRef\n\n\n\nLesions (yes)\n19 (22.1)\n182 (3.9)\n6.899835 (4.348729 11.590217)\n2.2e-16 *** (<0.001)\n\n\nLesions (no)\n461 (77.8)\n640 (96.1)\nRef\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nExample of interpretation: Among the non-cases only 3.9% had lesions\n\n\n\n\n4. Which variables will you include in the multivariate model? Should eye lesions be included?\n\n\n\n\n\n\nNote\n\n\n\nAll variable had a p-value of the LRTest less than 0.10 Even though because of the nature of the research, we are looking for epidemiological exposures of microfilaria, eye lesions are not an exposure are more a symptom/sign\n\n\n\n\n5. Fit the model with ‘age group’ as factor, ‘forest’ and ‘female’, which is now the weakest factor (highest p-value)? Does dropping it make the model significantly less precise? Present the final model in a table.\n\nlm5 <- glm(mf ~ agegrp + forest + female, family=binomial, data=onch1302)\nsummary(lm5)\n\n\nCall:\nglm(formula = mf ~ agegrp + forest + female, family = binomial, \n    data = onch1302)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.2212  -0.7666   0.5392   0.7081   2.1459  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    -1.6157     0.2066  -7.820 5.30e-15 ***\nagegrp(10-19)   0.9429     0.2239   4.211 2.54e-05 ***\nagegrp(20-29)   2.3478     0.2108  11.138  < 2e-16 ***\nagegrp(40+)     2.8713     0.2171  13.225  < 2e-16 ***\nforestforest    1.1227     0.1386   8.099 5.52e-16 ***\nfemalefemale   -0.5813     0.1356  -4.286 1.82e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1714.1  on 1301  degrees of freedom\nResidual deviance: 1366.1  on 1296  degrees of freedom\nAIC: 1378.1\n\nNumber of Fisher Scoring iterations: 4\n\nexp(coef(lm5))\n\n  (Intercept) agegrp(10-19) agegrp(20-29)   agegrp(40+)  forestforest \n    0.1987542     2.5673568    10.4623748    17.6593452     3.0731378 \n femalefemale \n    0.5591696 \n\nexp(confint(lm5))\n\nWaiting for profiling to be done...\n\n\n                   2.5 %     97.5 %\n(Intercept)    0.1312769  0.2954028\nagegrp(10-19)  1.6627984  4.0044862\nagegrp(20-29)  6.9776128 15.9588558\nagegrp(40+)   11.6370517 27.2821110\nforestforest   2.3475876  4.0437091\nfemalefemale   0.4279198  0.7284977\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn lm5 the variable with the highest p-value is female (p value = 1.82e-05). So we will do a new model without female and then compare it with lm5 to see if it caused a significant change\n\n\n\nlm6 <- glm(mf ~ agegrp + forest, family=binomial, data=onch1302)\nanova(lm5, lm6, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: mf ~ agegrp + forest + female\nModel 2: mf ~ agegrp + forest\n  Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    \n1      1296     1366.1                          \n2      1297     1384.8 -1  -18.712 1.521e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe p value of the Likelihood ratio test is 1.521e-05 (p < 0.001), So, when I eliminate female, it changes the model significant making it less precise. So we cannot eliminate female.\nThe model we will stick with is the more complex lm5 (mf ~ agegrp + forest + female) The table of OR of lm5 is:\n\n\n\nFactor (n=1302)\nOR (95% CI)\n\n\n\n\nFemale gender\n0.5591696 (0.4279198 0.7284977)\n\n\nAge group: 5-9 years\n2.5673568 (1.6627984 4.0044862)\n\n\n10-19 years\n2.5673568 (1.6627984 4.0044862)\n\n\n20-39 year\n10.4623748 (6.9776128 15.9588558)\n\n\n40 years and above\n17.6593452 (11.6370517 27.2821110)\n\n\nLiving in forest\n3.0731378 (2.3475876 4.0437091)\n\n\n\n\n\n\n\n6. Which are the three potential interactions? Does any of them significantly improve the model? If so, make a table with the odds ratio’s in which you have taken into account the interaction.\nFor this section we need to test is the variables are ok in that way (lm5) or there are interaction. We will compare lm5 with models with interactions\n6.1 Model with forest*female as interaction\n\nlm7 <- glm(mf ~ agegrp + forest*female , family=binomial, data=onch1302)\nanova(lm5, lm7, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: mf ~ agegrp + forest + female\nModel 2: mf ~ agegrp + forest * female\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)  \n1      1296     1366.1                       \n2      1295     1361.7  1   4.4028  0.03588 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe p-value of the Likelihood ratio test is 0.03588 (Lower than 0.05). So, it changes the model significant. So there is an interaction between forest*female We will keep this model\n\n\n6.2 Model with agegrp*forest as interaction\n\nlm8 <- glm(mf ~ agegrp*forest + female , family=binomial, data=onch1302)\nanova(lm5, lm8, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: mf ~ agegrp + forest + female\nModel 2: mf ~ agegrp * forest + female\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)\n1      1296     1366.1                     \n2      1293     1360.8  3   5.2497   0.1544\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe p-value of the Likelihood ratio test is 0.1544 (Higher than 0.05). So, it does not changes the model significant. So there is not an interaction between agegrp*forest\n\n\n6.3 Model with agegrp*female as interaction\n\nlm9 <- glm(mf ~ forest + agegrp*female , family=binomial, data=onch1302)\nanova(lm5, lm9, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: mf ~ agegrp + forest + female\nModel 2: mf ~ forest + agegrp * female\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)\n1      1296     1366.1                     \n2      1293     1361.2  3    4.873   0.1813\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe p-value of the Likelihood ratio test is 0.1813 (Higher than 0.05). So, it does not changes the model significant. So there is not an interaction between agegrp*female\n\n\n6.3 Filling the table requested Because we now know that we have an interaction : forest*female, is better to calculate the OR by categories of the interaction. We could decide to split the data by (women-men) or by (living/ not living in the forest). The most usual is present the results by sex, so:\n\ntable(onch1302$female)\n\n\n  male female \n   616    686 \n\nwomen  <-  subset(onch1302, female==\"female\")  #Creating a database for only women\nmen  <-  subset(onch1302, female==\"male\")    #Creating a database for only male\n\nThe model in women\n\nlm10 <- glm(mf ~ agegrp + forest , family=binomial, data=women)\nexp(coef(lm10))\n\n  (Intercept) agegrp(10-19) agegrp(20-29)   agegrp(40+)  forestforest \n   0.09191677    2.13748276   10.48287813   23.11558852    4.15267371 \n\nexp(confint(lm10))\n\nWaiting for profiling to be done...\n\n\n                    2.5 %     97.5 %\n(Intercept)    0.05060697  0.1596338\nagegrp(10-19)  1.13270252  4.1137899\nagegrp(20-29)  5.97014423 19.1384989\nagegrp(40+)   12.62532875 44.0769379\nforestforest   2.85704938  6.1178354\n\n\nThe model in man\n\nlm11 <- glm(mf ~ agegrp + forest , family=binomial, data=men)\nexp(coef(lm11))\n\n  (Intercept) agegrp(10-19) agegrp(20-29)   agegrp(40+)  forestforest \n    0.2392317     3.1894477    11.5596717    13.8388609     2.1425002 \n\nexp(confint(lm11))\n\nWaiting for profiling to be done...\n\n\n                  2.5 %     97.5 %\n(Intercept)   0.1395508  0.3959848\nagegrp(10-19) 1.7572835  5.9066602\nagegrp(20-29) 6.4172108 21.4996506\nagegrp(40+)   7.8746659 25.0737487\nforestforest  1.4425398  3.1999460\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\n\n\n\n\n\nFactor (n=1302)\nWomen (n=686) OR (95% CI)\nMen (N=616) OR (95% CI)\n\n\n\n\nAge group:5-9 years\n\n\n\n\n10-19 year\n2.13748276 (1.13270252 4.1137899)\n3.1894477 (1.7572835 5.9066602)\n\n\n20-39 year\n10.48287813 (5.97014423 19.1384989)\n11.5596717 (6.4172108 21.4996506)\n\n\n40 years +\n23.11558852 (12.62532875 44.0769379)\n13.8388609 (7.8746659 25.0737487)\n\n\nLiving in forest\n4.15267371 (2.85704938 6.1178354)\n2.1425002 (1.4425398 3.1999460)\n\n\n\nThe effect of living in the forest is different for women from men The Odds of having the disease is 4. times as high if you are women living in the forest than women living in savana The Odds of having the disease is 2. times as high if you are men living in the forest than men living in savana\nThis is because female is an interaction factor (The interaction test (likelihood ratio test) was significant)\n\n\n\n\n\nPart 2\nChange-in-Estimate model (it change the primary OR exposure) 1. We select the factor that can be exposures and the main exposure: Can we change it? 2. First the crude odd ratio bivariate outcome - primary exposure\n\nmod_crude <- glm(mf ~ forest, family=binomial, data=onch1302)\n\n\nThen adding one variable at the time and writing it down.\n\n\nmod_1 <- glm(mf ~ forest + sex, family=binomial, data=onch1302)\nmod_2 <- glm(mf ~ forest + agegrp, family=binomial, data=onch1302)\n\n\n\n\n\n\n\n\n\n\nFactor\nCo-factor\nOR\nChange (Original OR - New OR)/Original OR\n\n\n\n\nLiving in forest\n\n2.41\n\n\n\nLiving in forest\nFemale gender\n2.40\n= (2.41 - 2-40)/ 2.41\n\n\n\n\n\n= 0.4%\n\n\nLiving in forest\nAge group\n3.08\n= (3.08 - 2-41)/ 2.41\n\n\n\n\n\n= 27.8%\n\n\n\n\nSo the final model for now is: mod_2 <- glm(mf ~ forest + agegrp, family=binomial, data=onch1302)\nTring adding interaction effects If we want to check for interaction, is better to have no so may categories. So we will dichotomize agegroup\n\n\n#Adult variable (adult=1, non adult=0)\n  onch1302$adult <- ifelse(onch1302$agegrp>1,1,0)\n\nWarning in Ops.factor(onch1302$agegrp, 1): '>' not meaningful for factors\n\n\nWe compare with the likelihood ratio test the one without interaction (mf ~ forest + agegrp) and the one with interaction (mf ~ forest * agegrp)\nThe p value is not significant, so we keep with te more simple (mf ~ forest * agegrp)\n\n7.Now that you have made the final predictive model (using the classical moldel), let’s continue with an explanatory model for the effect of living in the forest versus the savannah. Which factors should we consider? We will follow these steps:\n\nFit a model containing only the primary exposure variable of interest; write down the effect size, which is the crude OR.\nconstruct models with two variables, including the primary exposure and another exposure; identify confounders by comparing crude with adjusted ORs\nconstruct saturated model containing all exposure variables which resulted in a 10% change in effect size of the primary exposure (ref. step 2)\neliminate exposure variables one after the other, but do not eliminate established confounders; retain exposure variable if removing it resulted in a 10% change in effect size of the primary exposure (ref. step 3)\nExplore interaction between primary exposure and other exposure variables; neglect other types of interaction\n\n\n\n8. Present a table with results of logistic regressions on forest alone, forest + female and forest + age group. Did the odds ratios of forest change as a result of this control for confounding?\n\n\n9. Gender is not a confounder, but age group is. Normally this would be the end of our procedure. However, we would also like to explore interaction effects between the primary exposure and each of the confounders. This is best done by recoding age group to two levels, creating a variable ‘adult’ set to ‘FALSE’ if age is 0-19 years and ‘TRUE’ if age is 20 years or above. Is ‘adult’ or ‘female’ an effect modifier in the association between ‘forest’ and disease?"
  },
  {
    "objectID": "2023-02-09 CaseAssigment.html",
    "href": "2023-02-09 CaseAssigment.html",
    "title": "2023-02-09 CaseAssignm",
    "section": "",
    "text": "Instituut Voor Tropische Geneeskunde - Antwerp, Belgium"
  },
  {
    "objectID": "2023-02-09 CaseAssigment.html#step-by-step---selection-of-variables-for-modeling",
    "href": "2023-02-09 CaseAssigment.html#step-by-step---selection-of-variables-for-modeling",
    "title": "2023-02-09 CaseAssignm",
    "section": "Step by Step - Selection of variables for modeling",
    "text": "Step by Step - Selection of variables for modeling\n\nImport data\nImporting a CSV database under the name of “VL_Bihar”:\n\nlibrary(readxl)\nVL_Bihar <- read_excel(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2/Logistic Regresion Exercise Database/Datasets/VL_Bihar.xlsx\")\n\n\n\nStarting the Exercise:\n\n1. Description of the study population\n1.1 Sex\n\n```{r}\ntable(VL_Bihar$sex, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$sex))           #proportion\n```\n\n\n   1    2 <NA> \n 907  973    0 \n\n        1         2 \n0.4824468 0.5175532 \n\n\n1.2 Age\n\n```{r}\nsummary(VL_Bihar$age)\n```\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2.00    8.00   19.50   24.15   35.00   90.00       2 \n\n\n1.2.1 Categories of age\n\n```{r}\n#Group Age\nVL_Bihar$groupage <- NA\nVL_Bihar$groupage[VL_Bihar$age<15] <- \"0\"\nVL_Bihar$groupage[VL_Bihar$age>14 & VL_Bihar$age<35] <- \"1\"\nVL_Bihar$groupage[VL_Bihar$age>34] <- \"2\"\n\ntable(VL_Bihar$groupage, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$groupage, useNA = \"always\"))           #proportion\n```\n\n\n   0    1    2 <NA> \n 765  608  505    2 \n\n         0          1          2       <NA> \n0.40691489 0.32340426 0.26861702 0.00106383 \n\n\n1.3 Case\n\n```{r}\ntable(VL_Bihar$case, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$case))           #proportion\n```\n\n\n   0    1 <NA> \n1673  207    0 \n\n        0         1 \n0.8898936 0.1101064 \n\n\n1.4. Died\n\n```{r}\ntable(VL_Bihar$died, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$died))           #proportion\n```\n\n\n   0    1 <NA> \n1877    3    0 \n\n          0           1 \n0.998404255 0.001595745 \n\n\n1.5. neem_tree\n\n```{r}\ntable(VL_Bihar$neem_tree, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$neem_tree))           #proportion\n```\n\n\n   0    1 <NA> \n1122  758    0 \n\n        0         1 \n0.5968085 0.4031915 \n\n\n1.6. bamboo_tree\n\n```{r}\ntable(VL_Bihar$bamboo_tree, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$bamboo_tree))           #proportion\n```\n\n\n   0    1 <NA> \n1144  736    0 \n\n        0         1 \n0.6085106 0.3914894 \n\n\n1.7. banana_tree\n\n```{r}\ntable(VL_Bihar$banana_tree, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$banana_tree))           #proportion\n```\n\n\n   0    1 <NA> \n 304 1576    0 \n\n        0         1 \n0.1617021 0.8382979 \n\n\n1.8. rice_field\n\n```{r}\ntable(VL_Bihar$rice_field, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$rice_field))           #proportion\n```\n\n\n   0    1 <NA> \n 379 1501    0 \n\n        0         1 \n0.2015957 0.7984043 \n\n\n1.9. permanent_water_body\n\n```{r}\ntable(VL_Bihar$permanent_water_body, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$permanent_water_body))           #proportion\n```\n\n\n   0    1 <NA> \n1002  878    0 \n\n        0         1 \n0.5329787 0.4670213 \n\n\n1.10 granaries_in_hh\n\n```{r}\ntable(VL_Bihar$granaries_in_hh, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$granaries_in_hh))           #proportion\n```\n\n\n   0    1 <NA> \n 806 1074    0 \n\n        0         1 \n0.4287234 0.5712766 \n\n\n1.11 owngoat\n\n```{r}\ntable(VL_Bihar$owngoat, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$owngoat))           #proportion\n```\n\n\n   0    1 <NA> \n1282  598    0 \n\n        0         1 \n0.6819149 0.3180851 \n\n\n1.12 ownpoul\n\n```{r}\ntable(VL_Bihar$ownpoul, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$ownpoul))           #proportion\n```\n\n\n   0    1 <NA> \n1799   81    0 \n\n         0          1 \n0.95691489 0.04308511 \n\n\n1.13 ownbov\n\n```{r}\ntable(VL_Bihar$ownbov, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$ownbov))           #proportion\n```\n\n\n   0    1 <NA> \n1161  719    0 \n\n        0         1 \n0.6175532 0.3824468 \n\n\n1.14 bednet\n\n```{r}\ntable(VL_Bihar$bednet, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$bednet))           #proportion\n```\n\n\n   0    1 <NA> \n1507  373    0 \n\n        0         1 \n0.8015957 0.1984043 \n\n\n1.15 asset_index\n\n```{r}\ntable(VL_Bihar$asset_index, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$asset_index))           #proportion\n```\n\n\n   1    2    3    4    5 <NA> \n 447  374  325  392  342    0 \n\n        1         2         3         4         5 \n0.2377660 0.1989362 0.1728723 0.2085106 0.1819149 \n\n\n1.16 riskwall\n\n```{r}\ntable(VL_Bihar$riskwall, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$riskwall))           #proportion\n```\n\n\n   0    1 <NA> \n1104  776    0 \n\n       0        1 \n0.587234 0.412766 \n\n\n1.17 earthfloor\n\n```{r}\ntable(VL_Bihar$earthfloor, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$earthfloor))           #proportion\n```\n\n\n   0    1 <NA> \n 171 1709    0 \n\n         0          1 \n0.09095745 0.90904255 \n\n\n1.18 sc_caste\n\n```{r}\ntable(VL_Bihar$sc_caste, useNA = \"always\")     #frecuency\nprop.table(table(VL_Bihar$sc_caste))           #proportion\n```\n\n\n   0    1 <NA> \n1808   72    0 \n\n         0          1 \n0.96170213 0.03829787 \n\n\n\n\n2. Bivariate analysis\n2.1 Case and sex\n\n```{r}\nGLM1 <- glm(formula = case ~ factor(sex), family = binomial, data = VL_Bihar)\n    summary(GLM1)\n    exp(coef(GLM1))\n    exp(confint(GLM1))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(sex), family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5011  -0.5011  -0.4657  -0.4657   2.1332  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   -2.0118     0.1029 -19.544   <2e-16 ***\nfactor(sex)2  -0.1550     0.1474  -1.051    0.293    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1302.6  on 1878  degrees of freedom\nAIC: 1306.6\n\nNumber of Fisher Scoring iterations: 4\n\n (Intercept) factor(sex)2 \n   0.1337500    0.8564302 \n                 2.5 %    97.5 %\n(Intercept)  0.1087251 0.1628343\nfactor(sex)2 0.6410060 1.1433795\n\n\n2.2 Case and age\n\n```{r}\nGLM2 <- glm(formula = case ~ age, family = binomial, data = VL_Bihar)\n    summary(GLM2)\n    exp(coef(GLM2))\n    exp(confint(GLM2))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ age, family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5340  -0.5134  -0.4815  -0.4272   2.2860  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.854781   0.118111 -15.704   <2e-16 ***\nage         -0.010493   0.004288  -2.447   0.0144 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1299.1  on 1877  degrees of freedom\nResidual deviance: 1292.8  on 1876  degrees of freedom\n  (2 observations deleted due to missingness)\nAIC: 1296.8\n\nNumber of Fisher Scoring iterations: 5\n\n(Intercept)         age \n  0.1564872   0.9895616 \n                2.5 %    97.5 %\n(Intercept) 0.1236807 0.1965649\nage         0.9810855 0.9977385\n\n\n2.2.1 Case and age group\n\n```{r}\nGLM2_1 <- glm(formula = case ~ groupage, family = binomial, data = VL_Bihar)\n    summary(GLM2_1)\n    exp(coef(GLM2_1))\n    exp(confint(GLM2_1))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ groupage, family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5265  -0.5265  -0.4677  -0.4270   2.2092  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -1.9062     0.1077 -17.696   <2e-16 ***\ngroupage1    -0.2515     0.1712  -1.469   0.1419    \ngroupage2    -0.4430     0.1910  -2.319   0.0204 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1299.1  on 1877  degrees of freedom\nResidual deviance: 1293.1  on 1875  degrees of freedom\n  (2 observations deleted due to missingness)\nAIC: 1299.1\n\nNumber of Fisher Scoring iterations: 5\n\n(Intercept)   groupage1   groupage2 \n  0.1486486   0.7776480   0.6420824 \n                2.5 %    97.5 %\n(Intercept) 0.1196675 0.1826217\ngroupage1   0.5538452 1.0847758\ngroupage2   0.4379600 0.9277561\n\n\n2.3 Case and died\n\n```{r}\nGLM3 <- glm(formula = case ~ factor(died), family = binomial, data = VL_Bihar)\n    summary(GLM3)\n    exp(coef(GLM3))\n    exp(confint(GLM3))\n```\n\nWaiting for profiling to be done...\n\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\n\nCall:\nglm(formula = case ~ factor(died), family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.4797  -0.4797  -0.4797  -0.4797   2.1068  \n\nCoefficients:\n               Estimate Std. Error z value Pr(>|z|)    \n(Intercept)    -2.10425    0.07416 -28.375   <2e-16 ***\nfactor(died)1  16.67032  509.65213   0.033    0.974    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1290.5  on 1878  degrees of freedom\nAIC: 1294.5\n\nNumber of Fisher Scoring iterations: 13\n\n  (Intercept) factor(died)1 \n 1.219366e-01  1.737115e+07 \n                     2.5 %    97.5 %\n(Intercept)   1.051421e-01 0.1406351\nfactor(died)1 2.290754e-22        NA\n\n\n2.4 Case and neem_tree\n\n```{r}\nGLM4 <- glm(formula = case ~ factor(neem_tree), family = binomial, data = VL_Bihar)\n    summary(GLM4)\n    exp(coef(GLM4))\n    exp(confint(GLM4))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(neem_tree), family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5023  -0.5023  -0.5023  -0.4533   2.1571  \n\nCoefficients:\n                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)        -2.00635    0.09236 -21.724   <2e-16 ***\nfactor(neem_tree)1 -0.21755    0.15330  -1.419    0.156    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1301.7  on 1878  degrees of freedom\nAIC: 1305.7\n\nNumber of Fisher Scoring iterations: 4\n\n       (Intercept) factor(neem_tree)1 \n         0.1344793          0.8044893 \n                       2.5 %   97.5 %\n(Intercept)        0.1117282 0.160517\nfactor(neem_tree)1 0.5933996 1.083238\n\n\n2.5 Case and bamboo_tree\n\n```{r}\nGLM5 <- glm(formula = case ~ factor(bamboo_tree), family = binomial, data = VL_Bihar)\n    summary(GLM5)\n    exp(coef(GLM5))\n    exp(confint(GLM5))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(bamboo_tree), family = binomial, \n    data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5287  -0.5287  -0.4518  -0.4518   2.1600  \n\nCoefficients:\n                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)          -2.23069    0.09987 -22.335   <2e-16 ***\nfactor(bamboo_tree)1  0.33357    0.14817   2.251   0.0244 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1298.7  on 1878  degrees of freedom\nAIC: 1302.7\n\nNumber of Fisher Scoring iterations: 4\n\n         (Intercept) factor(bamboo_tree)1 \n            0.107454             1.395946 \n                          2.5 %    97.5 %\n(Intercept)          0.08787735 0.1300431\nfactor(bamboo_tree)1 1.04293293 1.8656202\n\n\n2.6 Case and banana_tree\n\n```{r}\nGLM6 <- glm(formula = case ~ factor(banana_tree), family = binomial, data = VL_Bihar)\n    summary(GLM6)\n    exp(coef(GLM6))\n    exp(confint(GLM6))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(banana_tree), family = binomial, \n    data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5021  -0.4793  -0.4793  -0.4793   2.1076  \n\nCoefficients:\n                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)          -2.00747    0.17751 -11.309   <2e-16 ***\nfactor(banana_tree)1 -0.09866    0.19511  -0.506    0.613    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1303.5  on 1878  degrees of freedom\nAIC: 1307.5\n\nNumber of Fisher Scoring iterations: 4\n\n         (Intercept) factor(banana_tree)1 \n           0.1343284            0.9060498 \n                          2.5 %    97.5 %\n(Intercept)          0.09330639 0.1875041\nfactor(banana_tree)1 0.62506879 1.3458822\n\n\n2.7 Case and rice_field\n\n```{r}\nGLM7 <- glm(formula = case ~ factor(rice_field), family = binomial, data = VL_Bihar)\n    summary(GLM7)\n    exp(coef(GLM7))\n    exp(confint(GLM7))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(rice_field), family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.4949  -0.4949  -0.4949  -0.4336   2.1960  \n\nCoefficients:\n                    Estimate Std. Error z value Pr(>|z|)    \n(Intercept)          -2.3172     0.1797 -12.894   <2e-16 ***\nfactor(rice_field)1   0.2790     0.1970   1.416    0.157    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1301.6  on 1878  degrees of freedom\nAIC: 1305.6\n\nNumber of Fisher Scoring iterations: 4\n\n        (Intercept) factor(rice_field)1 \n         0.09855074          1.32186819 \n                         2.5 %    97.5 %\n(Intercept)         0.06804181 0.1379605\nfactor(rice_field)1 0.90960592 1.9741271\n\n\n2.8 Case and permanent_water_body\n\n```{r}\nGLM8 <- glm(formula = case ~ factor(permanent_water_body), family = binomial, data = VL_Bihar)\n    summary(GLM8)\n    exp(coef(GLM8))\n    exp(confint(GLM8))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(permanent_water_body), family = binomial, \n    data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.4846  -0.4846  -0.4812  -0.4812   2.1040  \n\nCoefficients:\n                              Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                   -2.08281    0.10065 -20.693   <2e-16 ***\nfactor(permanent_water_body)1 -0.01469    0.14773  -0.099    0.921    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1303.7  on 1878  degrees of freedom\nAIC: 1307.7\n\nNumber of Fisher Scoring iterations: 4\n\n                  (Intercept) factor(permanent_water_body)1 \n                    0.1245791                     0.9854151 \n                                  2.5 %   97.5 %\n(Intercept)                   0.1017388 0.151011\nfactor(permanent_water_body)1 0.7368210 1.315789\n\n\n2.9 Case and granaries_in_hh\n\n```{r}\nGLM9 <- glm(formula = case ~ factor(granaries_in_hh), family = binomial, data = VL_Bihar)\n    summary(GLM9)\n    exp(coef(GLM9))\n    exp(confint(GLM9))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(granaries_in_hh), family = binomial, \n    data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.4838  -0.4838  -0.4825  -0.4825   2.1016  \n\nCoefficients:\n                          Estimate Std. Error z value Pr(>|z|)    \n(Intercept)              -2.086439   0.112383 -18.565   <2e-16 ***\nfactor(granaries_in_hh)1 -0.005634   0.148829  -0.038     0.97    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1303.7  on 1878  degrees of freedom\nAIC: 1307.7\n\nNumber of Fisher Scoring iterations: 4\n\n             (Intercept) factor(granaries_in_hh)1 \n               0.1241283                0.9943820 \n                              2.5 %    97.5 %\n(Intercept)              0.09893469 0.1537828\nfactor(granaries_in_hh)1 0.74366989 1.3337585\n\n\n2.10 Case and owngoat\n\n```{r}\nGLM10 <- glm(formula = case ~ factor(owngoat), family = binomial, data = VL_Bihar)\n    summary(GLM10)\n    exp(coef(GLM10))\n    exp(confint(GLM10))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(owngoat), family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5065  -0.5065  -0.4717  -0.4717   2.1218  \n\nCoefficients:\n                 Estimate Std. Error z value Pr(>|z|)    \n(Intercept)      -2.13963    0.09099 -23.516   <2e-16 ***\nfactor(owngoat)1  0.15100    0.15514   0.973     0.33    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1302.8  on 1878  degrees of freedom\nAIC: 1306.8\n\nNumber of Fisher Scoring iterations: 4\n\n     (Intercept) factor(owngoat)1 \n       0.1176983        1.1629911 \n                      2.5 %    97.5 %\n(Intercept)      0.09804742 0.1401079\nfactor(owngoat)1 0.85459470 1.5712859\n\n\n2.11 Case and ownpoul\n\n```{r}\nGLM11 <- glm(formula = case ~ factor(ownpoul), family = binomial, data = VL_Bihar)\n    summary(GLM11)\n    exp(coef(GLM11))\n    exp(confint(GLM11))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(ownpoul), family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5915  -0.4777  -0.4777  -0.4777   2.1105  \n\nCoefficients:\n                 Estimate Std. Error z value Pr(>|z|)    \n(Intercept)      -2.11302    0.07601 -27.800   <2e-16 ***\nfactor(ownpoul)1  0.45846    0.31210   1.469    0.142    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1301.8  on 1878  degrees of freedom\nAIC: 1305.8\n\nNumber of Fisher Scoring iterations: 4\n\n     (Intercept) factor(ownpoul)1 \n       0.1208723        1.5816404 \n                     2.5 %    97.5 %\n(Intercept)      0.1038311 0.1398946\nfactor(ownpoul)1 0.8221058 2.8219122\n\n\n2.12 Case and ownbov\n\n```{r}\nGLM12 <- glm(formula = case ~ factor(ownbov), family = binomial, data = VL_Bihar)\n    summary(GLM12)\n    exp(coef(GLM12))\n    exp(confint(GLM12))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(ownbov), family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.4889  -0.4889  -0.4793  -0.4793   2.1075  \n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)     -2.10587    0.09435 -22.320   <2e-16 ***\nfactor(ownbov)1  0.04199    0.15105   0.278    0.781    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1303.7  on 1878  degrees of freedom\nAIC: 1307.7\n\nNumber of Fisher Scoring iterations: 4\n\n    (Intercept) factor(ownbov)1 \n      0.1217391       1.0428795 \n                    2.5 %    97.5 %\n(Intercept)     0.1007174 0.1458382\nfactor(ownbov)1 0.7734163 1.3992746\n\n\n2.13 Case and bednet\n\n```{r}\nGLM13 <- glm(formula = case ~ factor(bednet), family = binomial, data = VL_Bihar)\n    summary(GLM13)\n    exp(coef(GLM13))\n    exp(confint(GLM13))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(bednet), family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5103  -0.5103  -0.5103  -0.3568   2.3605  \n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)     -1.97272    0.07868 -25.073  < 2e-16 ***\nfactor(bednet)1 -0.74972    0.22918  -3.271  0.00107 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1291.2  on 1878  degrees of freedom\nAIC: 1295.2\n\nNumber of Fisher Scoring iterations: 5\n\n    (Intercept) factor(bednet)1 \n      0.1390779       0.4725000 \n                    2.5 %    97.5 %\n(Intercept)     0.1188343 0.1617957\nfactor(bednet)1 0.2941532 0.7252757\n\n\n2.14 Case and asset_index\n\n```{r}\nGLM14 <- glm(formula = case ~ factor(asset_index), family = binomial, data = VL_Bihar)\n    summary(GLM14)\n    exp(coef(GLM14))\n    exp(confint(GLM14))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(asset_index), family = binomial, \n    data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5882  -0.5860  -0.4628  -0.2995   2.5007  \n\nCoefficients:\n                      Estimate Std. Error z value Pr(>|z|)    \n(Intercept)          -1.666909   0.129399 -12.882  < 2e-16 ***\nfactor(asset_index)2 -0.008126   0.192010  -0.042 0.966243    \nfactor(asset_index)3 -0.513337   0.224659  -2.285 0.022315 *  \nfactor(asset_index)4 -0.860198   0.232339  -3.702 0.000214 ***\nfactor(asset_index)5 -1.415001   0.294023  -4.813 1.49e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1260.9  on 1875  degrees of freedom\nAIC: 1270.9\n\nNumber of Fisher Scoring iterations: 5\n\n         (Intercept) factor(asset_index)2 factor(asset_index)3 \n           0.1888298            0.9919070            0.5984951 \nfactor(asset_index)4 factor(asset_index)5 \n           0.4230784            0.2429255 \n                         2.5 %    97.5 %\n(Intercept)          0.1454019 0.2416577\nfactor(asset_index)2 0.6793381 1.4439490\nfactor(asset_index)3 0.3813144 0.9223585\nfactor(asset_index)4 0.2647424 0.6603038\nfactor(asset_index)5 0.1317253 0.4204629\n\n\n2.15 Case and riskwall\n\n```{r}\nGLM15 <- glm(formula = case ~ factor(riskwall), family = binomial, data = VL_Bihar)\n    summary(GLM15)\n    exp(coef(GLM15))\n    exp(confint(GLM15))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(riskwall), family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5717  -0.5717  -0.4124  -0.4124   2.2391  \n\nCoefficients:\n                  Estimate Std. Error z value Pr(>|z|)    \n(Intercept)        -2.4218     0.1100 -22.019  < 2e-16 ***\nfactor(riskwall)1   0.6933     0.1489   4.657 3.21e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1281.8  on 1878  degrees of freedom\nAIC: 1285.8\n\nNumber of Fisher Scoring iterations: 5\n\n      (Intercept) factor(riskwall)1 \n        0.0887574         2.0003035 \n                     2.5 %    97.5 %\n(Intercept)       0.071064 0.1094251\nfactor(riskwall)1 1.495792 2.6830202\n\n\n2.16 Case and earthfloor\n\n```{r}\nGLM16 <- glm(formula = case ~ factor(earthfloor), family = binomial, data = VL_Bihar)\n    summary(GLM16)\n    exp(coef(GLM16))\n    exp(confint(GLM16))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(earthfloor), family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5002  -0.5002  -0.5002  -0.5002   2.5884  \n\nCoefficients:\n                    Estimate Std. Error z value Pr(>|z|)    \n(Intercept)          -3.3142     0.4154  -7.979 1.47e-15 ***\nfactor(earthfloor)1   1.2990     0.4221   3.077  0.00209 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1289.8  on 1878  degrees of freedom\nAIC: 1293.8\n\nNumber of Fisher Scoring iterations: 5\n\n        (Intercept) factor(earthfloor)1 \n         0.03636366          3.66544816 \n                         2.5 %     97.5 %\n(Intercept)         0.01429586 0.07505732\nfactor(earthfloor)1 1.74657291 9.41739018\n\n\n2.17 Case and sc_caste\n\n```{r}\nGLM17 <- glm(formula = case ~ factor(sc_caste), family = binomial, data = VL_Bihar)\n    summary(GLM17)\n    exp(coef(GLM17))\n    exp(confint(GLM17))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = case ~ factor(sc_caste), family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.0842  -0.4512  -0.4512  -0.4512   2.1611  \n\nCoefficients:\n                  Estimate Std. Error z value Pr(>|z|)    \n(Intercept)       -2.23339    0.07954 -28.079  < 2e-16 ***\nfactor(sc_caste)1  2.01024    0.25015   8.036 9.28e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1248.7  on 1878  degrees of freedom\nAIC: 1252.7\n\nNumber of Fisher Scoring iterations: 5\n\n      (Intercept) factor(sc_caste)1 \n        0.1071647         7.4651429 \n                       2.5 %     97.5 %\n(Intercept)       0.09138689  0.1248467\nfactor(sc_caste)1 4.54860989 12.1710268\n\n\n\n\n3. Multivariate analysis. Association between incidence of visceral leshmanis and regular use of bednet and which factors are potential confounders\nWe will do the “Change in Estimate Model”\nStep 1. We select the factor that can be the main exposure and the other exposures that have logic\n\n\n\n\n\n\nNote\n\n\n\nMain exposure: regular use of bed net\nExclude: Died\n\n\nStep 2. First do the crude odd ratio (bivariate)\n\n```{r}\nML1 <- glm(factor(case) ~ factor(bednet), family=binomial, data=VL_Bihar)\nsummary(ML1)\nexp(coef(ML1))\nexp(confint(ML1))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = factor(case) ~ factor(bednet), family = binomial, \n    data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5103  -0.5103  -0.5103  -0.3568   2.3605  \n\nCoefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n(Intercept)     -1.97272    0.07868 -25.073  < 2e-16 ***\nfactor(bednet)1 -0.74972    0.22918  -3.271  0.00107 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1291.2  on 1878  degrees of freedom\nAIC: 1295.2\n\nNumber of Fisher Scoring iterations: 5\n\n    (Intercept) factor(bednet)1 \n      0.1390779       0.4725000 \n                    2.5 %    97.5 %\n(Intercept)     0.1188343 0.1617957\nfactor(bednet)1 0.2941532 0.7252757\n\n\nStep 3. Then adding each other variable and writing it down. And doing the table of how much change the OR\nCase - bednet + sex\n\n```{r}\nML2 <- glm(factor(case) ~ factor(bednet) + factor(sex), family=binomial, data=VL_Bihar)\nexp(coef(ML2))\nexp(confint(ML2))\n```\n\nWaiting for profiling to be done...\n\n\n    (Intercept) factor(bednet)1    factor(sex)2 \n      0.1497557       0.4737404       0.8623835 \n                    2.5 %    97.5 %\n(Intercept)     0.1208915 0.1836368\nfactor(bednet)1 0.2948994 0.7272629\nfactor(sex)2    0.6449093 1.1523372\n\n\nCase - bednet + age\n\n```{r}\nML3 <- glm(factor(case) ~ factor(bednet) + age, family=binomial, data=VL_Bihar)\nexp(coef(ML3))\nexp(confint(ML3))\n```\n\nWaiting for profiling to be done...\n\n\n    (Intercept) factor(bednet)1             age \n      0.1689851       0.4963053       0.9909758 \n                    2.5 %    97.5 %\n(Intercept)     0.1331263 0.2129796\nfactor(bednet)1 0.3083839 0.7636801\nage             0.9824605 0.9991968\n\n\nCase - bednet + groupage\n\n```{r}\nML3_2 <- glm(factor(case) ~ factor(bednet) + groupage, family=binomial, data=VL_Bihar)\nexp(coef(ML3_2))\nexp(confint(ML3_2))\n```\n\nWaiting for profiling to be done...\n\n\n    (Intercept) factor(bednet)1       groupage1       groupage2 \n      0.1613022       0.4961901       0.8078296       0.6846378 \n                    2.5 %    97.5 %\n(Intercept)     0.1293122 0.1990533\nfactor(bednet)1 0.3082705 0.7636340\ngroupage1       0.5745769 1.1285375\ngroupage2       0.4659519 0.9917488\n\n\nCase - bednet + neem_tree\n\n```{r}\nML4 <- glm(factor(case) ~ factor(bednet) + factor(neem_tree), family=binomial, data=VL_Bihar)\nexp(coef(ML4))\nexp(confint(ML4))\n```\n\nWaiting for profiling to be done...\n\n\n       (Intercept)    factor(bednet)1 factor(neem_tree)1 \n         0.1507119          0.4740451          0.8096511 \n                       2.5 %    97.5 %\n(Intercept)        0.1242335 0.1813191\nfactor(bednet)1    0.2950723 0.7277817\nfactor(neem_tree)1 0.5967055 1.0911650\n\n\nCase - bednet + bamboo_tree\n\n```{r}\nML5 <- glm(factor(case) ~ factor(bednet) + factor(bamboo_tree), family=binomial, data=VL_Bihar)\nexp(coef(ML5))\nexp(confint(ML5))\n```\n\nWaiting for profiling to be done...\n\n\n         (Intercept)      factor(bednet)1 factor(bamboo_tree)1 \n           0.1218403            0.4833793            1.3557781 \n                          2.5 %    97.5 %\n(Intercept)          0.09872222 0.1488309\nfactor(bednet)1      0.30071367 0.7426603\nfactor(bamboo_tree)1 1.01175573 1.8139321\n\n\nCase - bednet + banana_tree\n\n```{r}\nML6 <- glm(factor(case) ~ factor(bednet) + factor(banana_tree), family=binomial, data=VL_Bihar)\nexp(coef(ML6))\nexp(confint(ML6))\n```\n\nWaiting for profiling to be done...\n\n\n         (Intercept)      factor(bednet)1 factor(banana_tree)1 \n           0.1481994            0.4736328            0.9261514 \n                         2.5 %    97.5 %\n(Intercept)          0.1025907 0.2077231\nfactor(bednet)1      0.2948139 0.7271530\nfactor(banana_tree)1 0.6381431 1.3772929\n\n\nCase - bednet + rice_field\n\n```{r}\nML7 <- glm(factor(case) ~ factor(bednet) + factor(rice_field), family=binomial, data=VL_Bihar)\nexp(coef(ML7))\nexp(confint(ML7))\n```\n\nWaiting for profiling to be done...\n\n\n        (Intercept)     factor(bednet)1 factor(rice_field)1 \n          0.1144057           0.4800229           1.2666583 \n                         2.5 %    97.5 %\n(Intercept)         0.07841589 0.1615314\nfactor(bednet)1     0.29863762 0.7374461\nfactor(rice_field)1 0.86999235 1.8945309\n\n\nCase - bednet + permanent_water_body\n\n```{r}\nML8 <- glm(factor(case) ~ factor(bednet) + factor(permanent_water_body), family=binomial, data=VL_Bihar)\nexp(coef(ML8))\nexp(confint(ML8))\n```\n\nWaiting for profiling to be done...\n\n\n                  (Intercept)               factor(bednet)1 \n                    0.1386849                     0.4723452 \nfactor(permanent_water_body)1 \n                    1.0062094 \n                                  2.5 %    97.5 %\n(Intercept)                   0.1125509 0.1691994\nfactor(bednet)1               0.2939865 0.7252469\nfactor(permanent_water_body)1 0.7516130 1.3449976\n\n\nCase - bednet + granaries_in_hh\n\n```{r}\nML9 <- glm(factor(case) ~ factor(bednet) + factor(granaries_in_hh), family=binomial, data=VL_Bihar)\nexp(coef(ML9))\nexp(confint(ML9))\n```\n\nWaiting for profiling to be done...\n\n\n             (Intercept)          factor(bednet)1 factor(granaries_in_hh)1 \n               0.1385799                0.4724105                1.0063584 \n                             2.5 %    97.5 %\n(Intercept)              0.1097963 0.1727742\nfactor(bednet)1          0.2940746 0.7252060\nfactor(granaries_in_hh)1 0.7519452 1.3510593\n\n\nCase - bednet + owngoat\n\n```{r}\nML10 <- glm(factor(case) ~ factor(bednet) + factor(owngoat), family=binomial, data=VL_Bihar)\nexp(coef(ML10))\nexp(confint(ML10))\n```\n\nWaiting for profiling to be done...\n\n\n     (Intercept)  factor(bednet)1 factor(owngoat)1 \n       0.1348600        0.4785828        1.0907549 \n                     2.5 %    97.5 %\n(Intercept)      0.1110257 0.1623881\nfactor(bednet)1  0.2973262 0.7365004\nfactor(owngoat)1 0.7996930 1.4770939\n\n\nCase - bednet + ownpoul\n\n```{r}\nML11 <- glm(factor(case) ~ factor(bednet) + factor(ownpoul), family=binomial, data=VL_Bihar)\nexp(coef(ML11))\nexp(confint(ML11))\n```\n\nWaiting for profiling to be done...\n\n\n     (Intercept)  factor(bednet)1 factor(ownpoul)1 \n       0.1359797        0.4769139        1.5118321 \n                     2.5 %    97.5 %\n(Intercept)      0.1156162 0.1589157\nfactor(bednet)1  0.2968099 0.7323453\nfactor(ownpoul)1 0.7844602 2.7032767\n\n\nCase - bednet + ownbov\n\n```{r}\nML12 <- glm(factor(case) ~ factor(bednet) + factor(ownbov), family=binomial, data=VL_Bihar)\nexp(coef(ML12))\nexp(confint(ML12))\n```\n\nWaiting for profiling to be done...\n\n\n    (Intercept) factor(bednet)1 factor(ownbov)1 \n      0.1344998       0.4674983       1.0953236 \n                    2.5 %    97.5 %\n(Intercept)     0.1106581 0.1620431\nfactor(bednet)1 0.2906619 0.7186983\nfactor(ownbov)1 0.8108404 1.4725822\n\n\nCase - bednet + asset_index\n\n```{r}\nML13 <- glm(factor(case) ~ factor(bednet) + factor(asset_index), family=binomial, data=VL_Bihar)\nsummary(ML13)\nexp(coef(ML13))\nexp(confint(ML13))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = factor(case) ~ factor(bednet) + factor(asset_index), \n    family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.5955  -0.5941  -0.4723  -0.3225   2.5833  \n\nCoefficients:\n                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)          -1.64489    0.13006 -12.647  < 2e-16 ***\nfactor(bednet)1      -0.37012    0.24058  -1.538 0.123934    \nfactor(asset_index)2  0.00511    0.19228   0.027 0.978800    \nfactor(asset_index)3 -0.49232    0.22509  -2.187 0.028725 *  \nfactor(asset_index)4 -0.79317    0.23566  -3.366 0.000763 ***\nfactor(asset_index)5 -1.28561    0.30390  -4.230 2.33e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1258.3  on 1874  degrees of freedom\nAIC: 1270.3\n\nNumber of Fisher Scoring iterations: 5\n\n         (Intercept)      factor(bednet)1 factor(asset_index)2 \n           0.1930338            0.6906510            1.0051226 \nfactor(asset_index)3 factor(asset_index)4 factor(asset_index)5 \n           0.6112062            0.4524071            0.2764830 \n                         2.5 %    97.5 %\n(Intercept)          0.1484556 0.2473784\nfactor(bednet)1      0.4214821 1.0867165\nfactor(asset_index)2 0.6880463 1.4639808\nfactor(asset_index)3 0.3891080 0.9427867\nfactor(asset_index)4 0.2813302 0.7108052\nfactor(asset_index)5 0.1472895 0.4884626\n\n\nCase - bednet + riskwall\n\n```{r}\nML14 <- glm(factor(case) ~ factor(bednet) + factor(riskwall), family=binomial, data=VL_Bihar)\nexp(coef(ML14))\nexp(confint(ML14))\n```\n\nWaiting for profiling to be done...\n\n\n      (Intercept)   factor(bednet)1 factor(riskwall)1 \n        0.1011328         0.5528385         1.8463805 \n                       2.5 %    97.5 %\n(Intercept)       0.07972857 0.1265816\nfactor(bednet)1   0.34181591 0.8561327\nfactor(riskwall)1 1.37410587 2.4884630\n\n\nCase - bednet + earthfloor\n\n```{r}\nML15 <- glm(factor(case) ~ factor(bednet) + factor(earthfloor), family=binomial, data=VL_Bihar)\nexp(coef(ML15))\nexp(confint(ML15))\n```\n\nWaiting for profiling to be done...\n\n\n        (Intercept)     factor(bednet)1 factor(earthfloor)1 \n         0.04606946          0.52529186          3.16935398 \n                         2.5 %     97.5 %\n(Intercept)         0.01793912 0.09657055\nfactor(bednet)1     0.32593161 0.80963385\nfactor(earthfloor)1 1.49945482 8.17768200\n\n\nCase - bednet + sc_caste\n\n```{r}\nML16 <- glm(factor(case) ~ factor(bednet) + factor(sc_caste), family=binomial, data=VL_Bihar)\nexp(coef(ML16))\nexp(confint(ML16))\n```\n\nWaiting for profiling to be done...\n\n\n      (Intercept)   factor(bednet)1 factor(sc_caste)1 \n        0.1186469         0.5475738         6.7960195 \n                       2.5 %     97.5 %\n(Intercept)       0.09993218  0.1398283\nfactor(bednet)1   0.33945784  0.8451291\nfactor(sc_caste)1 4.12689597 11.1198834\n\n\nTable of how much change the OR\n\n\n\n\n\n\n\n\n\n\nFactor\nCo factor\nOR\n95IC\nChange-in-estimate\n\n\n\n\nBed nets\n\n0.4725\n0.2941532 0.7252757\nRef\n\n\nBed nets\nfactor(sex)\n0.47374\n0.2948994 0.7272629\n-0.3%\n\n\nBed nets\nage\n0.496305\n0.3083839 0.7636801\n-5.0%\n\n\nBed nets\ngroup age\n0.49619\n0.3082705 0.7636340\n-5.0%\n\n\nBed nets\nunder5\n0.482438\n0.3000965 0.7413054\n-2.1%\n\n\nBed nets\nfactor(neem_tree), f\n0.474045\n0.2950723 0.7277817\n-0.3%\n\n\nBed nets\nfactor(bamboo_tree),\n0.483379\n0.30071367 0.7426603\n-2.3%\n\n\nBed nets\nfactor(banana_tree),\n0.473633\n0.2948139 0.7271530\n-0.2%\n\n\nBed nets\nfactor(rice_field),\n0.480023\n0.29863762 0.7374461\n-1.6%\n\n\nBed nets\nfactor(permanent_wat\n0.472345\n0.2939865 0.7252469\n0.0%\n\n\nBed nets\nfactor(granaries_in_\n0.472411\n0.2940746 0.7252060\n0.0%\n\n\nBed nets\nfactor(owngoat),\n0.478583\n0.2973262 0.7365004\n-1.3%\n\n\nBed nets\nfactor(ownpoul),\n0.476914\n0.2968099 0.7323453\n-0.9%\n\n\nBed nets\nfactor(ownbov),\n0.467498\n0.2906619 0.7186983\n1.1%\n\n\nBed nets\nfactor(asset_index)\n0.690651\n0.4214821 1.0867165\n-46.2%\n\n\nBed nets\nfactor(riskwall), f\n0.552839\n0.34181591 0.8561327\n-17.0%\n\n\nBed nets\nfactor(earthfloor),\n0.525292\n0.32593161 0.80963385\n-11.2%\n\n\nBed nets\nfactor(sc_caste), f\n0.547574\n0.33945784 0.8451291\n-15.9%\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSo far we know that assess index, riskwall, earthfloor and sccastle have more than 10% of change in the OR of bednet\n    Assess index : change of 46.2%\n    Riskwall : change of 17%\n    earthfloor: 11.2%\n    sccastle : 15.9 ( Castle is similar to assess index, so we won´t take in to account)\n\n\nSo the model so far is:\n\nML17 <- glm(factor(case) ~ factor(bednet) + factor(asset_index) + factor(riskwall) + factor(earthfloor) , family=binomial, data=VL_Bihar)\n\nStep 4: We are going to exclude factors removing one by one (starting with the one with less change: earthfloor)\nWe will star removing earthfloor:\n\n```{r}\nML18 <- glm(factor(case) ~ factor(bednet) + factor(asset_index) + factor(riskwall) , family=binomial, data=VL_Bihar)\nsummary(ML18)\nexp(coef(ML18))\nexp(confint(ML18))\n```\n\nWaiting for profiling to be done...\n\n\n\nCall:\nglm(formula = factor(case) ~ factor(bednet) + factor(asset_index) + \n    factor(riskwall), family = binomial, data = VL_Bihar)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-0.6197  -0.5569  -0.4514  -0.3220   2.5816  \n\nCoefficients:\n                     Estimate Std. Error z value Pr(>|z|)    \n(Intercept)          -1.82815    0.19068  -9.588  < 2e-16 ***\nfactor(bednet)1      -0.36266    0.24083  -1.506 0.132088    \nfactor(asset_index)2  0.04281    0.19434   0.220 0.825645    \nfactor(asset_index)3 -0.40452    0.23418  -1.727 0.084100 .  \nfactor(asset_index)4 -0.66343    0.25476  -2.604 0.009212 ** \nfactor(asset_index)5 -1.10510    0.33366  -3.312 0.000926 ***\nfactor(riskwall)1     0.23261    0.17392   1.337 0.181078    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1303.7  on 1879  degrees of freedom\nResidual deviance: 1256.5  on 1873  degrees of freedom\nAIC: 1270.5\n\nNumber of Fisher Scoring iterations: 5\n\n         (Intercept)      factor(bednet)1 factor(asset_index)2 \n           0.1607100            0.6958205            1.0437402 \nfactor(asset_index)3 factor(asset_index)4 factor(asset_index)5 \n           0.6672951            0.5150839            0.3311786 \n   factor(riskwall)1 \n           1.2618946 \n                         2.5 %    97.5 %\n(Intercept)          0.1096759 0.2317313\nfactor(bednet)1      0.4244549 1.0954504\nfactor(asset_index)2 0.7116732 1.5265074\nfactor(asset_index)3 0.4176057 1.0483734\nfactor(asset_index)4 0.3091537 0.8414938\nfactor(asset_index)5 0.1675919 0.6242947\nfactor(riskwall)1    0.8990299 1.7791027\n\n\nAnd then comparing both models (ML17 vs ML18)\n\nanova(ML17, ML18, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: factor(case) ~ factor(bednet) + factor(asset_index) + factor(riskwall) + \n    factor(earthfloor)\nModel 2: factor(case) ~ factor(bednet) + factor(asset_index) + factor(riskwall)\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)\n1      1872     1254.1                     \n2      1873     1256.5 -1  -2.4739   0.1157\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause the Likelihood ratio test was not significant (p = 0.1157) there is not significant difference between LM17 an ML18, so we keep the simplest model ML18: factor(case) - factor(bednet) + factor(asset_index) + factor(riskwall)\n\n\nNow we will try to remove other factor (riskwall)\n\n  ML19 <- glm(factor(case) ~ factor(bednet) + factor(asset_index) , family=binomial, data=VL_Bihar)\n\nAnd then comparing both (ML18 vs ML19)\n\nanova(ML18, ML19, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: factor(case) ~ factor(bednet) + factor(asset_index) + factor(riskwall)\nModel 2: factor(case) ~ factor(bednet) + factor(asset_index)\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)\n1      1873     1256.5                     \n2      1874     1258.3 -1  -1.8029   0.1794\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause the Likelihood ratio test was not significant (p = 0.1794) there is not significant difference between LM18 an ML19, so we keep the simplest model LM19: factor(case) - factor(bednet) + factor(asset_index)\n\n\nNow we will try to remove the other factor (assest_index)\n\nML20 <- glm(factor(case) ~ factor(bednet) , family=binomial, data=VL_Bihar)\n\nAnd then comparing both (ML19 vs ML20)\n\nanova(ML19, ML20, test=\"Chisq\")\n\nAnalysis of Deviance Table\n\nModel 1: factor(case) ~ factor(bednet) + factor(asset_index)\nModel 2: factor(case) ~ factor(bednet)\n  Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    \n1      1874     1258.3                          \n2      1878     1291.2 -4  -32.812 1.305e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nNote\n\n\n\nBecause the Likelihood ratio test was significant (1.305e-06 ) there is a significant difference between LM18 an ML19, so we keep the complex model: factor(case) - factor(bednet) + factor(asset_index)\nSo the final model should include: Bednet and asset_index\nNow the question is if those factors are ok like that or there is an interaction between them?\n\n\nStep 5: Analyzing the interaction"
  },
  {
    "objectID": "2023-02-10 Poisson Regression Session 1.html",
    "href": "2023-02-10 Poisson Regression Session 1.html",
    "title": "2023-02-10 Session 1",
    "section": "",
    "text": "Instituut Voor Tropische Geneeskunde - Antwerp, Belgium\nJavier Silva-Valencia"
  },
  {
    "objectID": "2023-02-10 Poisson Regression Session 1.html#step-by-step---selection-of-variables-for-modeling",
    "href": "2023-02-10 Poisson Regression Session 1.html#step-by-step---selection-of-variables-for-modeling",
    "title": "2023-02-10 Session 1",
    "section": "Step by Step - Selection of variables for modeling",
    "text": "Step by Step - Selection of variables for modeling\n\nImport data\nImporting a CSV database under the name of “poisson_smoking_mort”, with “,” as separator:\n\npoisson_smoking_mort <- read.csv(\"C:/Users/pined/OneDrive - Universidad Nacional Mayor de San Marcos/Javier 2022/Belgica/AC2/Logistic Regresion Exercise Database/Datasets/poisson_smoking_mort.csv\", sep=\",\")\n\n\n\n\n\nStarting the Exercise\n\nstr(poisson_smoking_mort)\n\n'data.frame':   36 obs. of  4 variables:\n $ smoke : int  2 2 2 2 2 2 2 2 2 4 ...\n $ pop   : int  145 104 98 372 846 949 824 667 537 3410 ...\n $ deaths: int  2 4 3 38 113 173 212 243 253 124 ...\n $ age   : int  1 2 3 4 5 6 7 8 9 1 ...\n\npoisson_smoking_mort$smoke <-   factor(poisson_smoking_mort$smoke)\n\n\ntable1 <- aggregate(cbind(deaths, pop) ~ smoke, data=poisson_smoking_mort, FUN=sum)\ntable1\n\n  smoke deaths   pop\n1     1    820  5163\n2     2   1041  4542\n3     3   4128 27691\n4     4   3141 18726\n\n\n\ntable(poisson_smoking_mort$smoke)\n\n\n1 2 3 4 \n9 9 9 9"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Finley Malloc",
    "section": "",
    "text": "Finley Malloc is the Chief Data Scientist at Wengo Analytics. When not innovating on data platforms, Finley enjoys spending time unicycling and playing with her pet iguana."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Finley Malloc",
    "section": "Education",
    "text": "Education\nUniversity of California, San Diego | San Diego, CA PhD in Mathematics | Sept 2011 - June 2015\nMacalester College | St. Paul MA B.A in Economics | Sept 2007 - June 2011"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Finley Malloc",
    "section": "Experience",
    "text": "Experience\nWengo Analytics | Head Data Scientist | April 2018 - present\nGeoScynce | Chief Analyst | Spet 2012 - April 2018"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home: Lecture notes",
    "section": "",
    "text": "Welcome to the Lecture notes for the Multivariate Analysis Course at the Institute of Tropical Medicine in Antwerp. These notes were made by Javier Silva-Valencia and contain solutions to the exercises given in class.\nAll lecture notes and this webpage were created using RStudio and Quarto. Enjoy!"
  },
  {
    "objectID": "index.html#disclaimer",
    "href": "index.html#disclaimer",
    "title": "Home: Lecture notes",
    "section": "Disclaimer",
    "text": "Disclaimer\nPlease note: These lecture notes are the work of the author and may not exactly match all the code provided in class. Use them as a reference, but always double-check the solutions with your own understanding and the course materials."
  },
  {
    "objectID": "index.html#navigation",
    "href": "index.html#navigation",
    "title": "Home: Lecture notes",
    "section": "Navigation",
    "text": "Navigation\nUse the sidebar on the left to navigate through the different exercises covered in the course. Each topic has its own set of lecture notes and exercises with solutions."
  }
]